diff --git a/.circleci/config.yml b/.circleci/config.yml
index 3041c18..35ccf24 100755
--- a/.circleci/config.yml
+++ b/.circleci/config.yml
@@ -56,7 +56,7 @@ references:
        pip install -r requirements.txt --user
        sudo pip install -r docs/requirements.txt
        # sphinx-apidoc -o ./docs/source ./pytorch_lightning **/test_* --force --follow-links
-       cd docs; make clean ; make html
+       cd docs; make clean ; make html --debug --jobs 2
 
 jobs:
 
diff --git a/.drone.yml b/.drone.yml
new file mode 100644
index 0000000..60a6375
--- /dev/null
+++ b/.drone.yml
@@ -0,0 +1,23 @@
+# https://docs.drone.io/pipeline/docker/examples/languages/python/#python-example
+
+kind: pipeline
+type: docker
+name: torch-GPU
+
+steps:
+- name: testing
+  image: nvcr.io/nvidia/pytorch:20.02-py3
+  commands:
+    - python --version
+    - pip install pip -U
+    - pip --version
+    - nvidia-smi
+    #- pip install torch==1.3
+    - pip install -r requirements.txt --user
+    - pip install coverage pytest pytest-cov pytest-flake8
+    - pip install -r ./tests/requirements.txt --user
+    - pip list
+    - export SLURM_LOCALID=0
+    - python -c "import torch ; print(' & '.join([torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())]) if torch.cuda.is_available() else 'only CPU')"
+    - coverage run --source pytorch_lightning -m py.test pytorch_lightning tests pl_examples -v --doctest-modules #  --flake8
+    - coverage report
diff --git a/.github/CONTRIBUTING.md b/.github/CONTRIBUTING.md
index 71023d6..6069d72 100644
--- a/.github/CONTRIBUTING.md
+++ b/.github/CONTRIBUTING.md
@@ -1,57 +1,147 @@
 # Contributing    
 Welcome to the PyTorch Lightning community! We're building the most advanced research platform on the planet to implement the latest, best practices that the amazing PyTorch team rolls out!   
 
-## Main Core Value: One less thing to remember    
-Simplify the API as much as possible from the user perspective. Any additions or improvements should minimize things the user needs to remember.   
+## Main Core Value: One less thing to remember
 
-For example: One benefit of the validation_step is that the user doesn't have to remember to set the model to .eval(). This avoids all sorts of subtle errors the user could make.  
+Simplify the API as much as possible from the user perspective.
+ Any additions or improvements should minimize things the user needs to remember.   
 
-## Lightning Design Principles   
-We encourage all sorts of contributions you're interested in adding! When coding for lightning, please follow these principles.    
-#### No PyTorch Interference   
-We don't want to add any abstractions on top of pure PyTorch. This gives researchers all the control they need without having to learn yet another framework.    
+For example: One benefit of the validation_step is that the user doesn't have to remember to set the model to .eval().
+ This avoids all sorts of subtle errors the user could make.  
 
-#### Simple Internal Code    
-It's useful for users to look at the code and understand very quickly what's happening. Many users won't be engineers. Thus we need to value clear, simple code over condensed ninja moves. While that's super cool, this isn't the project for that :)      
+## Lightning Design Principles
+We encourage all sorts of contributions you're interested in adding! When coding for lightning, please follow these principles.   
+ 
+#### No PyTorch Interference
+We don't want to add any abstractions on top of pure PyTorch.
+ This gives researchers all the control they need without having to learn yet another framework.    
 
-#### Force User Decisions To Best Practices    
-There are 1,000 ways to do something. However, something eventually becomes standard practice that everyone does. Thus we pick one way of doing it and force everyone to do it this way. A good example is accumulated gradients. There are many ways to implement, we just pick one and force users to use that one. A bad forced decision would be to make users use a specific library to do something.    
+#### Simple Internal Code
+It's useful for users to look at the code and understand very quickly what's happening.
+ Many users won't be engineers. Thus we need to value clear, simple code over condensed ninja moves.
+ While that's super cool, this isn't the project for that :)      
+
+#### Force User Decisions To Best Practices
+There are 1,000 ways to do something. However, something eventually becomes standard practice that everyone does.
+ Thus we pick one way of doing it and force everyone to do it this way.
+ A good example is accumulated gradients.
+ There are many ways to implement, we just pick one and force users to use that one.
+ A bad forced decision would be to make users use a specific library to do something.    
 
 When something becomes a best practice, we add it to the framework. This likely looks like code in utils or in the model file that everyone keeps adding over and over again across projects. When this happens, bring that code inside the trainer and add a flag for it.
 
-#### Simple External API    
-What makes sense to you may not make sense to others. Create an issue with an API change suggestion and validate that it makes sense for others. Treat code changes how you treat a startup: validate that it's a needed feature, then add if it makes sense for many people. 
+#### Simple External API
+What makes sense to you may not make sense to others. Create an issue with an API change suggestion and validate that it makes sense for others.
+ Treat code changes how you treat a startup: validate that it's a needed feature, then add if it makes sense for many people.
 
-#### Backward-compatible API   
+#### Backward-compatible API
 We all hate updating our deep learning packages because we don't want to refactor a bunch of stuff. In Lightning, we make sure every change we make which could break an API is backwards compatible with good deprecation warnings.
 
-You shouldn't be afraid to upgrade Lightning :)
+**You shouldn't be afraid to upgrade Lightning :)**
 
-#### Gain User Trust    
-As a researcher you can't have any part of your code going wrong. So, make thorough tests that ensure an implementation of a new trick or subbtle change is correct.    
+#### Gain User Trust
+As a researcher you can't have any part of your code going wrong. So, make thorough tests that ensure an implementation of a new trick or subbtle change is correct.
 
-#### Interoperability  
+#### Interoperability
 Have a favorite feature from other libraries like fast.ai or transformers? Those should just work with lightning as well. Grab your favorite model or learning rate scheduler from your favorite library and run it in Lightning.
 
-## Contribution Types    
-Currently looking for help implementing new features or adding bug fixes. 
+---
+
+## Contribution Types
+Currently looking for help implementing new features or adding bug fixes.
+
+A lot of good work has already been done in project mechanics (requirements.txt, setup.py, pep8, badges, ci, etc...) we're in a good state there thanks to all the early contributors (even pre-beta release)!
+
+### Bug Fixes:
+1. Submit a github issue - try to decried what happen so other can reproduce it too.
+2. Try to ix it or recommend a solution...
+3. Submit a PR!
 
-A lot of good work has already been done in project mechanics (requirements.txt, setup.py, pep8, badges, ci, etc...) we're in a good state there thanks to all the early contributors (even pre-beta release)!   
 
-## Bug Fixes:  
-1. Submit a github issue.   
-2. Fix it.  
-3. Submit a PR! 
+### New Features:
+1. Submit a github issue - describe what is motivation of such feature (plus an use-case).
+2. Let's discuss to agree on the feature scope.
+3. Submit a PR! (with updated docs and tests 🙃).
 
-## New Features:  
-1. Submit a github issue.   
-2. We'll agree on the feature scope.     
-3. Submit a PR! (with updated docs and tests 🙃).   
+---
 
-## Coding Styleguide
-1. Test the code with flake8.
-2. Use f-strings.
-3. run locally PEP8 fixes:
+## Guidelines
+
+### Coding Style
+
+1. Use f-strings for output formation (except logging when we stay with lazy `logging.info("Hello %s!`, name).
+2. Test the code with flake8, run locally PEP8 fixes:
     ```
     autopep8 -v -r --max-line-length 120 --in-place .
-    ```
\ No newline at end of file
+    ```
+
+### Documentation
+
+We are using Sphinx with Napoleon extension. 
+Moreover we set Google style to follow with type convention. 
+
+- [Napoleon formatting with Google style](https://sphinxcontrib-napoleon.readthedocs.io/en/latest/example_google.html)
+- [ReStructured Text (reST)](https://docs.pylonsproject.org/projects/docs-style-guide/)
+- [Paragraph-level markup](https://www.sphinx-doc.org/en/1.5/markup/para.html)
+
+See following short example of a sample function taking one position string and optional 
+
+```python
+from typing import Optional
+
+def my_func(param_a: int, param_b: Optional[float] = None) -> str:
+    """Sample function.
+
+    Args:
+        param_a: first parameter
+        param_b: second parameter
+    
+    Return:
+        sum of both numbers
+
+    Example:
+        Sample doctest example...
+        >>> my_func(1, 2)
+        3
+
+    .. note:: If you want to add something.
+    """
+    p = param_b if param_b else 0
+    return str(param_a + p)
+```
+
+### Testing
+
+Test your work locally to speed up your work since so you can focus only in particular (failing) test-cases.
+ To setup a local development environment, install both local and test dependencies:
+```bash
+pip install -r requirements.txt
+pip install -r tests/requirements.txt
+``` 
+
+You can run the full test-case in your terminal via this bash script: 
+
+```bash
+bash .run_local_tests.sh
+```
+
+Note: if your computer does not have multi-GPU nor TPU these tests are skipped.
+
+For convenience, you can use also your own CircleCI building which will be triggered with each commit.
+This is useful if you do not test against all required dependencies version.
+To do so, login to [CircleCI](https://app.circleci.com/) and enable your forked project in the dashboard. It will just work after that.
+
+### Pull Request
+
+We welcome any useful contribution! For convinece here's a recommended workflow:
+
+0. Think about what you want to do - fix a bug, repair docs, etc. 
+1. Start your work locally (usually until you need our CI testing)
+    - create a branch and prepare your changes
+    - hint: do not work with your master directly, it may become complicated when you need to rebase
+    - hint: give your PR a good name! it will be useful later when you may work on multiple tasks/PRs
+2. Create a "Draft PR" which is clearly marked which lets us know you don't need feedback yet.
+3. When you feel like you are ready for integrating your work, turn your PR to "Ready for review".
+4. Use tags in PR name for following cases:
+    - **[blocked by #<number>]** if you work is depending on others changes
+    - **[wip]** when you start to re-edit your work, mark it so no one will accidentally merge it in meantime
diff --git a/.github/PULL_REQUEST_TEMPLATE.md b/.github/PULL_REQUEST_TEMPLATE.md
index 95f3b62..cf1368a 100644
--- a/.github/PULL_REQUEST_TEMPLATE.md
+++ b/.github/PULL_REQUEST_TEMPLATE.md
@@ -1,7 +1,7 @@
 # Before submitting
 
-- [ ] Was this discussed/approved via a Github issue? (no need for typos, doc improvements)
-- [ ] Did you read the [contributor guideline](https://github.com/PyTorchLightning/pytorch-lightning/blob/master/.github/CONTRIBUTING.md)?
+- [ ] Was this discussed/approved via a Github issue? (no need for typos and docs improvements)
+- [ ] Did you read the [contributor guideline](https://github.com/PyTorchLightning/pytorch-lightning/blob/master/.github/CONTRIBUTING.md), Pull Request section?
 - [ ] Did you make sure to update the docs?   
 - [ ] Did you write any new necessary tests?  
 - [ ] If you made a notable change (that affects users), did you update the [CHANGELOG](https://github.com/PyTorchLightning/pytorch-lightning/blob/master/.github/CHANGELOG.md)?
diff --git a/.github/workflows/ci-testing.yml b/.github/workflows/ci-testing.yml
index 6543b91..2cd85c1 100644
--- a/.github/workflows/ci-testing.yml
+++ b/.github/workflows/ci-testing.yml
@@ -1,6 +1,15 @@
 name: CI testing
 
-on: [push, pull_request]
+# https://help.github.com/en/actions/reference/events-that-trigger-workflows
+on:
+  # Trigger the workflow on push or pull request,
+  # but only for the master branch
+  push:
+    branches:
+      - master
+  pull_request:
+    branches:
+      - master
 
 jobs:
   build:
@@ -14,8 +23,10 @@ jobs:
         python-version: [3.6, 3.7]
         requires: ['minimal', 'latest']
 
+    # https://stackoverflow.com/a/59076067/4521646
+    timeout-minutes: 20
     steps:
-    - uses: actions/checkout@v1
+    - uses: actions/checkout@v2
     - name: Set up Python ${{ matrix.python-version }}
       uses: actions/setup-python@v1
       with:
@@ -37,6 +48,13 @@ jobs:
           ${{ runner.os }}-pip-${{ matrix.python-version }}-
           ${{ runner.os }}-${{ matrix.python-version }}-
 
+    - name: Cache datasets
+      uses: actions/cache@v1
+      with:
+        path: tests/datasets # This path is specific to Ubuntu
+        # Look to see if there is a cache hit for the corresponding requirements file
+        key: mnist-dataset
+
     - name: Install dependencies
       run: |
         # python -m pip install --upgrade --user pip
diff --git a/.github/workflows/docs-check.yml b/.github/workflows/docs-check.yml
index a871d65..cd49a01 100644
--- a/.github/workflows/docs-check.yml
+++ b/.github/workflows/docs-check.yml
@@ -8,7 +8,7 @@ jobs:
   docs:
     runs-on: ubuntu-latest
     steps:
-    - uses: actions/checkout@v1
+    - uses: actions/checkout@v2
     - uses: ammaraskar/sphinx-action@master
       with:
         # git is requried to clone the docs theme
diff --git a/.github/workflows/greetings.yml b/.github/workflows/greetings.yml
index 8c6d454..0b4be67 100644
--- a/.github/workflows/greetings.yml
+++ b/.github/workflows/greetings.yml
@@ -1,7 +1,7 @@
 name: Greetings
 # https://github.com/marketplace/actions/first-interaction
 
-on: [pull_request, issues]
+on: [issues]  # pull_request
 
 jobs:
   greeting:
@@ -10,5 +10,5 @@ jobs:
     - uses: actions/first-interaction@v1
       with:
         repo-token: ${{ secrets.GITHUB_TOKEN }}
-        issue-message: 'Hey, thanks for your contribution! Great first issue!'
-        pr-message: 'Hey, thanks for the input! Please give us a bit of time to review it!'
+        issue-message: 'Hi! thanks for your contribution!, great first issue!'
+        pr-message: 'Hey thanks for the input! Please give us a bit of time to review it!'
diff --git a/.pep8speaks.yml b/.pep8speaks.yml
index 154d525..e33d46b 100644
--- a/.pep8speaks.yml
+++ b/.pep8speaks.yml
@@ -5,7 +5,7 @@ scanner:
     linter: pycodestyle  # Other option is flake8
 
 pycodestyle:  # Same as scanner.linter value. Other option is flake8
-    max-line-length: 120  # Default is 79 in PEP 8
+    max-line-length: 100  # Default is 79 in PEP 8
     ignore:  # Errors and warnings to ignore
         - W504  # line break after binary operator
         - E402  # module level import not at top of file
diff --git a/.run_local_tests.sh b/.run_local_tests.sh
index ce7fce5..ce2a920 100644
--- a/.run_local_tests.sh
+++ b/.run_local_tests.sh
@@ -1,5 +1,9 @@
 #!/usr/bin/env bash
 
+# install APEX, see https://github.com/NVIDIA/apex#linux
+# to imitate SLURM set only single node
+export SLURM_LOCALID=0
+
 # use this to run tests
 rm -rf _ckpt_*
 rm -rf ./tests/save_dir*
diff --git a/CHANGELOG.md b/CHANGELOG.md
index b96da2d..d417a21 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -4,10 +4,43 @@ All notable changes to this project will be documented in this file.
 
 The format is based on [Keep a Changelog](http://keepachangelog.com/en/1.0.0/).
 
-## [Unreleased]
+## [unreleased] - YYYY-MM-DD
 
 ### Added
 
+- Add support for hierarchical dict ([#1144](https://github.com/PyTorchLightning/pytorch-lightning/issues/1144))
+- Added type hints to `pytorch_lightning.core` ([#946](https://github.com/PyTorchLightning/pytorch-lightning/pull/946))
+- Added support for IterableDataset in validation and testing ([#1104](https://github.com/PyTorchLightning/pytorch-lightning/pull/1104))
+
+### Changed
+
+-
+
+### Deprecated
+
+-
+
+### Removed
+
+-
+
+### Fixed
+
+-
+
+## [0.7.1] - 2020-03-07
+
+### Fixed
+
+- Fixes `print` issues and `data_loader` ([#1080](https://github.com/PyTorchLightning/pytorch-lightning/pull/1080))
+
+## [0.7.0] - 2020-03-06
+
+### Added
+
+- Added automatic sampler setup. Depending on DDP or TPU, lightning configures the sampler correctly (user needs to do nothing)  ([#926](https://github.com/PyTorchLightning/pytorch-lightning/pull/926))
+- Added `reload_dataloaders_every_epoch=False` flag for trainer. Some users require reloading data every epoch  ([#926](https://github.com/PyTorchLightning/pytorch-lightning/pull/926))
+- Added `progress_bar_refresh_rate=50` flag for trainer. Throttle refresh rate on notebooks  ([#926](https://github.com/PyTorchLightning/pytorch-lightning/pull/926))
 - Updated governance docs
 - Added a check to ensure that the metric used for early stopping exists before training commences ([#542](https://github.com/PyTorchLightning/pytorch-lightning/pull/542))
 - Added `optimizer_idx` argument to `backward` hook ([#733](https://github.com/PyTorchLightning/pytorch-lightning/pull/733))
@@ -17,18 +50,42 @@ The format is based on [Keep a Changelog](http://keepachangelog.com/en/1.0.0/).
 - Added option to specify `step` key when logging metrics ([#808](https://github.com/PyTorchLightning/pytorch-lightning/pull/808))
 - Added `train_dataloader`, `val_dataloader` and `test_dataloader` arguments to `Trainer.fit()`, for alternative data parsing ([#759](https://github.com/PyTorchLightning/pytorch-lightning/pull/759))
 - Added Tensor Processing Unit (TPU) support ([#868](https://github.com/PyTorchLightning/pytorch-lightning/pull/868))
-- Added semantic segmentation example ([#751](https://github.com/PyTorchLightning/pytorch-lightning/pull/751),[#876](https://github.com/PyTorchLightning/pytorch-lightning/pull/876))
+- Added semantic segmentation example ([#751](https://github.com/PyTorchLightning/pytorch-lightning/pull/751),[#876](https://github.com/PyTorchLightning/pytorch-lightning/pull/876), [#881](https://github.com/PyTorchLightning/pytorch-lightning/pull/881))
 - Split callbacks in multiple files ([#849](https://github.com/PyTorchLightning/pytorch-lightning/pull/849))
+- Support for user defined callbacks ([#889](https://github.com/PyTorchLightning/pytorch-lightning/pull/889) and [#950](https://github.com/PyTorchLightning/pytorch-lightning/pull/950))
+- Added support for multiple loggers to be passed to `Trainer` as an iterable (e.g. list, tuple, etc.) ([#903](https://github.com/PyTorchLightning/pytorch-lightning/pull/903))
+- Added support for step-based learning rate scheduling ([#941](https://github.com/PyTorchLightning/pytorch-lightning/pull/941))
+- Added support for logging hparams as dict ([#1029](https://github.com/PyTorchLightning/pytorch-lightning/pull/1029))
+- Checkpoint and early stopping now work without val. step ([#1041](https://github.com/PyTorchLightning/pytorch-lightning/pull/1041))
+- Support graceful training cleanup after Keyboard Interrupt ([#856](https://github.com/PyTorchLightning/pytorch-lightning/pull/856), [#1019](https://github.com/PyTorchLightning/pytorch-lightning/pull/1019))
+- Added type hints for function arguments ([#912](https://github.com/PyTorchLightning/pytorch-lightning/pull/912), )
+- Added default `argparser` for `Trainer` ([#952](https://github.com/PyTorchLightning/pytorch-lightning/pull/1023), [#1023](https://github.com/PyTorchLightning/pytorch-lightning/pull/1023))
+- Added TPU gradient clipping ([#963](https://github.com/PyTorchLightning/pytorch-lightning/pull/963))
+- Added max/min number of steps in Trainer ([#728](https://github.com/PyTorchLightning/pytorch-lightning/pull/728))
+
 
 ### Changed
 
 - Changed default TQDM to use `tqdm.auto` for prettier outputs in IPython notebooks ([#752](https://github.com/PyTorchLightning/pytorch-lightning/pull/752))
 - Changed `pytorch_lightning.logging` to `pytorch_lightning.loggers` ([#767](https://github.com/PyTorchLightning/pytorch-lightning/pull/767))
 - Moved the default `tqdm_dict` definition from Trainer to `LightningModule`, so it can be overridden by the user ([#749](https://github.com/PyTorchLightning/pytorch-lightning/pull/749))
+- Moved functionality of `LightningModule.load_from_metrics` into `LightningModule.load_from_checkpoint` ([#995](https://github.com/PyTorchLightning/pytorch-lightning/pull/995))
+- Changed Checkpoint path parameter from `filepath` to `dirpath` ([#1016](https://github.com/PyTorchLightning/pytorch-lightning/pull/1016))
+- Freezed models `hparams` as `Namespace` property ([#1029](https://github.com/PyTorchLightning/pytorch-lightning/pull/1029))
+- Dropped `logging` config in package init ([#1015](https://github.com/PyTorchLightning/pytorch-lightning/pull/1015))
+- Renames model steps ([#1051](https://github.com/PyTorchLightning/pytorch-lightning/pull/1051))
+    * `training_end` >> `training_epoch_end`
+    * `validation_end` >> `validation_epoch_end`
+    * `test_end` >> `test_epoch_end`
+- Refactor dataloading, supports infinite dataloader ([#955](https://github.com/PyTorchLightning/pytorch-lightning/pull/955))
+- Create single file in `TensorBoardLogger` ([#777](https://github.com/PyTorchLightning/pytorch-lightning/pull/777))
 
 ### Deprecated
 
-- None
+- Deprecated `pytorch_lightning.logging` ([#767](https://github.com/PyTorchLightning/pytorch-lightning/pull/767))
+- Deprecated `LightningModule.load_from_metrics` in favour of `LightningModule.load_from_checkpoint` ([#995](https://github.com/PyTorchLightning/pytorch-lightning/pull/995), [#1079](https://github.com/PyTorchLightning/pytorch-lightning/pull/1079))
+- Deprecated `@data_loader` decorator  ([#926](https://github.com/PyTorchLightning/pytorch-lightning/pull/926))
+- Deprecated model steps `training_end`, `validation_end` and `test_end` ([#1051](https://github.com/PyTorchLightning/pytorch-lightning/pull/1051), [#1056](https://github.com/PyTorchLightning/pytorch-lightning/pull/1056))
 
 ### Removed
 
@@ -42,6 +99,13 @@ The format is based on [Keep a Changelog](http://keepachangelog.com/en/1.0.0/).
 - Fixed a bug where the model checkpointer didn't write to the same directory as the logger ([#771](https://github.com/PyTorchLightning/pytorch-lightning/pull/771))
 - Fixed a bug where the `TensorBoardLogger` class would create an additional empty log file during fitting ([#777](https://github.com/PyTorchLightning/pytorch-lightning/pull/777))
 - Fixed a bug where `global_step` was advanced incorrectly when using `accumulate_grad_batches > 1` ([#832](https://github.com/PyTorchLightning/pytorch-lightning/pull/832))
+- Fixed a bug when calling `self.logger.experiment` with multiple loggers ([#1009](https://github.com/PyTorchLightning/pytorch-lightning/pull/1009))
+- Fixed a bug when calling `logger.append_tags` on a `NeptuneLogger` with a single tag ([#1009](https://github.com/PyTorchLightning/pytorch-lightning/pull/1009))
+- Fixed sending back data from `.spawn` by saving and loading the trained model in/out of the process ([#1017](https://github.com/PyTorchLightning/pytorch-lightning/pull/1017)
+- Fixed port collision on DDP ([#1010](https://github.com/PyTorchLightning/pytorch-lightning/pull/1010))
+- Fixed/tested pass overrides ([#918](https://github.com/PyTorchLightning/pytorch-lightning/pull/918))
+- Fixed comet logger to log after train ([#892](https://github.com/PyTorchLightning/pytorch-lightning/pull/892))
+- Remove deprecated args to learning rate step function ([#890](https://github.com/PyTorchLightning/pytorch-lightning/pull/890))
 
 ## [0.6.0] - 2020-01-21
 
@@ -131,10 +195,6 @@ The format is based on [Keep a Changelog](http://keepachangelog.com/en/1.0.0/).
 
 - Deprecated `tng_dataloader`
 
-### Removed
-
-- None
-
 ### Fixed
 
 - Fixed an issue where the number of batches was off by one during training
@@ -157,10 +217,6 @@ The format is based on [Keep a Changelog](http://keepachangelog.com/en/1.0.0/).
 
 - Changed default for `amp_level` to `O1`
 
-### Deprecated
-
-- None
-
 ### Removed
 
 - Removed the `print_weights_summary` argument from `Trainer`
@@ -192,14 +248,6 @@ The format is based on [Keep a Changelog](http://keepachangelog.com/en/1.0.0/).
 - Disabled auto GPU loading when restoring weights to prevent out of memory errors
 - Changed logging, early stopping and checkpointing to occur by default
 
-### Deprecated
-
-- None
-
-### Removed
-
-- None
-
 ### Fixed
 
 - Fixed a bug with samplers that do not specify `set_epoch`
@@ -209,10 +257,6 @@ The format is based on [Keep a Changelog](http://keepachangelog.com/en/1.0.0/).
 
 ## [0.5.0] - 2019-09-26
 
-### Added
-
-- None
-
 ### Changed
 
 - Changed `data_batch` argument to `batch` throughout
@@ -222,14 +266,6 @@ The format is based on [Keep a Changelog](http://keepachangelog.com/en/1.0.0/).
 - Changed `gradient_clip` argument to `gradient_clip_val`
 - Changed `add_log_row_interval` to `row_log_interval`
 
-### Deprecated
-
-- None
-
-### Removed
-
-- None
-
 ### Fixed
 
 - Fixed a bug with tensorboard logging in multi-gpu setup
@@ -251,14 +287,6 @@ memory utilization
 - Changed gpu API to take integers as well (e.g. `gpus=2` instead of `gpus=[0, 1]`)
 - All models now loaded on to CPU to avoid device and out of memory issues in PyTorch
 
-### Deprecated
-
-- None
-
-### Removed
-
-- None
-
 ### Fixed
 
 - Fixed a bug where data types that implement `.to` but not `.cuda` would not be properly moved onto the GPU
@@ -272,41 +300,17 @@ memory utilization
 - Added `GradientAccumulationScheduler` callback which can be used to schedule changes to the number of accumulation batches
 - Added option to skip the validation sanity check by setting `nb_sanity_val_steps = 0`
 
-### Changed
-
-- None
-
-### Deprecated
-
-- None
-
-### Removed
-
-- None
-
 ### Fixed
 
 - Fixed a bug when setting `nb_sanity_val_steps = 0`
 
 ## [0.4.7] - 2019-08-24
 
-### Added
-
-- None
-
 ### Changed
 
 - Changed the default `val_check_interval` to `1.0`
 - Changed defaults for `nb_val_batches`, `nb_tng_batches` and `nb_test_batches` to 0
 
-### Deprecated
-
-- None
-
-### Removed
-
-- None
-
 ### Fixed
 
 - Fixed a bug where the full validation set as used despite setting `val_percent_check`
@@ -324,18 +328,6 @@ memory utilization
 - Added support for data to be given as a `dict` or `list` with a single gpu
 - Added support for `configure_optimizers` to return a single optimizer, two list (optimizers and schedulers), or a single list
 
-### Changed
-
-- None
-
-### Deprecated
-
-- None
-
-### Removed
-
-- None
-
 ### Fixed
 
 - Fixed a bug where returning just an optimizer list (i.e. without schedulers) from `configure_optimizers` would throw an `Exception`
@@ -346,22 +338,6 @@ memory utilization
 
 - Added `optimizer_step` method that can be overridden to change the standard optimizer behaviour
 
-### Changed
-
-- None
-
-### Deprecated
-
-- None
-
-### Removed
-
-- None
-
-### Fixed
-
-- None
-
 ## [0.4.4] - 2019-08-12
 
 ### Added
@@ -374,14 +350,6 @@ memory utilization
 - `validation_step` and `val_dataloader` are now optional
 - `lr_scheduler` is now activated after epoch
 
-### Deprecated
-
-- None
-
-### Removed
-
-- None
-
 ### Fixed
 
 - Fixed a bug where a warning would show when using `lr_scheduler` in `torch>1.1.0`
@@ -389,70 +357,22 @@ memory utilization
 
 ## [0.4.3] - 2019-08-10
 
-### Added
-
-- None
-
-### Changed
-
-- None
-
-### Deprecated
-
-- None
-
-### Removed
-
-- None
-
 ### Fixed
 
 - Fixed a bug where accumulate gradients would scale the loss incorrectly
 
 ## [0.4.2] - 2019-08-08
 
-### Added
-
-- None
-
 ### Changed
 
 - Changed install requirement to `torch==1.2.0`
 
-### Deprecated
-
-- None
-
-### Removed
-
-- None
-
-### Fixed
-
-- None
-
 ## [0.4.1] - 2019-08-08
 
-### Added
-
-- None
-
 ### Changed
 
 - Changed install requirement to `torch==1.1.0`
 
-### Deprecated
-
-- None
-
-### Removed
-
-- None
-
-### Fixed
-
-- None
-
 ## [0.4.0] - 2019-08-08
 
 ### Added
@@ -464,10 +384,6 @@ memory utilization
 
 - Changed `training_step` and `validation_step`, outputs will no longer be automatically reduced
 
-### Deprecated
-
-- None
-
 ### Removed
 
 - Removed need for `Experiment` object in `Trainer`
@@ -476,46 +392,26 @@ memory utilization
 
 - Fixed issues with reducing outputs from generative models (such as images and text)
 
-## [0.3.6.1] - 2019-07-27
+## [0.3.6] - 2019-07-25
 
 ### Added
 
-- None
-
-### Changed
-
-- None
-
-### Deprecated
-
-- None
-
-### Removed
-
-- None
+- Added a decorator to do lazy data loading internally
 
 ### Fixed
 
 - Fixed a bug where `Experiment` object was not process safe, potentially causing logs to be overwritten
 
-## [0.3.6] - 2019-07-25
+## [0.3.5] - 2019-MM-DD
 
-### Added
+## [0.3.4] - 2019-MM-DD
 
-- Added a decorator to do lazy data loading internally
-
-### Changed
+## [0.3.3] - 2019-MM-DD
 
-- None
-
-### Deprecated
+## [0.3.2] - 2019-MM-DD
 
-- None
+## [0.3.1] - 2019-MM-DD
 
-### Removed
-
-- None
-
-### Fixed
+## [0.2.x] - YYYY-MM-DD
 
-- None
+## [0.1.x] - YYYY-MM-DD
diff --git a/README.md b/README.md
index fa8c1f1..a9f742e 100644
--- a/README.md
+++ b/README.md
@@ -12,10 +12,10 @@
 [![Coverage](docs/source/_static/images/coverage.svg)](https://github.com/PytorchLightning/pytorch-lightning/tree/master/tests#running-coverage)
 [![CodeFactor](https://www.codefactor.io/repository/github/pytorchlightning/pytorch-lightning/badge)](https://www.codefactor.io/repository/github/pytorchlightning/pytorch-lightning)
 
-[![ReadTheDocs](https://readthedocs.org/projects/pytorch-lightning/badge/?version=latest)](https://pytorch-lightning.readthedocs.io/en/latest/)
+[![ReadTheDocs](https://readthedocs.org/projects/pytorch-lightning/badge/?version=0.7.1)](https://pytorch-lightning.readthedocs.io/en/0.7.1/)
 [![Slack](https://img.shields.io/badge/slack-chat-green.svg?logo=slack)](https://join.slack.com/t/pytorch-lightning/shared_invite/enQtODU5ODIyNTUzODQwLTFkMDg5Mzc1MDBmNjEzMDgxOTVmYTdhYjA1MDdmODUyOTg2OGQ1ZWZkYTQzODhhNzdhZDA3YmNhMDhlMDY4YzQ)
 [![license](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://github.com/PytorchLightning/pytorch-lightning/blob/master/LICENSE)
-[![Next Release](https://img.shields.io/badge/Next%20Release-Feb%2021-<COLOR>.svg)](https://shields.io/)
+[![Next Release](https://img.shields.io/badge/Next%20Release-May%2006-<COLOR>.svg)](https://shields.io/)
 
 <!-- 
 removed until codecov badge isn't empy. likely a config error showing nothing on master.
@@ -27,14 +27,13 @@ removed until codecov badge isn't empy. likely a config error showing nothing on
 ## Continuous Integration
 <center>
 
-| System / PyTorch Version | 1.1 | 1.2 | 1.3 | 1.4 |
+| System / PyTorch ver. | 1.1 | 1.2 | 1.3 | 1.4 |
 | :---: | :---: | :---: | :---: | :---: |
-| Linux py3.6 | [![CircleCI](https://circleci.com/gh/PyTorchLightning/pytorch-lightning.svg?style=svg)](https://circleci.com/gh/PyTorchLightning/pytorch-lightning) | [![CircleCI](https://circleci.com/gh/PyTorchLightning/pytorch-lightning.svg?style=svg)](https://circleci.com/gh/PyTorchLightning/pytorch-lightning) | [![CircleCI](https://circleci.com/gh/PyTorchLightning/pytorch-lightning.svg?style=svg)](https://circleci.com/gh/PyTorchLightning/pytorch-lightning) | [![CircleCI](https://circleci.com/gh/PyTorchLightning/pytorch-lightning.svg?style=svg)](https://circleci.com/gh/PyTorchLightning/pytorch-lightning) |
-| Linux py3.7 | ![CI testing](https://github.com/PyTorchLightning/pytorch-lightning/workflows/CI%20testing/badge.svg?event=push) | <center>—</center> | <center>—</center> | ![CI testing](https://github.com/PyTorchLightning/pytorch-lightning/workflows/CI%20testing/badge.svg?event=push) |
-| OSX py3.6 | ![CI testing](https://github.com/PyTorchLightning/pytorch-lightning/workflows/CI%20testing/badge.svg?event=push) | <center>—</center> | <center>—</center> | ![CI testing](https://github.com/PyTorchLightning/pytorch-lightning/workflows/CI%20testing/badge.svg?event=push) |
-| OSX py3.7 | ![CI testing](https://github.com/PyTorchLightning/pytorch-lightning/workflows/CI%20testing/badge.svg?event=push) | <center>—</center> | <center>—</center> | ![CI testing](https://github.com/PyTorchLightning/pytorch-lightning/workflows/CI%20testing/badge.svg?event=push) |
-| Windows py3.6 | ![CI testing](https://github.com/PyTorchLightning/pytorch-lightning/workflows/CI%20testing/badge.svg?event=push) | <center>—</center> | <center>—</center> | ![CI testing](https://github.com/PyTorchLightning/pytorch-lightning/workflows/CI%20testing/badge.svg?event=push) |
-| Windows py3.7 | ![CI testing](https://github.com/PyTorchLightning/pytorch-lightning/workflows/CI%20testing/badge.svg?event=push) | <center>—</center> | <center>—</center> | ![CI testing](https://github.com/PyTorchLightning/pytorch-lightning/workflows/CI%20testing/badge.svg?event=push) |
+| Linux py3.6 [CPU] | [![CircleCI](https://circleci.com/gh/PyTorchLightning/pytorch-lightning.svg?style=svg)](https://circleci.com/gh/PyTorchLightning/pytorch-lightning) | [![CircleCI](https://circleci.com/gh/PyTorchLightning/pytorch-lightning.svg?style=svg)](https://circleci.com/gh/PyTorchLightning/pytorch-lightning) | [![CircleCI](https://circleci.com/gh/PyTorchLightning/pytorch-lightning.svg?style=svg)](https://circleci.com/gh/PyTorchLightning/pytorch-lightning) | [![CircleCI](https://circleci.com/gh/PyTorchLightning/pytorch-lightning.svg?style=svg)](https://circleci.com/gh/PyTorchLightning/pytorch-lightning) |
+| Linux py3.7 [GPU] | <center>—</center> | <center>—</center> | <center>—</center> | [![Build Status](http://35.192.60.23/api/badges/PyTorchLightning/pytorch-lightning/status.svg)](http://35.192.60.23/PyTorchLightning/pytorch-lightning) |
+| Linux py3.6 / py3.7 | ![CI testing](https://github.com/PyTorchLightning/pytorch-lightning/workflows/CI%20testing/badge.svg?event=push) | <center>—</center> | <center>—</center> | ![CI testing](https://github.com/PyTorchLightning/pytorch-lightning/workflows/CI%20testing/badge.svg?event=push) |
+| OSX py3.6 / py3.7| ![CI testing](https://github.com/PyTorchLightning/pytorch-lightning/workflows/CI%20testing/badge.svg?event=push) | <center>—</center> | <center>—</center> | ![CI testing](https://github.com/PyTorchLightning/pytorch-lightning/workflows/CI%20testing/badge.svg?event=push) |
+| Windows py3.6 / py3.7 | ![CI testing](https://github.com/PyTorchLightning/pytorch-lightning/workflows/CI%20testing/badge.svg?event=push) | <center>—</center> | <center>—</center> | ![CI testing](https://github.com/PyTorchLightning/pytorch-lightning/workflows/CI%20testing/badge.svg?event=push) |
 
 </center>
 
@@ -44,21 +43,40 @@ pip install pytorch-lightning
 ```
 
 ## Docs   
-- [master](https://pytorch-lightning.readthedocs.io/en/latest)   
+- [master](https://pytorch-lightning.readthedocs.io/en/latest)  
+- [0.7.1](https://pytorch-lightning.readthedocs.io/en/0.7.1/)
 - [0.6.0](https://pytorch-lightning.readthedocs.io/en/0.6.0/)
 - [0.5.3.2](https://pytorch-lightning.readthedocs.io/en/0.5.3.2/)
 
-
 ## Demo  
-[Copy and run this COLAB!](https://colab.research.google.com/drive/1F_RNcHzTfFuQf-LeKvSlud6x7jXYkG31#scrollTo=HOk9c4_35FKg)
+[MNIST, GAN, BERT on COLAB!](https://colab.research.google.com/drive/1F_RNcHzTfFuQf-LeKvSlud6x7jXYkG31#scrollTo=HOk9c4_35FKg)   
+[MNIST on TPUs](https://colab.research.google.com/drive/1-_LKx4HwAxl5M6xPJmqAAu444LTDQoa3)
+
+## What is it?
+Lightning is a way to organize your PyTorch code to decouple the science code from the engineering. It's more of a style-guide than a framework. 
+
+To use Lightning, first refactor your research code into a [LightningModule](https://pytorch-lightning.readthedocs.io/en/latest/lightning-module.html).
+
+![PT to PL](docs/source/_images/lightning_module/pt_to_pl.png)
+
+And Lightning automates the rest using the [Trainer](https://pytorch-lightning.readthedocs.io/en/latest/trainer.html)!
+![PT to PL](docs/source/_images/lightning_module/pt_trainer.png)
+
+Lightning guarantees riguously tested, correct, modern best practices for the automated parts.  
+
+## How flexible is it?  
+As you see, you're just organizing your PyTorch code - there's no abstraction. 
+
+And for the stuff that the Trainer abstracts out you can [override any part](https://pytorch-lightning.readthedocs.io/en/latest/introduction_guide.html#extensibility) you want to do things like implement your own distributed training, 16-bit precision, or even a custom backwards pass.
 
-## What is it?  
-Lightning is a very lightweight wrapper on PyTorch that decouples the science code from the engineering code. It's more of a style-guide than a framework. By refactoring your code, we can automate most of the non-research code.  
+For anything else you might need, we have an extensive [callback system](https://pytorch-lightning.readthedocs.io/en/latest/introduction_guide.html#callbacks) you can use to add arbitrary functionality not implemented by our team in the Trainer.
 
-To use Lightning, simply refactor your research code into the [LightningModule](https://github.com/PytorchLightning/pytorch-lightning#how-do-i-do-use-it) format (the science) and Lightning will automate the rest (the engineering). Lightning guarantees tested, correct, modern best practices for the automated parts.
+## Who is Lightning for?
+- Professional researchers
+- PhD students
+- Corporate production teams
 
-- If you are a researcher, Lightning is infinitely flexible, you can modify everything down to the way .backward is called or distributed is set up. 
-- If you are a scientist or production team, lightning is very simple to use with best practice defaults.
+If you're just getting into deep learning, we recommend you learn PyTorch first! Once you've implemented a few models, come back and use all the advanced features of Lightning :)
 
 ## What does lightning control for me?   
 
@@ -68,15 +86,23 @@ This is how lightning separates the science (red) from the engineering (blue).
 ![Overview](docs/source/_static/images/pl_overview.gif)
 
 ## How much effort is it to convert?
-You're probably tired of switching frameworks at this point. But it is a very quick process to refactor into the Lightning format (ie: hours). [Check out this tutorial](https://towardsdatascience.com/how-to-refactor-your-pytorch-code-to-get-these-42-benefits-of-pytorch-lighting-6fdd0dc97538)
+If your code is not a huge mess you should be able to organize it into a LightningModule in less than 1 hour.
+If your code IS a mess, then you needed to clean up anyhow ;)
+
+[Check out this step-by-step guide](https://towardsdatascience.com/from-pytorch-to-pytorch-lightning-a-gentle-introduction-b371b7caaf09).
+
 
 ## Starting a new project?   
 [Use our seed-project aimed at reproducibility!](https://github.com/PytorchLightning/pytorch-lightning-conference-seed)     
 
 ## Why do I want to use lightning?
-Every research project starts the same, a model, a training loop, validation loop, etc. As your research advances, you're likely to need distributed training, 16-bit precision, checkpointing, gradient accumulation, etc.   
+Although your research/production project might start simple, once you add things like GPU AND TPU training, 16-bit precision, etc, you end up spending more time engineering than researching. Lightning automates AND rigorously tests those parts for you.
 
-Lightning sets up all the boilerplate state-of-the-art training for you so you can focus on the research.   
+## Support
+- [7 core contributors](https://pytorch-lightning.readthedocs.io/en/latest/governance.html) who are all a mix of professional engineers, Research Scientists, PhD students from top AI labs. 
+- 100+ community contributors.
+
+Lightning is also part of the [PyTorch ecosystem](https://pytorch.org/ecosystem/) which requires projects to have solid testing, documentation and support.
 
 ---
  
@@ -96,26 +122,19 @@ Lightning sets up all the boilerplate state-of-the-art training for you so you c
 
 ---
 
-## How do I do use it?   
-Think about Lightning as refactoring your research code instead of using a new framework. The research code goes into a [LightningModule](https://pytorch-lightning.rtfd.io/en/latest/lightning-module.html) which you fit using a Trainer.
+## Realistic example
+Here's how you would organize a realistic PyTorch project into Lightning.
 
-The LightningModule defines a *system* such as seq-2-seq, GAN, etc... It can ALSO define a simple classifier such as the example below.     
+![PT to PL](docs/source/_images/mnist_imgs/pt_to_pl.jpg)
 
-To use lightning do 2 things:  
-1. [Define a LightningModule](https://pytorch-lightning.rtfd.io/en/latest/lightning-module.html)
-**WARNING:** This syntax is for version 0.5.0+ where abbreviations were removed.
-    ```python
-    import os
-    
-    import torch
-    from torch.nn import functional as F
-    from torch.utils.data import DataLoader
-    from torchvision.datasets import MNIST
-    from torchvision import transforms
-    
-    import pytorch_lightning as pl
-    
-    class CoolSystem(pl.LightningModule):
+The LightningModule defines a *system* such as seq-2-seq, GAN, etc... 
+It can ALSO define a simple classifier.   
+
+In summary, you:
+
+1. Define a [LightningModule](https://pytorch-lightning.rtfd.io/en/latest/lightning-module.html)
+```python
+    class LitSystem(pl.LightningModule):
     
         def __init__(self):
             super(CoolSystem, self).__init__()
@@ -124,102 +143,29 @@ To use lightning do 2 things:
     
         def forward(self, x):
             return torch.relu(self.l1(x.view(x.size(0), -1)))
-    
-        def training_step(self, batch, batch_idx):
-            # REQUIRED
-            x, y = batch
-            y_hat = self.forward(x)
-            loss = F.cross_entropy(y_hat, y)
-            tensorboard_logs = {'train_loss': loss}
-            return {'loss': loss, 'log': tensorboard_logs}
-    
-        def validation_step(self, batch, batch_idx):
-            # OPTIONAL
-            x, y = batch
-            y_hat = self.forward(x)
-            return {'val_loss': F.cross_entropy(y_hat, y)}
-    
-        def validation_end(self, outputs):
-            # OPTIONAL
-            avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()
-            tensorboard_logs = {'val_loss': avg_loss}
-            return {'avg_val_loss': avg_loss, 'log': tensorboard_logs}
             
-        def test_step(self, batch, batch_idx):
-            # OPTIONAL
-            x, y = batch
-            y_hat = self.forward(x)
-            return {'test_loss': F.cross_entropy(y_hat, y)}
-    
-        def test_end(self, outputs):
-            # OPTIONAL
-            avg_loss = torch.stack([x['test_loss'] for x in outputs]).mean()
-            tensorboard_logs = {'test_loss': avg_loss}
-            return {'avg_test_loss': avg_loss, 'log': tensorboard_logs}
-    
-        def configure_optimizers(self):
-            # REQUIRED
-            # can return multiple optimizers and learning_rate schedulers
-            # (LBFGS it is automatically supported, no need for closure function)
-            return torch.optim.Adam(self.parameters(), lr=0.02)
-    
-        @pl.data_loader
-        def train_dataloader(self):
-            # REQUIRED
-            return DataLoader(MNIST(os.getcwd(), train=True, download=True, transform=transforms.ToTensor()), batch_size=32)
-    
-        @pl.data_loader
-        def val_dataloader(self):
-            # OPTIONAL
-            return DataLoader(MNIST(os.getcwd(), train=True, download=True, transform=transforms.ToTensor()), batch_size=32)
-    
-        @pl.data_loader
-        def test_dataloader(self):
-            # OPTIONAL
-            return DataLoader(MNIST(os.getcwd(), train=False, download=True, transform=transforms.ToTensor()), batch_size=32)
-    ```
-2. Fit with a [trainer](https://pytorch-lightning.rtfd.io/en/latest/pytorch_lightning.trainer.html)    
-    ```python
-    from pytorch_lightning import Trainer
-    
-    model = CoolSystem()
-    
-    # most basic trainer, uses good defaults
-    trainer = Trainer()    
-    trainer.fit(model)   
-    ```
-
-Trainer sets up a tensorboard logger, early stopping and checkpointing by default (you can modify all of them or
-use something other than tensorboard).   
-
-Here are more advanced examples
-```python   
-# train on cpu using only 10% of the data (for demo purposes)
-trainer = Trainer(max_epochs=1, train_percent_check=0.1)
-
-# train on 4 gpus (lightning chooses GPUs for you)
-# trainer = Trainer(max_epochs=1, gpus=4, distributed_backend='ddp')  
-
-# train on 4 gpus (you choose GPUs)
-# trainer = Trainer(max_epochs=1, gpus=[0, 1, 3, 7], distributed_backend='ddp')   
+        def training_step(self, batch, batch_idx):
+            ...
+```
 
-# train on 32 gpus across 4 nodes (make sure to submit appropriate SLURM job)
-# trainer = Trainer(max_epochs=1, gpus=8, num_gpu_nodes=4, distributed_backend='ddp')
+2. Fit it with a [Trainer](https://pytorch-lightning.rtfd.io/en/latest/pytorch_lightning.trainer.html)
+ ```python
+ from pytorch_lightning import Trainer
 
-# train (1 epoch only here for demo)
-trainer.fit(model)
+ model = CoolSystem()
 
-# view tensorboard logs 
-logging.info(f'View tensorboard logs by running\ntensorboard --logdir {os.getcwd()}')
-logging.info('and going to http://localhost:6006 on your browser')
-```
-
-When you're all done you can even run the test set separately.   
-```python
-trainer.test()
-```
+ # most basic trainer, uses good defaults
+ trainer = Trainer()    
+ trainer.fit(model)   
+ ```
+ 
+[Check out the COLAB demo here](https://colab.research.google.com/drive/1F_RNcHzTfFuQf-LeKvSlud6x7jXYkG31#scrollTo=HOk9c4_35FKg)
+ 
+## What types of research works?
+Anything! Remember, that this is just organized PyTorch code.
+The Training step defines the core complexity found in the training loop.
 
-**Could be as complex as seq-2-seq + attention**    
+#### Could be as complex as a seq2seq
 
 ```python
 # define what happens for training here
@@ -246,7 +192,7 @@ def training_step(self, batch, batch_idx):
     return {'loss': loss} 
 ```
 
-**Or as basic as CNN image classification**      
+#### Or as basic as CNN image classification     
 
 ```python
 # define what happens for validation here
@@ -259,62 +205,74 @@ def validation_step(self, batch, batch_idx):
     return {'loss': loss} 
 ```
 
-**And you also decide how to collate the output of all validation steps**    
+And without changing a single line of code, you could run on CPUs
+```python   
+trainer = Trainer(max_epochs=1)
+```
+
 
-```python
-def validation_end(self, outputs):
-    """
-    Called at the end of validation to aggregate outputs
-    :param outputs: list of individual outputs of each validation step
-    :return:
-    """
-    val_loss_mean = 0
-    val_acc_mean = 0
-    for output in outputs:
-        val_loss_mean += output['val_loss']
-        val_acc_mean += output['val_acc']
-
-    val_loss_mean /= len(outputs)
-    val_acc_mean /= len(outputs)
-    logs = {'val_loss': val_loss_mean.item(), 'val_acc': val_acc_mean.item()}
-    result = {'log': logs}
-    return result
+Or GPUs
+```python   
+# 8 GPUs
+trainer = Trainer(max_epochs=1, gpus=8)
+
+# 256 GPUs
+trainer = Trainer(max_epochs=1, gpus=8, num_nodes=32)
 ```
-   
-## Tensorboard    
-Lightning is fully integrated with tensorboard, MLFlow and supports any logging module.   
 
-![tensorboard-support](docs/source/_static/images/tf_loss.png)
+Or TPUs
+```python 
+trainer = Trainer(num_tpu_cores=8)
+```
 
-Lightning also adds a text column with all the hyperparameters for this experiment.      
+When you're done training, run the test accuracy
+```python
+trainer.test()
+```
 
-![tensorboard-support](docs/source/_static/images/tf_tags.png)
+## Visualization
+Lightning has out-of-the-box integration with the popular logging/visualizing frameworks
 
-## Lightning automates all of the following ([each is also configurable](https://pytorch-lightning.rtfd.io/en/latest/pytorch_lightning.trainer.html)):
+- Tensorboard
+- MLFlow
+- Neptune.ai
+- Comet.ml
+- ...  
+
+![tensorboard-support](docs/source/_static/images/tf_loss.png)
 
 
-- [Running grid search on a cluster](https://pytorch-lightning.rtfd.io/en/latest/pytorch_lightning.trainer.distrib_data_parallel.html)  
-- [Fast dev run](https://pytorch-lightning.rtfd.io/en/latest/pytorch_lightning.utilities.debugging.html)
-- [Logging](https://pytorch-lightning.rtfd.io/en/latest/pytorch_lightning.loggers.html)
-- [Implement Your Own Distributed (DDP) training](https://pytorch-lightning.rtfd.io/en/latest/pytorch_lightning.core.lightning.html#pytorch_lightning.core.lightning.LightningModule.configure_ddp)
-- [Multi-GPU & Multi-node](https://pytorch-lightning.rtfd.io/en/latest/pytorch_lightning.trainer.distrib_parts.html)
-- [Training loop](https://pytorch-lightning.rtfd.io/en/latest/pytorch_lightning.trainer.training_loop.html)
-- [Hooks](https://pytorch-lightning.rtfd.io/en/latest/pytorch_lightning.core.hooks.html)
-- [Configure optimizers](https://pytorch-lightning.rtfd.io/en/latest/pytorch_lightning.core.lightning.html#pytorch_lightning.core.lightning.LightningModule.configure_optimizers)
-- [Validations](https://pytorch-lightning.rtfd.io/en/latest/pytorch_lightning.trainer.evaluation_loop.html)
-- [Model saving & Restoring training session](https://pytorch-lightning.rtfd.io/en/latest/pytorch_lightning.trainer.training_io.html)
+## Lightning automates 40+ parts of DL/ML research
+- GPU training
+- Distributed GPU (cluster) training
+- TPU training
+- EarlyStopping
+- Logging/Visualizing
+- Checkpointing
+- Experiment management
+- [Full list here](https://pytorch-lightning.readthedocs.io/en/latest/#common-use-cases)
   
 
 ## Examples   
-- [GAN](https://github.com/PytorchLightning/pytorch-lightning/tree/master/pl_examples/domain_templates/gan.py)    
-- [MNIST](https://github.com/PytorchLightning/pytorch-lightning/tree/master/pl_examples/basic_examples)      
-- [Other projects using Lightning](https://github.com/PytorchLightning/pytorch-lightning/network/dependents?package_id=UGFja2FnZS0zNzE3NDU4OTM%3D)    
-- [Multi-node](https://github.com/PytorchLightning/pytorch-lightning/tree/master/pl_examples/multi_node_examples)   
+Check out this awesome list of research papers and implementations done with Lightning. 
+
+- [Contextual Emotion Detection (DoubleDistilBert)](https://github.com/PyTorchLightning/emotion_transformer)
+- [Generative Adversarial Network](https://colab.research.google.com/drive/1F_RNcHzTfFuQf-LeKvSlud6x7jXYkG31#scrollTo=TyYOdg8g77P0)
+- [Hyperparameter optimization with Optuna](https://github.com/optuna/optuna/blob/master/examples/pytorch_lightning_simple.py)
+- [Image Inpainting using Partial Convolutions](https://github.com/ryanwongsa/Image-Inpainting)
+- [MNIST on TPU](https://colab.research.google.com/drive/1-_LKx4HwAxl5M6xPJmqAAu444LTDQoa3#scrollTo=BHBz1_AnamN_)
+- [NER (transformers, TPU, huggingface)](https://colab.research.google.com/drive/1dBN-wwYUngLYVt985wGs_OKPlK_ANB9D)
+- [NeuralTexture (CVPR)](https://github.com/PyTorchLightning/neuraltexture)
+- [Recurrent Attentive Neural Process](https://github.com/PyTorchLightning/attentive-neural-processes)
+- [Siamese Nets for One-shot Image Recognition](https://github.com/PyTorchLightning/Siamese-Neural-Networks)
+- [Speech Transformers](https://github.com/PyTorchLightning/speech-transformer-pytorch_lightning)
+- [Transformers transfer learning (Huggingface)](https://colab.research.google.com/drive/1F_RNcHzTfFuQf-LeKvSlud6x7jXYkG31#scrollTo=yr7eaxkF-djf)
+- [Transformers text classification](https://github.com/ricardorei/lightning-text-classification)
+- [VAE Library of over 18+ VAE flavors](https://github.com/AntixK/PyTorch-VAE)
 
 ## Tutorials   
-- [Basic Lightning use](https://towardsdatascience.com/supercharge-your-ai-research-with-pytorch-lightning-337948a99eec)    
-- [9 key speed features in Pytorch-Lightning](https://towardsdatascience.com/9-tips-for-training-lightning-fast-neural-networks-in-pytorch-8e63a502f565)    
-- [SLURM, multi-node training with Lightning](https://towardsdatascience.com/trivial-multi-node-training-with-pytorch-lightning-ff75dfb809bd)     
+Check out our [introduction guide](https://pytorch-lightning.readthedocs.io/en/latest/introduction_guide.html) to get started.
+Or jump straight into [our tutorials](https://pytorch-lightning.readthedocs.io/en/latest/#tutorials).
 
 ---
 
@@ -323,26 +281,24 @@ Welcome to the Lightning community!
 
 If you have any questions, feel free to:   
 1. [read the docs](https://pytorch-lightning.rtfd.io/en/latest/).     
-2. [Search through the issues](https://github.com/PytorchLightning/pytorch-lightning/issues?utf8=%E2%9C%93&q=my++question).      
+2. [Search through the issues](https://github.com/PytorchLightning/pytorch-lightning/issues?utf8=%E2%9C%93&q=my++question).   
 3. [Ask on stackoverflow](https://stackoverflow.com/questions/ask?guided=false) with the tag pytorch-lightning.   
-
-If no one replies to you quickly enough, feel free to post the stackoverflow link to our Gitter chat!   
-
-To chat with the rest of us visit our [gitter channel](https://gitter.im/PyTorch-Lightning/community)!     
+4. [Join our slack](https://join.slack.com/t/pytorch-lightning/shared_invite/enQtODU5ODIyNTUzODQwLTFkMDg5Mzc1MDBmNjEzMDgxOTVmYTdhYjA1MDdmODUyOTg2OGQ1ZWZkYTQzODhhNzdhZDA3YmNhMDhlMDY4YzQ).
 
 ---   
 ## FAQ    
 **How do I use Lightning for rapid research?**   
-[Here's a walk-through](https://pytorch-lightning.rtfd.io/en/latest/)  
+[Here's a walk-through](https://pytorch-lightning.readthedocs.io/en/latest/introduction_guide.html)  
 
 **Why was Lightning created?**     
 Lightning has 3 goals in mind:
+
 1. Maximal flexibility while abstracting out the common boilerplate across research projects.   
 2. Reproducibility. If all projects use the LightningModule template, it will be much much easier to understand what's going on and where to look! It will also mean every implementation follows a standard format.   
 3. Democratizing PyTorch power user features. Distributed training? 16-bit? know you need them but don't want to take the time to implement? All good... these come built into Lightning.    
 
 **How does Lightning compare with Ignite and fast.ai?**     
-[Here's a thorough comparison](https://medium.com/@_willfalcon/pytorch-lightning-vs-pytorch-ignite-vs-fast-ai-61dc7480ad8a).    
+[Here's a thorough comparison](https://medium.com/@_willfalcon/pytorch-lightning-vs-pytorch-ignite-vs-fast-ai-61dc7480ad8a).   
 
 **Is this another library I have to learn?**    
 Nope! We use pure Pytorch everywhere and don't add unecessary abstractions!   
@@ -392,13 +348,14 @@ pip install https://github.com/PytorchLightning/pytorch-lightning/archive/0.X.Y.
 
 #### Leads
 - William Falcon [(williamFalcon)](https://github.com/williamFalcon) (Lightning founder)
-- Jirka Borovec [(Borda)](https://github.com/Borda)
+- Jirka Borovec [(Borda)](https://github.com/Borda) (-_-)
 - Ethan Harris [(ethanwharris)](https://github.com/ethanwharris) (Torchbearer founder)
 - Matthew Painter [(MattPainter01)](https://github.com/MattPainter01) (Torchbearer founder)
 
 #### Core Maintainers
 
 - Nick Eggert [(neggert)](https://github.com/neggert)
+- Jeremy Jordan [(jeremyjordan)](https://github.com/jeremyjordan)
 - Jeff Ling [(jeffling)](https://github.com/jeffling)
 - Tullie Murrell [(tullie)](https://github.com/tullie)
 
diff --git a/docs/source/_images/lightning_module/pt_to_pl.png b/docs/source/_images/lightning_module/pt_to_pl.png
new file mode 100644
index 0000000..8b35bee
Binary files /dev/null and b/docs/source/_images/lightning_module/pt_to_pl.png differ
diff --git a/docs/source/_images/lightning_module/pt_trainer.png b/docs/source/_images/lightning_module/pt_trainer.png
new file mode 100644
index 0000000..a6c5d5e
Binary files /dev/null and b/docs/source/_images/lightning_module/pt_trainer.png differ
diff --git a/docs/source/_images/mnist_imgs/mnist_cpu_bar.png b/docs/source/_images/mnist_imgs/mnist_cpu_bar.png
new file mode 100644
index 0000000..fa896ea
Binary files /dev/null and b/docs/source/_images/mnist_imgs/mnist_cpu_bar.png differ
diff --git a/docs/source/_images/mnist_imgs/mnist_gpu.png b/docs/source/_images/mnist_imgs/mnist_gpu.png
new file mode 100644
index 0000000..75021ce
Binary files /dev/null and b/docs/source/_images/mnist_imgs/mnist_gpu.png differ
diff --git a/docs/source/_images/mnist_imgs/mnist_tb.png b/docs/source/_images/mnist_imgs/mnist_tb.png
new file mode 100644
index 0000000..a8cf719
Binary files /dev/null and b/docs/source/_images/mnist_imgs/mnist_tb.png differ
diff --git a/docs/source/_images/mnist_imgs/pt_to_pl.jpg b/docs/source/_images/mnist_imgs/pt_to_pl.jpg
new file mode 100644
index 0000000..4bad788
Binary files /dev/null and b/docs/source/_images/mnist_imgs/pt_to_pl.jpg differ
diff --git a/docs/source/_images/mnist_imgs/restart_runtime.png b/docs/source/_images/mnist_imgs/restart_runtime.png
new file mode 100644
index 0000000..84ccae4
Binary files /dev/null and b/docs/source/_images/mnist_imgs/restart_runtime.png differ
diff --git a/docs/source/_images/mnist_imgs/runtime_tpu.png b/docs/source/_images/mnist_imgs/runtime_tpu.png
new file mode 100644
index 0000000..9dc069a
Binary files /dev/null and b/docs/source/_images/mnist_imgs/runtime_tpu.png differ
diff --git a/docs/source/_images/mnist_imgs/tpu_fast.png b/docs/source/_images/mnist_imgs/tpu_fast.png
new file mode 100644
index 0000000..08d9f9a
Binary files /dev/null and b/docs/source/_images/mnist_imgs/tpu_fast.png differ
diff --git a/docs/source/_images/mnist_imgs/tpu_start.png b/docs/source/_images/mnist_imgs/tpu_start.png
new file mode 100644
index 0000000..3474f68
Binary files /dev/null and b/docs/source/_images/mnist_imgs/tpu_start.png differ
diff --git a/docs/source/callbacks.rst b/docs/source/callbacks.rst
index cfeaa81..6301212 100644
--- a/docs/source/callbacks.rst
+++ b/docs/source/callbacks.rst
@@ -3,12 +3,74 @@
 
 Callbacks
 =========
-.. automodule:: pytorch_lightning.callbacks
+
+Lightning has a callback system to execute arbitrary code. Callbacks should capture NON-ESSENTIAL
+logic that is NOT required for your LightningModule to run.
+
+An overall Lightning system should have:
+
+1. Trainer for all engineering
+2. LightningModule for all research code.
+3. Callbacks for non-essential code.
+
+Example
+
+.. code-block:: python
+
+    import pytorch_lightning as pl
+
+    class MyPrintingCallback(pl.Callback):
+
+        def on_init_start(self, trainer):
+            print('Starting to init trainer!')
+
+        def on_init_end(self, trainer):
+            print('trainer is init now')
+
+        def on_train_end(self, trainer, pl_module):
+            print('do something when training ends')
+
+    # pass to trainer
+    trainer = pl.Trainer(callbacks=[MyPrintingCallback()])
+
+We successfully extended functionality without polluting our super clean LightningModule research code
+
+---------
+
+.. automodule:: pytorch_lightning.callbacks.base
+   :noindex:
+   :exclude-members:
+        _del_model,
+        _save_model,
+        _abc_impl,
+        check_monitor_top_k,
+
+---------
+
+.. automodule:: pytorch_lightning.callbacks.early_stopping
+   :noindex:
+   :exclude-members:
+        _del_model,
+        _save_model,
+        _abc_impl,
+        check_monitor_top_k,
+
+---------
+
+.. automodule:: pytorch_lightning.callbacks.model_checkpoint
+   :noindex:
+   :exclude-members:
+        _del_model,
+        _save_model,
+        _abc_impl,
+        check_monitor_top_k,
+
+---------
+
+.. automodule:: pytorch_lightning.callbacks.gradient_accumulation_scheduler
+   :noindex:
    :exclude-members:
         _del_model,
         _save_model,
-        on_epoch_end,
-        on_train_end,
-        on_epoch_begin,
+        _abc_impl,
         check_monitor_top_k,
-        on_train_begin,
\ No newline at end of file
diff --git a/docs/source/checkpointing.rst b/docs/source/checkpointing.rst
deleted file mode 100644
index 318d95d..0000000
--- a/docs/source/checkpointing.rst
+++ /dev/null
@@ -1,80 +0,0 @@
-Checkpointing
-==============
-
-.. _model-saving:
-
-Model saving
--------------------
-To save a LightningModule, provide a :meth:`pytorch_lightning.callbacks.ModelCheckpoint` callback.
-
-The Lightning checkpoint also saves the hparams (hyperparams) passed into the LightningModule init.
-
-.. note:: hparams is a `Namespace <https://docs.python.org/2/library/argparse.html#argparse.Namespace>`_ or dictionary.
-
-.. code-block:: python
-   :emphasize-lines: 8
-
-   from argparse import Namespace
-
-   # usually these come from command line args
-   args = Namespace(**{'learning_rate':0.001})
-
-   # define you module to have hparams as the first arg
-   # this means your checkpoint will have everything that went into making
-   # this model (in this case, learning rate)
-   class MyLightningModule(pl.LightningModule):
-
-       def __init__(self, hparams, ...):
-           self.hparams = hparams
-
-   my_model = MyLightningModule(args)
-
-   # auto-saves checkpoint
-   checkpoint_callback = ModelCheckpoint(filepath='my_path')
-   Trainer(checkpoint_callback=checkpoint_callback)
-
-
-Model loading
------------------------------------
-
-To load a model, use :meth:`pytorch_lightning.core.LightningModule.load_from_checkpoint`
-
-.. note:: If lightning created your checkpoint, your model will receive all the hyperparameters used
-   to create the checkpoint. (See: :ref:`model-saving`).
-
-.. code-block:: python
-
-    # load weights without mapping
-    MyLightningModule.load_from_checkpoint('path/to/checkpoint.ckpt')
-
-    # load weights mapping all weights from GPU 1 to GPU 0
-    map_location = {'cuda:1':'cuda:0'}
-    MyLightningModule.load_from_checkpoint('path/to/checkpoint.ckpt', map_location=map_location)
-
-Restoring training session
------------------------------------
-
-If you want to pick up training from where you left off, you have a few options.
-
-1. Pass in a logger with the same experiment version to continue training.
-
-.. code-block:: python
-
-   # train the first time and set the version number
-   logger = TensorboardLogger(version=10)
-   trainer = Trainer(logger=logger)
-   trainer.fit(model)
-
-   # when you init another logger with that same version, the model
-   # will continue where it left off
-   logger = TensorboardLogger(version=10)
-   trainer = Trainer(logger=logger)
-   trainer.fit(model)
-
-2. A second option is to pass in a path to a checkpoint (see: :ref:`pytorch_lightning.trainer`).
-
-.. code-block:: python
-
-   # train the first time and set the version number
-   trainer = Trainer(resume_from_checkpoint='some/path/to/my_checkpoint.ckpt')
-   trainer.fit(model)
\ No newline at end of file
diff --git a/docs/source/child_modules.rst b/docs/source/child_modules.rst
new file mode 100644
index 0000000..6ea0c59
--- /dev/null
+++ b/docs/source/child_modules.rst
@@ -0,0 +1,62 @@
+Child Modules
+-------------
+Research projects tend to test different approaches to the same dataset.
+This is very easy to do in Lightning with inheritance.
+
+For example, imagine we now want to train an Autoencoder to use as a feature extractor for MNIST images.
+Recall that `LitMNIST` already defines all the dataloading etc... The only things
+that change in the `Autoencoder` model are the init, forward, training, validation and test step.
+
+.. code-block:: python
+
+    class Encoder(torch.nn.Module):
+        ...
+
+    class AutoEncoder(LitMNIST):
+        def __init__(self):
+            self.encoder = Encoder()
+            self.decoder = Decoder()
+
+        def forward(self, x):
+            generated = self.decoder(x)
+
+        def training_step(self, batch, batch_idx):
+            x, _ = batch
+
+            representation = self.encoder(x)
+            x_hat = self.forward(representation)
+
+            loss = MSE(x, x_hat)
+            return loss
+
+        def validation_step(self, batch, batch_idx):
+            return self._shared_eval(batch, batch_idx, 'val'):
+
+        def test_step(self, batch, batch_idx):
+            return self._shared_eval(batch, batch_idx, 'test'):
+
+        def _shared_eval(self, batch, batch_idx, prefix):
+            x, y = batch
+            representation = self.encoder(x)
+            x_hat = self.forward(representation)
+
+            loss = F.nll_loss(logits, y)
+            return {f'{prefix}_loss': loss}
+
+and we can train this using the same trainer
+
+.. code-block:: python
+
+    autoencoder = AutoEncoder()
+    trainer = Trainer()
+    trainer.fit(autoencoder)
+
+And remember that the forward method is to define the practical use of a LightningModule.
+In this case, we want to use the `AutoEncoder` to extract image representations
+
+.. code-block:: python
+
+    some_images = torch.Tensor(32, 1, 28, 28)
+    representations = autoencoder(some_images)
+
+..
\ No newline at end of file
diff --git a/docs/source/conf.py b/docs/source/conf.py
index ddccd79..d1c0b54 100644
--- a/docs/source/conf.py
+++ b/docs/source/conf.py
@@ -354,11 +354,13 @@ autoclass_content = 'both'
 #  see https://github.com/sphinx-doc/sphinx/issues/5459
 autodoc_default_options = {
     'members': None,
+    'methods': None,
+    # 'attributes': None,
     'special-members': '__call__',
-    'undoc-members': True,
     # 'exclude-members': '__weakref__',
     'show-inheritance': True,
     'private-members': True,
+    'noindex': True,
 }
 
 # Sphinx will add “permalinks” for each heading and description environment as paragraph signs that
diff --git a/docs/source/early_stopping.rst b/docs/source/early_stopping.rst
index f0d6de0..ce288d3 100644
--- a/docs/source/early_stopping.rst
+++ b/docs/source/early_stopping.rst
@@ -4,7 +4,7 @@ Early stopping
 Default behavior
 ----------------
 By default early stopping will be enabled if `'val_loss'`
-is found in `validation_end()` return dict. Otherwise
+is found in `validation_epoch_end()` return dict. Otherwise
 training will proceed with early stopping disabled.
 
 Enable Early Stopping
@@ -16,7 +16,7 @@ There are two ways to enable early stopping.
 .. code-block:: python
 
     # A) Set early_stop_callback to True. Will look for 'val_loss'
-    # in validation_end() return dict. If it is not found an error is raised.
+    # in validation_epoch_end() return dict. If it is not found an error is raised.
     trainer = Trainer(early_stop_callback=True)
 
     # B) Or configure your own callback
diff --git a/docs/source/examples.rst b/docs/source/examples.rst
index c83c3ff..01339f0 100644
--- a/docs/source/examples.rst
+++ b/docs/source/examples.rst
@@ -1,34 +1,18 @@
-GAN
-===
 .. toctree::
-   :maxdepth: 3
-
-   pl_examples.domain_templates.gan
-
-MNIST
-=====
-.. toctree::
-   :maxdepth: 3
-
-   pl_examples.basic_examples.lightning_module_template
-
-Multi-node (ddp) MNIST
-======================
-.. toctree::
-   :maxdepth: 3
-
-   pl_examples.multi_node_examples.multi_node_ddp_demo
-
-Multi-node (ddp2) MNIST
-=======================
-.. toctree::
-   :maxdepth: 3
-
-   pl_examples.multi_node_examples.multi_node_ddp2_demo
-
-Imagenet
-========
-.. toctree::
-   :maxdepth: 3
-
-   pl_examples.full_examples.imagenet.imagenet_example
+   :maxdepth: 1
+   :name: Community Examples
+   :caption: Community Examples
+
+    Contextual Emotion Detection (DoubleDistilBert) <https://github.com/PyTorchLightning/emotion_transformer>
+    Generative Adversarial Network <https://colab.research.google.com/drive/1F_RNcHzTfFuQf-LeKvSlud6x7jXYkG31#scrollTo=TyYOdg8g77P0>
+    Hyperparameter optimization with Optuna <https://github.com/optuna/optuna/blob/master/examples/pytorch_lightning_simple.py>
+    Image Inpainting using Partial Convolutions <https://github.com/ryanwongsa/Image-Inpainting>
+    MNIST on TPU <https://colab.research.google.com/drive/1-_LKx4HwAxl5M6xPJmqAAu444LTDQoa3#scrollTo=BHBz1_AnamN_>
+    NER (transformers, TPU) <https://colab.research.google.com/drive/1dBN-wwYUngLYVt985wGs_OKPlK_ANB9D>
+    NeuralTexture (CVPR) <https://github.com/PyTorchLightning/neuraltexture>
+    Recurrent Attentive Neural Process <https://github.com/PyTorchLightning/attentive-neural-processes>
+    Siamese Nets for One-shot Image Recognition <https://github.com/PyTorchLightning/Siamese-Neural-Networks>
+    Speech Transformers <https://github.com/PyTorchLightning/speech-transformer-pytorch_lightning>
+    Transformers transfer learning (Huggingface) <https://colab.research.google.com/drive/1F_RNcHzTfFuQf-LeKvSlud6x7jXYkG31#scrollTo=yr7eaxkF-djf>
+    Transformers text classification <https://github.com/ricardorei/lightning-text-classification>
+    VAE Library of over 18+ VAE flavors <https://github.com/AntixK/PyTorch-VAE>
diff --git a/docs/source/experiment_logging.rst b/docs/source/experiment_logging.rst
index 853f250..1edd067 100644
--- a/docs/source/experiment_logging.rst
+++ b/docs/source/experiment_logging.rst
@@ -11,7 +11,7 @@ To use CometLogger as your logger do the following.
 
 .. code-block:: python
 
-   from pytorch_lightning.loggers import TestTubeLogger
+   from pytorch_lightning.loggers import CometLogger
 
     comet_logger = CometLogger(
         api_key=os.environ["COMET_KEY"],
@@ -22,13 +22,13 @@ To use CometLogger as your logger do the following.
     )
    trainer = Trainer(logger=comet_logger)
 
-The CometLogger is available anywhere in your LightningModule
+The CometLogger is available anywhere except ``__init__`` in your LightningModule
 
 .. code-block:: python
 
    class MyModule(pl.LightningModule):
 
-      def __init__(self, ...):
+      def any_lightning_module_function_or_hook(self, ...):
          some_img = fake_image()
          self.logger.experiment.add_image('generated_images', some_img, 0)
 
@@ -52,13 +52,13 @@ To use Neptune.ai as your logger do the following.
     )
    trainer = Trainer(logger=neptune_logger)
 
-The Neptune.ai is available anywhere in your LightningModule
+The Neptune.ai is available anywhere except ``__init__`` in your LightningModule
 
 .. code-block:: python
 
    class MyModule(pl.LightningModule):
 
-      def __init__(self, ...):
+      def any_lightning_module_function_or_hook(self, ...):
          some_img = fake_image()
          self.logger.experiment.add_image('generated_images', some_img, 0)
 
@@ -76,13 +76,13 @@ To use `Tensorboard <https://pytorch.org/docs/stable/tensorboard.html>`_ as your
    logger = TensorBoardLogger("tb_logs", name="my_model")
    trainer = Trainer(logger=logger)
 
-The TensorBoardLogger is available anywhere in your LightningModule
+The TensorBoardLogger is available anywhere except ``__init__`` in your LightningModule
 
 .. code-block:: python
 
    class MyModule(pl.LightningModule):
 
-      def __init__(self, ...):
+      def any_lightning_module_function_or_hook(self, ...):
          some_img = fake_image()
          self.logger.experiment.add_image('generated_images', some_img, 0)
 
@@ -102,13 +102,13 @@ To use TestTube as your logger do the following.
    logger = TestTubeLogger("tb_logs", name="my_model")
    trainer = Trainer(logger=logger)
 
-The TestTubeLogger is available anywhere in your LightningModule
+The TestTubeLogger is available anywhere except ``__init__`` in your LightningModule
 
 .. code-block:: python
 
    class MyModule(pl.LightningModule):
 
-      def __init__(self, ...):
+      def any_lightning_module_function_or_hook(self, ...):
          some_img = fake_image()
          self.logger.experiment.add_image('generated_images', some_img, 0)
 
@@ -127,13 +127,41 @@ To use Wandb as your logger do the following.
    wandb_logger = WandbLogger()
    trainer = Trainer(logger=wandb_logger)
 
-The Wandb logger is available anywhere in your LightningModule
+The Wandb logger is available anywhere except ``__init__`` in your LightningModule
 
 .. code-block:: python
 
    class MyModule(pl.LightningModule):
 
-      def __init__(self, ...):
+      def any_lightning_module_function_or_hook(self, ...):
          some_img = fake_image()
          self.logger.experiment.add_image('generated_images', some_img, 0)
 
+
+Multiple Loggers
+^^^^^^^^^^^^^^^^^
+
+PyTorch-Lightning supports use of multiple loggers, just pass a list to the `Trainer`.
+
+.. code-block:: python
+
+   from pytorch_lightning.loggers import TensorBoardLogger, TestTubeLogger
+   
+   logger1 = TensorBoardLogger("tb_logs", name="my_model")
+   logger2 = TestTubeLogger("tt_logs", name="my_model")
+   trainer = Trainer(logger=[logger1, logger2])
+   
+The loggers are available as a list anywhere except ``__init__`` in your LightningModule
+
+.. code-block:: python
+
+   class MyModule(pl.LightningModule):
+
+      def any_lightning_module_function_or_hook(self, ...):
+         some_img = fake_image()
+
+         # Option 1
+         self.logger.experiment[0].add_image('generated_images', some_img, 0)
+
+         # Option 2
+         self.logger[0].experiment.add_image('generated_images', some_img, 0)
diff --git a/docs/source/experiment_reporting.rst b/docs/source/experiment_reporting.rst
index 58a865d..a738a23 100644
--- a/docs/source/experiment_reporting.rst
+++ b/docs/source/experiment_reporting.rst
@@ -34,11 +34,11 @@ Log metrics
 
 To plot metrics into whatever logger you passed in (tensorboard, comet, neptune, etc...)
 
-1. Training_end, validation_end, test_end will all log anything in the "log" key of the return dict.
+1. training_epoch_end, validation_epoch_end, test_epoch_end will all log anything in the "log" key of the return dict.
 
 .. code-block:: python
 
-   def training_end(self, outputs):
+   def training_epoch_end(self, outputs):
       loss = some_loss()
       ...
 
@@ -46,7 +46,7 @@ To plot metrics into whatever logger you passed in (tensorboard, comet, neptune,
       results = {'log': logs}
       return results
 
-   def validation_end(self, outputs):
+   def validation_epoch_end(self, outputs):
       loss = some_loss()
       ...
 
@@ -54,7 +54,7 @@ To plot metrics into whatever logger you passed in (tensorboard, comet, neptune,
       results = {'log': logs}
       return results
 
-   def test_end(self, outputs):
+   def test_epoch_end(self, outputs):
       loss = some_loss()
       ...
 
@@ -62,19 +62,7 @@ To plot metrics into whatever logger you passed in (tensorboard, comet, neptune,
       results = {'log': logs}
       return results
 
-2. Most of the time, you only need training_step and not training_end. You can also return logs from here:
-
-.. code-block:: python
-
-   def training_step(self, batch, batch_idx):
-      loss = some_loss()
-      ...
-
-      logs = {'train_loss': loss}
-      results = {'log': logs}
-      return results
-
-3. In addition, you can also use any arbitrary functionality from a particular logger from within your LightningModule.
+2. In addition, you can also use any arbitrary functionality from a particular logger from within your LightningModule.
 For instance, here we log images using tensorboard.
 
 .. code-block:: python
@@ -99,7 +87,7 @@ Here we show the validation loss in the progress bar
 
 .. code-block:: python
 
-   def validation_end(self, outputs):
+   def validation_epoch_end(self, outputs):
       loss = some_loss()
       ...
 
diff --git a/docs/source/governance.rst b/docs/source/governance.rst
index e4b9ff3..ad0d41e 100644
--- a/docs/source/governance.rst
+++ b/docs/source/governance.rst
@@ -4,12 +4,12 @@ Pytorch Lightning Governance | Persons of interest
 Leads
 -----
 - William Falcon (`williamFalcon <https://github.com/williamFalcon>`_) (Lightning founder)
-- Jirka Borovek (`Borda <https://github.com/Borda>`_)
+- Jirka Borovec (`Borda <https://github.com/Borda>`_)
 - Ethan Harris (`ethanwharris <https://github.com/ethanwharris>`_) (Torchbearer founder)
 - Matthew Painter (`MattPainter01 <https://github.com/MattPainter01>`_) (Torchbearer founder)
 
 Core Maintainers
 ----------------
-- Nick Eggert (`neggert <https://github.com/neggert>`_)
+- Nic Eggert (`neggert <https://github.com/neggert>`_)
 - Jeff Ling (`jeffling <https://github.com/jeffling>`_)
 - Tullie Murrell (`tullie <https://github.com/tullie>`_)
diff --git a/docs/source/hooks.rst b/docs/source/hooks.rst
index fee74ea..8e98808 100644
--- a/docs/source/hooks.rst
+++ b/docs/source/hooks.rst
@@ -1,27 +1,32 @@
 Hooks
-=======
-This is the order in which lightning calls the hooks. You can override each for custom behavior.
+=====
+
+.. automodule:: pytorch_lightning.core.hooks
+
+Hooks lifecycle
+---------------
 
 Training set-up
---------------------
+^^^^^^^^^^^^^^^
+
 - init_ddp_connection
 - init_optimizers
 - configure_apex
 - configure_ddp
-- get_train_dataloader
-- get_test_dataloaders
-- get_val_dataloaders
+- train_dataloader
+- test_dataloaders
+- val_dataloaders
 - summarize
 - restore_weights
 
 Training loop
---------------------
+^^^^^^^^^^^^^
 
 - on_epoch_start
 - on_batch_start
 - tbptt_split_batch
 - training_step
-- training_end (optional)
+- training_step_end (optional)
 - backward
 - on_after_backward
 - optimizer.step()
@@ -29,7 +34,7 @@ Training loop
 - on_epoch_end
 
 Validation loop
---------------------
+^^^^^^^^^^^^^^^
 
 - model.zero_grad()
 - model.eval()
@@ -41,7 +46,7 @@ Validation loop
 - on_post_performance_check
 
 Test loop
-------------
+^^^^^^^^^
 
 - model.zero_grad()
 - model.eval()
diff --git a/docs/source/hyperparameters.rst b/docs/source/hyperparameters.rst
new file mode 100644
index 0000000..ea58b9e
--- /dev/null
+++ b/docs/source/hyperparameters.rst
@@ -0,0 +1,211 @@
+Hyperparameters
+---------------
+Lightning has utilities to interact seamlessly with the command line ArgumentParser
+and plays well with the hyperparameter optimization framework of your choice.
+
+LightiningModule hparams
+^^^^^^^^^^^^^^^^^^^^^^^^
+
+Normally, we don't hard-code the values to a model. We usually use the command line to
+modify the network. The `Trainer` can add all the available options to an ArgumentParser.
+
+.. code-block:: python
+
+    from argparse import ArgumentParser
+
+    parser = ArgumentParser()
+
+    # parametrize the network
+    parser.add_argument('--layer_1_dim', type=int, default=128)
+    parser.add_argument('--layer_2_dim', type=int, default=256)
+    parser.add_argument('--batch_size', type=int, default=64)
+
+    # add all the available options to the trainer
+    parser = pl.Trainer.add_argparse_args(parser)
+
+    args = parser.parse_args()
+
+Now we can parametrize the LightningModule.
+
+.. code-block:: python
+    :emphasize-lines: 5,6,7,12,14
+
+    class LitMNIST(pl.LightningModule):
+      def __init__(self, hparams):
+        super(LitMNIST, self).__init__()
+        self.hparams = hparams
+
+        self.layer_1 = torch.nn.Linear(28 * 28, hparams.layer_1_dim)
+        self.layer_2 = torch.nn.Linear(hparams.layer_1_dim, hparams.layer_2_dim)
+        self.layer_3 = torch.nn.Linear(hparams.layer_2_dim, 10)
+
+      def forward(self, x):
+        ...
+
+      def train_dataloader(self):
+        ...
+        return DataLoader(mnist_train, batch_size=self.hparams.batch_size)
+
+      def configure_optimizers(self):
+        return Adam(self.parameters(), lr=self.hparams.learning_rate)
+
+    hparams = parse_args()
+    model = LitMNIST(hparams)
+
+.. note:: Bonus! if (hparams) is in your module, Lightning will save it into the checkpoint and restore your
+    model using those hparams exactly.
+
+And we can also add all the flags available in the Trainer to the Argparser.
+
+.. code-block:: python
+
+    # add all the available Trainer options to the ArgParser
+    parser = pl.Trainer.add_argparse_args(parser)
+    args = parser.parse_args()
+
+And now you can start your program with
+
+.. code-block:: bash
+
+    # now you can use any trainer flag
+    $ python main.py --num_nodes 2 --gpus 8
+
+Trainer args
+^^^^^^^^^^^^
+
+It also gets annoying to map each argument into the Argparser. Luckily we have
+a default parser
+
+.. code-block:: python
+
+    parser = ArgumentParser()
+
+    # add all options available in the trainer such as (max_epochs, etc...)
+    parser = Trainer.add_argparse_args(parser)
+
+We set up the main training entry point file like this:
+
+.. code-block:: python
+
+    def main(args):
+        model = LitMNIST(hparams=args)
+        trainer = Trainer(max_epochs=args.max_epochs)
+        trainer.fit(model)
+
+    if __name__ == '__main__':
+        parser = ArgumentParser()
+
+        # adds all the trainer options as default arguments (like max_epochs)
+        parser = Trainer.add_argparse_args(parser)
+
+        # parametrize the network
+        parser.add_argument('--layer_1_dim', type=int, default=128)
+        parser.add_argument('--layer_1_dim', type=int, default=256)
+        parser.add_argument('--batch_size', type=int, default=64)
+        args = parser.parse_args()
+
+        # train
+        main(args)
+
+And now we can train like this:
+
+.. code-block:: bash
+
+    $ python main.py --layer_1_dim 128 --layer_2_dim 256 --batch_size 64 --max_epochs 64
+
+But it would also be nice to pass in any arbitrary argument to the trainer.
+We can do it by changing how we init the trainer.
+
+.. code-block:: python
+
+    def main(args):
+        model = LitMNIST(hparams=args)
+
+        # makes all trainer options available from the command line
+        trainer = Trainer.from_argparse_args(args)
+
+and now we can do this:
+
+.. code-block:: bash
+
+    $ python main.py --gpus 1 --min_epochs 12 --max_epochs 64 --arbitrary_trainer_arg some_value
+
+Multiple Lightning Modules
+^^^^^^^^^^^^^^^^^^^^^^^^^^
+
+We often have multiple Lightning Modules where each one has different arguments. Instead of
+polluting the main.py file, the LightningModule lets you define arguments for each one.
+
+.. code-block:: python
+
+    class LitMNIST(pl.LightningModule):
+      def __init__(self, hparams):
+        super(LitMNIST, self).__init__()
+        self.layer_1 = torch.nn.Linear(28 * 28, hparams.layer_1_dim)
+
+        @staticmethod
+        def add_model_specific_args(parent_parser):
+            parser = ArgumentParser(parents=[parent_parser])
+            parser.add_argument('--layer_1_dim', type=int, default=128)
+            return parser
+
+    class GoodGAN(pl.LightningModule):
+      def __init__(self, hparams):
+        super(GoodGAN, self).__init__()
+        self.encoder = Encoder(layers=hparams.encoder_layers)
+
+        @staticmethod
+        def add_model_specific_args(parent_parser):
+            parser = ArgumentParser(parents=[parent_parser])
+            parser.add_argument('--encoder_layers', type=int, default=12)
+            return parser
+
+Now we can allow each model to inject the arguments it needs in the main.py
+
+.. code-block:: python
+
+    def main(args):
+
+        # pick model
+        if args.model_name == 'gan':
+            model = GoodGAN(hparams=args)
+        elif args.model_name == 'mnist':
+            model = LitMNIST(hparams=args)
+
+        model = LitMNIST(hparams=args)
+        trainer = Trainer(max_epochs=args.max_epochs)
+        trainer.fit(model)
+
+    if __name__ == '__main__':
+        parser = ArgumentParser()
+        parser = Trainer.add_argparse_args(parser)
+
+        # figure out which model to use
+        parser.add_argument('--model_name', type=str, default='gan', help='gan or mnist')
+        temp_args = parser.parse_known_args()
+
+        # let the model add what it wants
+        if temp_args.model_name == 'gan':
+            parser = GoodGAN.add_model_specific_args(parser)
+        elif temp_args.model_name == 'mnist':
+            parser = LitMNIST.add_model_specific_args(parser)
+
+        args = parser.parse_args()
+
+        # train
+        main(args)
+
+and now we can train MNIST or the gan using the command line interface!
+
+.. code-block:: bash
+
+    $ python main.py --model_name gan --encoder_layers 24
+    $ python main.py --model_name mnist --layer_1_dim 128
+
+Hyperparameter Optimization
+^^^^^^^^^^^^^^^^^^^^^^^^^^^
+Lightning is fully compatible with the hyperparameter optimization libraries!
+Here are some useful ones:
+
+- `Hydra <https://medium.com/pytorch/hydra-a-fresh-look-at-configuration-for-machine-learning-projects-50583186b710>`_
+- `Optuna <https://github.com/optuna/optuna/blob/master/examples/pytorch_lightning_simple.py>`_
diff --git a/docs/source/index.rst b/docs/source/index.rst
index 3232e74..f1eee28 100644
--- a/docs/source/index.rst
+++ b/docs/source/index.rst
@@ -3,7 +3,7 @@
    You can adapt this file completely to your liking, but it should at least
    contain the root `toctree` directive.
 
-PyTorch-Lightning Documentation
+PyTorch Lightning Documentation
 ===============================
 
 .. toctree::
@@ -11,22 +11,24 @@ PyTorch-Lightning Documentation
    :name: start
    :caption: Start Here
 
-   new-project
+   introduction_guide
 
 .. toctree::
-   :maxdepth: 4
+   :maxdepth: 2
    :name: docs
    :caption: Python API
 
    callbacks
+   hooks
    lightning-module
    loggers
    trainer
 
+
 .. toctree::
    :maxdepth: 1
-   :name: Examples
-   :caption: Examples
+   :name: Community Examples
+   :caption: Community Examples
 
    examples
 
@@ -35,7 +37,7 @@ PyTorch-Lightning Documentation
    :name: Tutorials
    :caption: Tutorials
 
-   tutorials
+   From PyTorch to PyTorch Lightning <https://towardsdatascience.com/from-pytorch-to-pytorch-lightning-a-gentle-introduction-b371b7caaf09>
 
 .. toctree::
    :maxdepth: 1
@@ -43,22 +45,25 @@ PyTorch-Lightning Documentation
    :caption: Common Use Cases
 
    apex
-   checkpointing
    slurm
+   child_modules
    debugging
    experiment_logging
    experiment_reporting
    early_stopping
    fast_training
    hooks
+   hyperparameters
    multi_gpu
+   weights_loading
+   optimizers
+   profiler
    single_gpu
    sequences
    training_tricks
+   transfer_learning
    tpu
    test_set
-   optimizers
-   profiler
 
 .. toctree::
    :maxdepth: 1
@@ -69,6 +74,7 @@ PyTorch-Lightning Documentation
    CODE_OF_CONDUCT.md
    CONTRIBUTING.md
    BECOMING_A_CORE_CONTRIBUTOR.md
+   PULL_REQUEST_TEMPLATE.md
    governance.md
 
 Indices and tables
diff --git a/docs/source/introduction_guide.rst b/docs/source/introduction_guide.rst
new file mode 100644
index 0000000..b048c07
--- /dev/null
+++ b/docs/source/introduction_guide.rst
@@ -0,0 +1,993 @@
+Introduction Guide
+==================
+PyTorch Lightning provides a very simple template for organizing your PyTorch code. Once
+you've organized it into a LightningModule, it automates most of the training for you.
+
+To illustrate, here's the typical PyTorch project structure organized in a LightningModule.
+
+.. figure:: /_images/mnist_imgs/pt_to_pl.jpg
+   :alt: Convert from PyTorch to Lightning
+
+As your project grows in complexity with things like 16-bit precision, distributed training, etc... the part in blue
+quickly becomes onerous and starts distracting from the core research code.
+
+---------
+
+Goal of this guide
+------------------
+This guide walks through the major parts of the library to help you understand
+what each parts does. But at the end of the day, you write the same PyTorch code... just organize it
+into the LightningModule template which means you keep ALL the flexibility without having to deal with
+any of the boilerplate code
+
+To show how Lightning works, we'll start with an MNIST classifier. We'll end showing how
+to use inheritance to very quickly create an AutoEncoder.
+
+.. note:: Any DL/ML PyTorch project fits into the Lightning structure. Here we just focus on 3 types
+    of research to illustrate.
+
+---------
+
+Lightning Philosophy
+--------------------
+Lightning factors DL/ML code into three types:
+
+- Research code
+- Engineering code
+- Non-essential code
+
+Research code
+^^^^^^^^^^^^^
+In the MNIST generation example, the research code would be the particular system and how it's trained (ie: A GAN or VAE).
+In Lightning, this code is abstracted out by the `LightningModule`.
+
+.. code-block:: python
+
+    l1 = nn.Linear(...)
+    l2 = nn.Linear(...)
+    decoder = Decoder()
+
+    x1 = l1(x)
+    x2 = l2(x2)
+    out = decoder(features, x)
+
+    loss = perceptual_loss(x1, x2, x) + CE(out, x)
+
+Engineering code
+^^^^^^^^^^^^^^^^
+
+The Engineering code is all the code related to training this system. Things such as early stopping, distribution
+over GPUs, 16-bit precision, etc. This is normally code that is THE SAME across most projects.
+
+In Lightning, this code is abstracted out by the `Trainer`.
+
+.. code-block:: python
+
+    model.cuda(0)
+    x = x.cuda(0)
+
+    distributed = DistributedParallel(model)
+
+    with gpu_zero:
+        download_data()
+
+    dist.barrier()
+
+Non-essential code
+^^^^^^^^^^^^^^^^^^
+This is code that helps the research but isn't relevant to the research code. Some examples might be:
+1. Inspect gradients
+2. Log to tensorboard.
+
+In Lightning this code is abstracted out by `Callbacks`.
+
+.. code-block:: python
+
+    # log samples
+    z = Q.rsample()
+    generated = decoder(z)
+    self.experiment.log('images', generated)
+
+---------
+
+Elements of a research project
+------------------------------
+Every research project requires the same core ingredients:
+
+1. A model
+2. Train/val/test data
+3. Optimizer(s)
+4. Training step computations
+5. Validation step computations
+6. Test step computations
+
+
+The Model
+^^^^^^^^^
+The LightningModule provides the structure on how to organize these 5 ingredients.
+
+Let's first start with the model. In this case we'll design
+a 3-layer neural network.
+
+.. code-block:: default
+
+    import torch
+    from torch.nn import functional as F
+    from torch import nn
+    import pytorch_lightning as pl
+
+    class LitMNIST(pl.LightningModule):
+
+      def __init__(self):
+        super(LitMNIST, self).__init__()
+
+        # mnist images are (1, 28, 28) (channels, width, height)
+        self.layer_1 = torch.nn.Linear(28 * 28, 128)
+        self.layer_2 = torch.nn.Linear(128, 256)
+        self.layer_3 = torch.nn.Linear(256, 10)
+
+      def forward(self, x):
+        batch_size, channels, width, height = x.size()
+
+        # (b, 1, 28, 28) -> (b, 1*28*28)
+        x = x.view(batch_size, -1)
+
+        # layer 1
+        x = self.layer_1(x)
+        x = torch.relu(x)
+
+        # layer 2
+        x = self.layer_2(x)
+        x = torch.relu(x)
+
+        # layer 3
+        x = self.layer_3(x)
+
+        # probability distribution over labels
+        x = torch.log_softmax(x, dim=1)
+
+        return x
+
+Notice this is a `LightningModule` instead of a `torch.nn.Module`. A LightningModule is
+equivalent to a PyTorch Module except it has added functionality. However, you can use it
+EXACTLY the same as you would a PyTorch Module.
+
+.. code-block:: default
+
+    net = LitMNIST()
+    x = torch.Tensor(1, 1, 28, 28)
+    out = net(x)
+
+.. rst-class:: sphx-glr-script-out
+
+ Out:
+
+ .. code-block:: none
+
+    torch.Size([1, 10])
+
+Data
+^^^^
+
+The Lightning Module organizes your dataloaders and data processing as well.
+Here's the PyTorch code for loading MNIST
+
+.. code-block:: default
+
+    from torch.utils.data import DataLoader, random_split
+    from torchvision.datasets import MNIST
+    import os
+    from torchvision import datasets, transforms
+
+
+    # transforms
+    # prepare transforms standard to MNIST
+    transform=transforms.Compose([transforms.ToTensor(),
+                                  transforms.Normalize((0.1307,), (0.3081,))])
+
+    # data
+    mnist_train = MNIST(os.getcwd(), train=True, download=True)
+    mnist_train = DataLoader(mnist_train, batch_size=64)
+
+When using PyTorch Lightning, we use the exact same code except we organize it into
+the LightningModule
+
+.. code-block:: python
+
+    from torch.utils.data import DataLoader, random_split
+    from torchvision.datasets import MNIST
+    import os
+    from torchvision import datasets, transforms
+
+    class LitMNIST(pl.LightningModule):
+
+      def train_dataloader(self):
+        transform=transforms.Compose([transforms.ToTensor(),
+                                      transforms.Normalize((0.1307,), (0.3081,))])
+        mnist_train = MNIST(os.getcwd(), train=True, download=False,
+                            transform=transform)
+        return DataLoader(mnist_train, batch_size=64)
+
+Notice the code is exactly the same, except now the training dataloading has been organized by the LightningModule
+under the `train_dataloader` method. This is great because if you run into a project that uses Lightning and want
+to figure out how they prepare their training data you can just look in the `train_dataloader` method.
+
+Usually though, we want to separate the things that write to disk in data-processing from
+things like transforms which happen in memory.
+
+.. code-block:: python
+
+    class LitMNIST(pl.LightningModule):
+
+      def prepare_data(self):
+        # download only
+        MNIST(os.getcwd(), train=True, download=True)
+
+      def train_dataloader(self):
+        # no download, just transform
+        transform=transforms.Compose([transforms.ToTensor(),
+                                      transforms.Normalize((0.1307,), (0.3081,))])
+        mnist_train = MNIST(os.getcwd(), train=True, download=False,
+                            transform=transform)
+        return DataLoader(mnist_train, batch_size=64)
+
+Doing it in the `prepare_data` method ensures that when you have
+multiple GPUs you won't overwrite the data. This is a contrived example
+but it gets more complicated with things like NLP or Imagenet.
+
+In general fill these methods with the following:
+
+.. code-block:: python
+
+    class LitMNIST(pl.LightningModule):
+
+      def prepare_data(self):
+        # stuff here is done once at the very beginning of training
+        # before any distributed training starts
+
+        # download stuff
+        # save to disk
+        # etc...
+
+      def train_dataloader(self):
+        # data transforms
+        # dataset creation
+        # return a DataLoader
+
+
+
+Optimizer
+^^^^^^^^^
+
+Next we choose what optimizer to use for training our system.
+In PyTorch we do it as follows:
+
+.. code-block:: python
+
+    from torch.optim import Adam
+    optimizer = Adam(LitMNIST().parameters(), lr=1e-3)
+
+
+In Lightning we do the same but organize it under the configure_optimizers method.
+If you don't define this, Lightning will automatically use `Adam(self.parameters(), lr=1e-3)`.
+
+.. code-block:: python
+
+    class LitMNIST(pl.LightningModule):
+
+      def configure_optimizers(self):
+        return Adam(self.parameters(), lr=1e-3)
+
+Training step
+^^^^^^^^^^^^^
+
+The training step is what happens inside the training loop.
+
+.. code-block:: python
+
+    for epoch in epochs:
+        for batch in data:
+            # TRAINING STEP
+            # ....
+            # TRAINING STEP
+            loss.backward()
+            optimizer.step()
+            optimizer.zero_grad()
+
+In the case of MNIST we do the following
+
+.. code-block:: python
+
+    for epoch in epochs:
+        for batch in data:
+            # TRAINING STEP START
+            x, y = batch
+            logits = model(x)
+            loss = F.nll_loss(logits, y)
+            # TRAINING STEP END
+
+            loss.backward()
+            optimizer.step()
+            optimizer.zero_grad()
+
+In Lightning, everything that is in the training step gets organized under the `training_step` function
+in the LightningModule
+
+.. code-block:: python
+
+    class LitMNIST(pl.LightningModule):
+
+      def training_step(self, batch, batch_idx):
+        x, y = batch
+        logits = self.forward(x)
+        loss = F.nll_loss(logits, y)
+        return {'loss': loss}
+        # return loss (also works)
+
+Again, this is the same PyTorch code except that it has been organized by the LightningModule.
+This code is not restricted which means it can be as complicated as a full seq-2-seq, RL loop, GAN, etc...
+
+---------
+
+Training
+--------
+So far we defined 4 key ingredients in pure PyTorch but organized the code inside the LightningModule.
+
+1. Model.
+2. Training data.
+3. Optimizer.
+4. What happens in the training loop.
+
+For clarity, we'll recall that the full LightningModule now looks like this.
+
+.. code-block:: python
+
+    class LitMNIST(pl.LightningModule):
+      def __init__(self):
+        super(LitMNIST, self).__init__()
+        self.layer_1 = torch.nn.Linear(28 * 28, 128)
+        self.layer_2 = torch.nn.Linear(128, 256)
+        self.layer_3 = torch.nn.Linear(256, 10)
+
+      def forward(self, x):
+        batch_size, channels, width, height = x.size()
+        x = x.view(batch_size, -1)
+        x = self.layer_1(x)
+        x = torch.relu(x)
+        x = self.layer_2(x)
+        x = torch.relu(x)
+        x = self.layer_3(x)
+        x = torch.log_softmax(x, dim=1)
+        return x
+
+      def train_dataloader(self):
+        transform=transforms.Compose([transforms.ToTensor(),
+                                      transforms.Normalize((0.1307,), (0.3081,))])
+        mnist_train = MNIST(os.getcwd(), train=True, download=False, transform=transform)
+        return DataLoader(mnist_train, batch_size=64)
+
+      def configure_optimizers(self):
+        return Adam(self.parameters(), lr=1e-3)
+
+      def training_step(self, batch, batch_idx):
+        x, y = batch
+        logits = self.forward(x)
+        loss = F.nll_loss(logits, y)
+
+        # add logging
+        logs = {'loss': loss}
+        return {'loss': loss, 'log': logs}
+
+Again, this is the same PyTorch code, except that it's organized
+by the LightningModule. This organization now lets us train this model
+
+Train on CPU
+^^^^^^^^^^^^
+
+.. code-block:: python
+
+    from pytorch_lightning import Trainer
+
+    model = LitMNIST()
+    trainer = Trainer()
+    trainer.fit(model)
+
+You should see the following weights summary and progress bar
+
+.. figure:: /_images/mnist_imgs/mnist_cpu_bar.png
+   :alt: mnist CPU bar
+
+Logging
+^^^^^^^
+
+When we added the `log` key in the return dictionary it went into the built in tensorboard logger.
+But you could have also logged by calling:
+
+.. code-block:: python
+
+    def training_step(self, batch, batch_idx):
+        # ...
+        loss = ...
+        self.logger.summary.scalar('loss', loss)
+
+Which will generate automatic tensorboard logs.
+
+.. figure:: /_images/mnist_imgs/mnist_tb.png
+   :alt: mnist CPU bar
+
+But you can also use any of the `number of other loggers <loggers.rst>`_ we support.
+
+GPU training
+^^^^^^^^^^^^
+
+But the beauty is all the magic you can do with the trainer flags. For instance, to run this model on a GPU:
+
+.. code-block:: python
+
+    model = LitMNIST()
+    trainer = Trainer(gpus=1)
+    trainer.fit(model)
+
+
+.. figure:: /_images/mnist_imgs/mnist_gpu.png
+    :alt: mnist GPU bar
+
+Multi-GPU training
+^^^^^^^^^^^^^^^^^^
+
+Or you can also train on multiple GPUs.
+
+.. code-block:: python
+
+    model = LitMNIST()
+    trainer = Trainer(gpus=8)
+    trainer.fit(model)
+
+Or multiple nodes
+
+.. code-block:: python
+
+    # (32 GPUs)
+    model = LitMNIST()
+    trainer = Trainer(gpus=8, num_nodes=4, distributed_backend='ddp')
+    trainer.fit(model)
+
+Refer to the `distributed computing guide for more details <multi_gpu.rst>`_.
+
+TPUs
+^^^^
+Did you know you can use PyTorch on TPUs? It's very hard to do, but we've
+worked with the xla team to use their awesome library to get this to work
+out of the box!
+
+Let's train on Colab (`full demo available here <https://colab.research.google.com/drive/1-_LKx4HwAxl5M6xPJmqAAu444LTDQoa3>`_)
+
+First, change the runtime to TPU (and reinstall lightning).
+
+.. figure:: /_images/mnist_imgs/runtime_tpu.png
+    :alt: mnist GPU bar
+
+.. figure:: /_images/mnist_imgs/restart_runtime.png
+    :alt: mnist GPU bar
+
+Next, install the required xla library (adds support for PyTorch on TPUs)
+
+.. code-block:: python
+
+    import collections
+    from datetime import datetime, timedelta
+    import os
+    import requests
+    import threading
+
+    _VersionConfig = collections.namedtuple('_VersionConfig', 'wheels,server')
+    VERSION = "torch_xla==nightly"  #@param ["xrt==1.15.0", "torch_xla==nightly"]
+    CONFIG = {
+        'xrt==1.15.0': _VersionConfig('1.15', '1.15.0'),
+        'torch_xla==nightly': _VersionConfig('nightly', 'XRT-dev{}'.format(
+            (datetime.today() - timedelta(1)).strftime('%Y%m%d'))),
+    }[VERSION]
+    DIST_BUCKET = 'gs://tpu-pytorch/wheels'
+    TORCH_WHEEL = 'torch-{}-cp36-cp36m-linux_x86_64.whl'.format(CONFIG.wheels)
+    TORCH_XLA_WHEEL = 'torch_xla-{}-cp36-cp36m-linux_x86_64.whl'.format(CONFIG.wheels)
+    TORCHVISION_WHEEL = 'torchvision-{}-cp36-cp36m-linux_x86_64.whl'.format(CONFIG.wheels)
+
+    # Update TPU XRT version
+    def update_server_xrt():
+      print('Updating server-side XRT to {} ...'.format(CONFIG.server))
+      url = 'http://{TPU_ADDRESS}:8475/requestversion/{XRT_VERSION}'.format(
+          TPU_ADDRESS=os.environ['COLAB_TPU_ADDR'].split(':')[0],
+          XRT_VERSION=CONFIG.server,
+      )
+      print('Done updating server-side XRT: {}'.format(requests.post(url)))
+
+    update = threading.Thread(target=update_server_xrt)
+    update.start()
+
+    # Install Colab TPU compat PyTorch/TPU wheels and dependencies
+    !pip uninstall -y torch torchvision
+    !gsutil cp "$DIST_BUCKET/$TORCH_WHEEL" .
+    !gsutil cp "$DIST_BUCKET/$TORCH_XLA_WHEEL" .
+    !gsutil cp "$DIST_BUCKET/$TORCHVISION_WHEEL" .
+    !pip install "$TORCH_WHEEL"
+    !pip install "$TORCH_XLA_WHEEL"
+    !pip install "$TORCHVISION_WHEEL"
+    !sudo apt-get install libomp5
+    update.join()
+
+In distributed training (multiple GPUs and multiple TPU cores) each GPU or TPU core will run a copy
+of this program. This means that without taking any care you will download the dataset N times which
+will cause all sorts of issues.
+
+To solve this problem, move the download code to the `prepare_data` method in the LightningModule.
+In this method we do all the preparation we need to do once (instead of on every gpu).
+
+.. code-block:: python
+
+    class LitMNIST(pl.LightningModule):
+      def prepare_data(self):
+        # transform
+        transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])
+
+        # download
+        mnist_train = MNIST(os.getcwd(), train=True, download=True, transform=transform)
+        mnist_test = MNIST(os.getcwd(), train=False, download=True, transform=transform)
+
+        # train/val split
+        mnist_train, mnist_val = random_split(mnist_train, [55000, 5000])
+
+        # assign to use in dataloaders
+        self.train_dataset = mnist_train
+        self.val_dataset = mnist_val
+        self.test_dataset = mnist_test
+
+      def train_dataloader(self):
+        return DataLoader(self.train_dataset, batch_size=64)
+
+      def val_dataloader(self):
+        return DataLoader(self.mnist_val, batch_size=64)
+
+      def test_dataloader(self):
+        return DataLoader(self.mnist_test, batch_size=64)
+
+The `prepare_data` method is also a good place to do any data processing that needs to be done only
+once (ie: download or tokenize, etc...).
+
+.. note:: Lightning inserts the correct DistributedSampler for distributed training. No need to add yourself!
+
+Now we can train the LightningModule on a TPU without doing anything else!
+
+.. code-block:: python
+
+    model = LitMNIST()
+    trainer = Trainer(num_tpu_cores=8)
+    trainer.fit(model)
+
+You'll now see the TPU cores booting up.
+
+.. figure:: /_images/mnist_imgs/tpu_start.png
+    :alt: TPU start
+
+Notice the epoch is MUCH faster!
+
+.. figure:: /_images/mnist_imgs/tpu_fast.png
+    :alt: TPU speed
+
+---------
+
+Hyperparameters
+---------------
+Normally, we don't hard-code the values to a model. We usually use the command line to
+modify the network.
+
+.. code-block:: python
+
+    from argparse import ArgumentParser
+
+    parser = ArgumentParser()
+
+    # parametrize the network
+    parser.add_argument('--layer_1_dim', type=int, default=128)
+    parser.add_argument('--layer_2_dim', type=int, default=256)
+    parser.add_argument('--batch_size', type=int, default=64)
+
+    args = parser.parse_args()
+
+Now we can parametrize the LightningModule.
+
+.. code-block:: python
+    :emphasize-lines: 5,6,7,12,14
+
+    class LitMNIST(pl.LightningModule):
+      def __init__(self, hparams):
+        super(LitMNIST, self).__init__()
+        self.hparams = hparams
+
+        self.layer_1 = torch.nn.Linear(28 * 28, hparams.layer_1_dim)
+        self.layer_2 = torch.nn.Linear(hparams.layer_1_dim, hparams.layer_2_dim)
+        self.layer_3 = torch.nn.Linear(hparams.layer_2_dim, 10)
+
+      def forward(self, x):
+        ...
+
+      def train_dataloader(self):
+        ...
+        return DataLoader(mnist_train, batch_size=self.hparams.batch_size)
+
+      def configure_optimizers(self):
+        return Adam(self.parameters(), lr=self.hparams.learning_rate)
+
+    hparams = parse_args()
+    model = LitMNIST(hparams)
+
+.. note:: Bonus! if (hparams) is in your module, Lightning will save it into the checkpoint and restore your
+    model using those hparams exactly.
+
+And we can also add all the flags available in the Trainer to the Argparser.
+
+.. code-block:: python
+
+    # add all the available Trainer options to the ArgParser
+    parser = pl.Trainer.add_argparse_args(parser)
+    args = parser.parse_args()
+
+And now you can start your program with
+
+.. code-block:: bash
+
+    # now you can use any trainer flag
+    $ python main.py --num_nodes 2 --gpus 8
+
+
+For a full guide on using hyperparameters, `check out the hyperparameters docs <hyperparameters.rst>`_.
+
+---------
+
+Validating
+----------
+
+For most cases, we stop training the model when the performance on a validation
+split of the data reaches a minimum.
+
+Just like the `training_step`, we can define a `validation_step` to check whatever
+metrics we care about, generate samples or add more to our logs.
+
+.. code-block:: python
+
+    for epoch in epochs:
+        for batch in data:
+            # ...
+            # train
+
+        # validate
+        outputs = []
+        for batch in val_data:
+            x, y = batch                        # validation_step
+            y_hat = model(x)                    # validation_step
+            loss = loss(y_hat, x)               # validation_step
+            outputs.append({'val_loss': loss})  # validation_step
+
+        full_loss = outputs.mean()              # validation_epoch_end
+
+Since the `validation_step` processes a single batch,
+in Lightning we also have a `validation_epoch_end` method which allows you to compute
+statistics on the full dataset after an epoch of validation data and not just the batch.
+
+In addition, we define a `val_dataloader` method which tells the trainer what data to use for validation.
+Notice we split the train split of MNIST into train, validation. We also have to make sure to do the
+sample split in the `train_dataloader` method.
+
+.. code-block:: python
+
+    class LitMNIST(pl.LightningModule):
+      def validation_step(self, batch, batch_idx):
+        x, y = batch
+        logits = self.forward(x)
+        loss = F.nll_loss(logits, y)
+        return {'val_loss': loss}
+
+      def validation_epoch_end(self, outputs):
+        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()
+        tensorboard_logs = {'val_loss': avg_loss}
+        return {'avg_val_loss': avg_loss, 'log': tensorboard_logs}
+
+      def val_dataloader(self):
+        transform=transforms.Compose([transforms.ToTensor(),
+                                      transforms.Normalize((0.1307,), (0.3081,))])
+        mnist_train = MNIST(os.getcwd(), train=True, download=False,
+                            transform=transform)
+        _, mnist_val = random_split(mnist_train, [55000, 5000])
+        mnist_val = DataLoader(mnist_val, batch_size=64)
+        return mnist_val
+
+Again, we've just organized the regular PyTorch code into two steps, the `validation_step` method which
+operates on a single batch and the `validation_epoch_end` method to compute statistics on all batches.
+
+If you have these methods defined, Lightning will call them automatically. Now we can train
+while checking the validation set.
+
+.. code-block:: python
+
+    from pytorch_lightning import Trainer
+
+    model = LitMNIST()
+    trainer = Trainer(num_tpu_cores=8)
+    trainer.fit(model)
+
+You may have noticed the words `Validation sanity check` logged. This is because Lightning runs 5 batches
+of validation before starting to train. This is a kind of unit test to make sure that if you have a bug
+in the validation loop, you won't need to potentially wait a full epoch to find out.
+
+.. note:: Lightning disables gradients, puts model in eval mode and does everything needed for validation.
+
+---------
+
+Testing
+-------
+Once our research is done and we're about to publish or deploy a model, we normally want to figure out
+how it will generalize in the "real world." For this, we use a held-out split of the data for testing.
+
+Just like the validation loop, we define exactly the same steps for testing:
+
+- test_step
+- test_epoch_end
+- test_dataloader
+
+.. code-block:: python
+
+    class LitMNIST(pl.LightningModule):
+      def test_step(self, batch, batch_idx):
+        x, y = batch
+        logits = self.forward(x)
+        loss = F.nll_loss(logits, y)
+        return {'val_loss': loss}
+
+      def test_epoch_end(self, outputs):
+        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()
+        tensorboard_logs = {'val_loss': avg_loss}
+        return {'avg_val_loss': avg_loss, 'log': tensorboard_logs}
+
+      def test_dataloader(self):
+        transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])
+        mnist_train = MNIST(os.getcwd(), train=False, download=False, transform=transform)
+        _, mnist_val = random_split(mnist_train, [55000, 5000])
+        mnist_val = DataLoader(mnist_val, batch_size=64)
+        return mnist_val
+
+However, to make sure the test set isn't used inadvertently, Lightning has a separate API to run tests.
+Once you train your model simply call `.test()`.
+
+.. code-block:: python
+
+    from pytorch_lightning import Trainer
+
+    model = LitMNIST()
+    trainer = Trainer(num_tpu_cores=8)
+    trainer.fit(model)
+
+    # run test set
+    trainer.test()
+
+.. rst-class:: sphx-glr-script-out
+
+ Out:
+
+ .. code-block:: none
+
+        --------------------------------------------------------------
+        TEST RESULTS
+        {'test_loss': tensor(1.1703, device='cuda:0')}
+        --------------------------------------------------------------
+
+You can also run the test from a saved lightning model
+
+.. code-block:: python
+
+    model = LitMNIST.load_from_checkpoint(PATH)
+    trainer = Trainer(num_tpu_cores=8)
+    trainer.test(model)
+
+.. note:: Lightning disables gradients, puts model in eval mode and does everything needed for testing.
+
+.. warning:: .test() is not stable yet on TPUs. We're working on getting around the multiprocessing challenges.
+
+---------
+
+Predicting
+----------
+Again, a LightningModule is exactly the same as a PyTorch module. This means you can load it
+and use it for prediction.
+
+.. code-block:: python
+
+    model = LitMNIST.load_from_checkpoint(PATH)
+    x = torch.Tensor(1, 1, 28, 28)
+    out = model(x)
+
+On the surface, it looks like `forward` and `training_step` are similar. Generally, we want to make sure that
+what we want the model to do is what happens in the `forward`. whereas the `training_step` likely calls forward from
+within it.
+
+.. code-block:: python
+
+    class MNISTClassifier(pl.LightningModule):
+
+      def forward(self, x):
+        batch_size, channels, width, height = x.size()
+        x = x.view(batch_size, -1)
+        x = self.layer_1(x)
+        x = torch.relu(x)
+        x = self.layer_2(x)
+        x = torch.relu(x)
+        x = self.layer_3(x)
+        x = torch.log_softmax(x, dim=1)
+        return x
+
+      def training_step(self, batch, batch_idx):
+        x, y = batch
+        logits = self.forward(x)
+        loss = F.nll_loss(logits, y)
+        return loss
+
+.. code-block:: python
+
+    model = MNISTClassifier()
+    x = mnist_image()
+    logits = model(x)
+
+In this case, we've set this LightningModel to predict logits. But we could also have it predict feature maps:
+
+.. code-block:: python
+
+    class MNISTRepresentator(pl.LightningModule):
+
+      def forward(self, x):
+        batch_size, channels, width, height = x.size()
+        x = x.view(batch_size, -1)
+        x = self.layer_1(x)
+        x1 = torch.relu(x)
+        x = self.layer_2(x1)
+        x2 = torch.relu(x)
+        x3 = self.layer_3(x2)
+        return [x, x1, x2, x3]
+
+      def training_step(self, batch, batch_idx):
+        x, y = batch
+        out, l1_feats, l2_feats, l3_feats = self.forward(x)
+        logits = torch.log_softmax(out, dim=1)
+        ce_loss = F.nll_loss(logits, y)
+        loss = perceptual_loss(l1_feats, l2_feats, l3_feats) + ce_loss
+        return loss
+
+.. code-block:: python
+
+    model = MNISTRepresentator.load_from_checkpoint(PATH)
+    x = mnist_image()
+    feature_maps = model(x)
+
+Or maybe we have a model that we use to do generation
+
+.. code-block:: python
+
+    class LitMNISTDreamer(pl.LightningModule):
+
+      def forward(self, z):
+        imgs = self.decoder(z)
+        return imgs
+
+      def training_step(self, batch, batch_idx):
+        x, y = batch
+        representation = self.encoder(x)
+        imgs = self.forward(representation)
+
+        loss = perceptual_loss(imgs, x)
+        return loss
+
+.. code-block:: python
+
+    model = LitMNISTDreamer.load_from_checkpoint(PATH)
+    z = sample_noise()
+    generated_imgs = model(z)
+
+How you split up what goes in `forward` vs `training_step` depends on how you want to use this model for
+prediction.
+
+---------
+
+Extensibility
+-------------
+Although lightning makes everything super simple, it doesn't sacrifice any flexibility or control.
+Lightning offers multiple ways of managing the training state.
+
+Training overrides
+^^^^^^^^^^^^^^^^^^
+
+Any part of the training, validation and testing loop can be modified.
+For instance, if you wanted to do your own backward pass, you would override the
+default implementation
+
+.. code-block:: python
+
+    def backward(self, use_amp, loss, optimizer):
+        if use_amp:
+            with amp.scale_loss(loss, optimizer) as scaled_loss:
+                scaled_loss.backward()
+        else:
+            loss.backward()
+
+With your own
+
+.. code-block:: python
+
+    class LitMNIST(pl.LightningModule):
+
+        def backward(self, use_amp, loss, optimizer):
+            # do a custom way of backward
+            loss.backward(retain_graph=True)
+
+Or if you wanted to initialize ddp in a different way than the default one
+
+.. code-block:: python
+
+    def configure_ddp(self, model, device_ids):
+        # Lightning DDP simply routes to test_step, val_step, etc...
+        model = LightningDistributedDataParallel(
+            model,
+            device_ids=device_ids,
+            find_unused_parameters=True
+        )
+        return model
+
+you could do your own:
+
+.. code-block:: python
+
+    class LitMNIST(pl.LightningModule):
+
+        def configure_ddp(self, model, device_ids):
+
+            model = Horovod(model)
+            # model = Ray(model)
+            return model
+
+Every single part of training is configurable this way.
+For a full list look at `lightningModule <lightning-module.rst>`_.
+
+---------
+
+Callbacks
+---------
+Another way to add arbitrary functionality is to add a custom callback
+for hooks that you might care about
+
+.. code-block:: python
+
+    import pytorch_lightning as pl
+
+    class MyPrintingCallback(pl.Callback):
+
+        def on_init_start(self, trainer):
+            print('Starting to init trainer!')
+
+        def on_init_end(self, trainer):
+            print('trainer is init now')
+
+        def on_train_end(self, trainer, pl_module):
+            print('do something when training ends')
+
+And pass the callbacks into the trainer
+
+.. code-block:: python
+
+    Trainer(callbacks=[MyPrintingCallback()])
+
+.. note:: See full list of 12+ hooks in the `Callback docs <callbacks.rst#callback-class>`_
+
+---------
+
+.. include:: child_modules.rst
+
+---------
+
+.. include:: transfer_learning.rst
+
diff --git a/docs/source/lightning-module.rst b/docs/source/lightning-module.rst
index a05c1de..3e329be 100644
--- a/docs/source/lightning-module.rst
+++ b/docs/source/lightning-module.rst
@@ -5,6 +5,7 @@ LightningModule
 ===============
 
 .. automodule:: pytorch_lightning.core
+   :noindex:
    :exclude-members:
         _abc_impl,
         summarize,
diff --git a/docs/source/loggers.rst b/docs/source/loggers.rst
index c030e65..67cfdcf 100644
--- a/docs/source/loggers.rst
+++ b/docs/source/loggers.rst
@@ -4,9 +4,10 @@
 Loggers
 ===========
 .. automodule:: pytorch_lightning.loggers
+   :noindex:
    :exclude-members:
         _abc_impl,
         _save_model,
         on_epoch_end,
         on_train_end,
-        on_epoch_begin,
+        on_epoch_start,
diff --git a/docs/source/multi_gpu.rst b/docs/source/multi_gpu.rst
index f44cb3f..fdd5a92 100644
--- a/docs/source/multi_gpu.rst
+++ b/docs/source/multi_gpu.rst
@@ -1,10 +1,83 @@
 Multi-GPU training
-=====================
-
+===================
 Lightning supports multiple ways of doing distributed training.
 
-Data Parallel (dp)
+Preparing your code
 -------------------
+To train on CPU/GPU/TPU without changing your code, we need to build a few good habits :)
+
+Delete .cuda() or .to() calls
+^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
+
+Delete any calls to .cuda() or .to(device).
+
+.. code-block:: python
+
+    # before lightning
+    def forward(self, x):
+        x = x.cuda(0)
+        layer_1.cuda(0)
+        x_hat = layer_1(x)
+
+    # after lightning
+    def forward(self, x):
+        x_hat = layer_1(x)
+
+Init using type_as
+^^^^^^^^^^^^^^^^^^
+When you need to create a new tensor, use `type_as`.
+This will make your code scale to any arbitrary number of GPUs or TPUs with Lightning
+
+.. code-block:: python
+
+    # before lightning
+    def forward(self, x):
+        z = torch.Tensor(2, 3)
+        z = z.cuda(0)
+
+    # with lightning
+    def forward(self, x):
+        z = torch.Tensor(2, 3)
+        z = z.type_as(x.type())
+
+Remove samplers
+^^^^^^^^^^^^^^^
+For multi-node or TPU training, in PyTorch we must use `torch.nn.DistributedSampler`. The
+sampler makes sure each GPU sees the appropriate part of your data.
+
+.. code-block:: python
+
+    # without lightning
+    def train_dataloader(self):
+        dataset = MNIST(...)
+        sampler = None
+
+        if self.on_tpu:
+            sampler = DistributedSampler(dataset)
+
+        return DataLoader(dataset, sampler=sampler)
+
+With Lightning, you don't need to do this because it takes care of adding the correct samplers
+when needed.
+
+.. code-block:: python
+
+    # with lightning
+    def train_dataloader(self):
+        dataset = MNIST(...)
+        return DataLoader(dataset)
+
+Distributed modes
+-----------------
+Lightning allows multiple ways of training
+
+- Data Parallel (`distributed_backend='dp'`) (multiple-gpus, 1 machine)
+- DistributedDataParallel (`distributed_backend='ddp'`) (multiple-gpus across many machines).
+- DistributedDataParallel2 (`distributed_backend='ddp2'`) (dp in a machine, ddp across machines).
+- TPUs (`num_tpu_cores=8|x`) (tpu or TPU pod)
+
+Data Parallel (dp)
+^^^^^^^^^^^^^^^^^^
 `DataParallel <https://pytorch.org/docs/stable/nn.html#torch.nn.DataParallel>`_ splits a batch across k GPUs. That is, if you have a batch of 32 and use dp with 2 gpus,
 each GPU will process 16 samples, after which the root node will aggregate the results.
 
@@ -14,7 +87,7 @@ each GPU will process 16 samples, after which the root node will aggregate the r
     trainer = pl.Trainer(gpus=2, distributed_backend='dp')
 
 Distributed Data Parallel
----------------------------
+^^^^^^^^^^^^^^^^^^^^^^^^^
 `DistributedDataParallel <https://pytorch.org/docs/stable/nn.html#distributeddataparallel>`_ works as follows.
 
 1. Each GPU across every node gets its own process.
@@ -40,7 +113,7 @@ Distributed Data Parallel
     trainer = pl.Trainer(gpus=8, distributed_backend='ddp', num_nodes=4)
 
 Distributed Data Parallel 2
------------------------------
+^^^^^^^^^^^^^^^^^^^^^^^^^^^
 In certain cases, it's advantageous to use all batches on the same machine instead of a subset.
 For instance you might want to compute a NCE loss where it pays  to have more negative samples.
 
@@ -61,9 +134,108 @@ In  this case, we can use ddp2 which behaves like dp in a machine and ddp across
     # train on 32 GPUs (4 nodes)
     trainer = pl.Trainer(gpus=8, distributed_backend='ddp2', num_nodes=4)
 
+DP/DDP2 caveats
+^^^^^^^^^^^^^^^
+In DP and DDP2 each GPU within a machine sees a portion of a batch.
+DP and ddp2 roughly do the following:
+
+.. code-block:: python
+
+    def distributed_forward(batch, model):
+        batch = torch.Tensor(32, 8)
+        gpu_0_batch = batch[:8]
+        gpu_1_batch = batch[8:16]
+        gpu_2_batch = batch[16:24]
+        gpu_3_batch = batch[24:]
+
+        y_0 = model_copy_gpu_0(gpu_0_batch)
+        y_1 = model_copy_gpu_0(gpu_1_batch)
+        y_2 = model_copy_gpu_0(gpu_2_batch)
+        y_3 = model_copy_gpu_0(gpu_3_batch)
+
+        return [y_0, y_1, y_2, y_3]
+
+So, when Lightning calls any of the `training_step`, `validation_step`, `test_step`
+you will only be operating on one of those pieces.
+
+.. code-block:: python
+
+    # the batch here is a portion of the FULL batch
+    def training_step(self, batch, batch_idx):
+        y_0 = batch
+
+For most metrics, this doesn't really matter. However, if you want
+to add something to your computational graph (like softmax)
+using all batch parts you can use the `training_step_end` step.
+
+.. code-block:: python
+
+    def training_step_end(self, outputs):
+        # only use when  on dp
+        outputs = torch.cat(outputs, dim=1)
+        softmax = softmax(outputs, dim=1)
+        out = softmax.mean()
+        return out
+
+In pseudocode, the full sequence is:
+
+.. code-block:: python
+
+    # get data
+    batch = next(dataloader)
+
+    # copy model and data to each gpu
+    batch_splits = split_batch(batch, num_gpus)
+    models = copy_model_to_gpus(model)
+
+    # in parallel, operate on each batch chunk
+    all_results = []
+    for gpu_num in gpus:
+        batch_split = batch_splits[gpu_num]
+        gpu_model = models[gpu_num]
+        out = gpu_model(batch_split)
+        all_results.append(out)
+
+    # use the full batch for something like softmax
+    full out = model.training_step_end(all_results)
+
+to illustrate why this is needed, let's look at dataparallel
+
+.. code-block:: python
+
+    def training_step(self, batch, batch_idx):
+        x, y = batch
+        y_hat = self.forward(batch)
+
+        # on dp or ddp2 if we did softmax now it would be wrong
+        # because batch is actually a piece of the full batch
+        return y_hat
+
+    def training_step_end(self, batch_parts_outputs):
+        # batch_parts_outputs has outputs of each part of the batch
+
+        # do softmax here
+        outputs = torch.cat(outputs, dim=1)
+        softmax = softmax(outputs, dim=1)
+        out = softmax.mean()
+
+        return out
+
+If `training_step_end` is defined it will be called regardless of tpu, dp, ddp, etc... which means
+it will behave the same no matter the backend.
+
+Validation and test step also have the same option when using dp
+
+.. code-block:: python
+
+        def validation_step_end(self, batch_parts_outputs):
+            ...
+
+        def test_step_end(self, batch_parts_outputs):
+            ...
 
 Implement Your Own Distributed (DDP) training
-----------------------------------------------
-If you need your own way to init PyTorch DDP you can override :meth:`pytorch_lightning.core.LightningModule.init_ddp_connection`.
+^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
+If you need your own way to init PyTorch DDP you can override :meth:`pytorch_lightning.core.LightningModule.`.
 
 If you also need to use your own DDP implementation, override:  :meth:`pytorch_lightning.core.LightningModule.configure_ddp`.
diff --git a/docs/source/optimizers.rst b/docs/source/optimizers.rst
index 2dd4c63..1d9e77a 100644
--- a/docs/source/optimizers.rst
+++ b/docs/source/optimizers.rst
@@ -53,9 +53,9 @@ Lightning will call each optimizer sequentially:
 
 
 Step optimizers at arbitrary intervals
--------------------------------------
+----------------------------------------
 To do more interesting things with your optimizers such as learning rate warm-up or odd scheduling,
-override the :meth:`optimizer_step' function.
+override the :meth:`optimizer_step` function.
 
 For example, here step optimizer A every 2 batches and optimizer B every 4 batches
 
@@ -96,4 +96,4 @@ Here we add a learning-rate warm up
 
         # update params
         optimizer.step()
-        optimizer.zero_grad()
\ No newline at end of file
+        optimizer.zero_grad()
diff --git a/docs/source/profiler.rst b/docs/source/profiler.rst
index 605a472..115aaf2 100644
--- a/docs/source/profiler.rst
+++ b/docs/source/profiler.rst
@@ -3,8 +3,9 @@
 
 
 Performance and Bottleneck Profiler
-===========
+===================================
 .. automodule:: pytorch_lightning.profiler
+   :noindex:
    :exclude-members:
         _abc_impl,
         summarize,
diff --git a/docs/source/tpu.rst b/docs/source/tpu.rst
index ca8ad8f..119ec34 100644
--- a/docs/source/tpu.rst
+++ b/docs/source/tpu.rst
@@ -86,7 +86,7 @@ the TPU.
     !pip install "$TORCHVISION_WHEEL"
     !sudo apt-get install libomp5
     update.join()
-5. Once the above is done, install PyTorch Lightning (v 0.6.1+).
+5. Once the above is done, install PyTorch Lightning (v 0.7.0+).
 
 .. code-block::
 
@@ -101,7 +101,6 @@ train_dataloader (and val, train) code as follows.
 
     import torch_xla.core.xla_model as xm
 
-    @pl.data_loader
     def train_dataloader(self):
         dataset = MNIST(
             os.getcwd(),
@@ -174,3 +173,5 @@ About XLA
 ----------
 XLA is the library that interfaces PyTorch with the TPUs.
 For more information check out `XLA <https://github.com/pytorch/xla>`_.
+
+Guide for `troubleshooting XLA <https://github.com/pytorch/xla/blob/master/TROUBLESHOOTING.md>`_
diff --git a/docs/source/trainer.rst b/docs/source/trainer.rst
index fc4f7ee..b160cfa 100644
--- a/docs/source/trainer.rst
+++ b/docs/source/trainer.rst
@@ -3,13 +3,14 @@
 
 Trainer
 =======
-
 .. automodule:: pytorch_lightning.trainer
    :members: fit, test
-   :exclude-members: 
-        run_pretrain_routine, 
-        _abc_impl, 
-        _Trainer__set_root_gpu, 
+   :noindex:
+   :exclude-members:
+        run_pretrain_routine,
+        _abc_impl,
+        _Trainer__set_random_port,
+        _Trainer__set_root_gpu,
         _Trainer__init_optimizers,
         _Trainer__parse_gpu_ids,
         _Trainer__configure_schedulers,
diff --git a/docs/source/transfer_learning.rst b/docs/source/transfer_learning.rst
new file mode 100644
index 0000000..9737d7d
--- /dev/null
+++ b/docs/source/transfer_learning.rst
@@ -0,0 +1,115 @@
+Transfer Learning
+-----------------
+
+Using Pretrained Models
+^^^^^^^^^^^^^^^^^^^^^^^
+
+Sometimes we want to use a LightningModule as a pretrained model. This is fine because
+a LightningModule is just a `torch.nn.Module`!
+
+.. note:: Remember that a pl.LightningModule is EXACTLY a torch.nn.Module but with more capabilities.
+
+Let's use the `AutoEncoder` as a feature extractor in a separate model.
+
+
+.. code-block:: python
+
+    class Encoder(torch.nn.Module):
+        ...
+
+    class AutoEncoder(pl.LightningModule):
+        def __init__(self):
+            self.encoder = Encoder()
+            self.decoder = Decoder()
+
+    class CIFAR10Classifier(pl.LightingModule):
+        def __init__(self):
+            # init the pretrained LightningModule
+            self.feature_extractor = AutoEncoder.load_from_checkpoint(PATH)
+            self.feature_extractor.freeze()
+
+            # the autoencoder outputs a 100-dim representation and CIFAR-10 has 10 classes
+            self.classifier = nn.Linear(100, 10)
+
+        def forward(self, x):
+            representations = self.feature_extractor(x)
+            x = self.classifier(representations)
+            ...
+
+We used our pretrained Autoencoder (a LightningModule) for transfer learning!
+
+Example: Imagenet (computer Vision)
+^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
+
+.. code-block:: python
+
+    import torchvision.models as models
+
+    class ImagenetTranferLearning(pl.LightingModule):
+        def __init__(self):
+            # init a pretrained resnet
+            num_target_classes = 10
+            self.feature_extractor = model.resnet50(
+                                        pretrained=True,
+                                        num_classes=num_target_classes)
+            self.feature_extractor.eval()
+
+            # use the pretrained model to classify cifar-10 (10 image classes)
+            self.classifier = nn.Linear(2048, num_target_classes)
+
+        def forward(self, x):
+            representations = self.feature_extractor(x)
+            x = self.classifier(representations)
+            ...
+
+Finetune
+
+.. code-block:: python
+
+    model = ImagenetTranferLearning()
+    trainer = Trainer()
+    trainer.fit(model)
+
+And use it to predict your data of interest
+
+.. code-block:: python
+
+    model = ImagenetTranferLearning.load_from_checkpoint(PATH)
+    model.freeze()
+
+    x = some_images_from_cifar10()
+    predictions = model(x)
+
+We used a pretrained model on imagenet, finetuned on CIFAR-10 to predict on CIFAR-10.
+In the non-academic world we would finetune on a tiny dataset you have and predict on your dataset.
+
+Example: BERT (NLP)
+^^^^^^^^^^^^^^^^^^^
+Lightning is completely agnostic to what's used for transfer learning so long
+as it is a `torch.nn.Module` subclass.
+
+Here's a model that uses `Huggingface transformers <https://github.com/huggingface/transformers>`_.
+
+.. code-block:: python
+
+    from transformers import BertModel
+
+    class BertMNLIFinetuner(pl.LightningModule):
+
+    def __init__(self):
+        super(BertMNLIFinetuner, self).__init__()
+
+        self.bert = BertModel.from_pretrained('bert-base-cased', output_attentions=True)
+        self.W = nn.Linear(bert.config.hidden_size, 3)
+        self.num_classes = 3
+
+
+    def forward(self, input_ids, attention_mask, token_type_ids):
+
+        h, _, attn = self.bert(input_ids=input_ids,
+                         attention_mask=attention_mask,
+                         token_type_ids=token_type_ids)
+
+        h_cls = h[:, 0]
+        logits = self.W(h_cls)
+        return logits, attn
\ No newline at end of file
diff --git a/docs/source/tutorials.rst b/docs/source/tutorials.rst
index ba2baf2..f390a71 100644
--- a/docs/source/tutorials.rst
+++ b/docs/source/tutorials.rst
@@ -1,20 +1,4 @@
-Refactoring PyTorch into Lightning
-----------------------------------
-`How to refactor your PyTorch code to get these 42 benefits of PyTorch-Lighting <https://towardsdatascience.com/how-to-refactor-your-pytorch-code-to-get-these-42-benefits-of-pytorch-lighting-6fdd0dc97538>`_
-
-Start a research project
-------------------------
-`Research seed <https://github.com/PytorchLightning/pytorch-lightning-conference-seed>`_
-
-Basic Lightning use
--------------------
-`Supercharge your AI research with PyTorch-Lightning <https://towardsdatascience.com/supercharge-your-ai-research-with-pytorch-lightning-337948a99eec>`_
-
-9 key Lightning  tricks
------------------------
-`Tutorial on 9 key speed features in PyTorch-Lightning <9 key speed features in Pytorch-Lightning>`_
-
-Multi-node training on SLURM
-----------------------------
-`Trivial multi node training with PyTorch-Lightning <https://towardsdatascience.com/trivial-multi-node-training-with-pytorch-lightning-ff75dfb809bd>`_
+From PyTorch to Lightning
+=========================
 
+Talk about how to convert
diff --git a/docs/source/weights_loading.rst b/docs/source/weights_loading.rst
new file mode 100644
index 0000000..109adff
--- /dev/null
+++ b/docs/source/weights_loading.rst
@@ -0,0 +1,98 @@
+Saving and loading weights
+==========================
+
+Lightning can automate saving and loading checkpoints.
+
+Checkpoint saving
+-----------------
+A Lightning checkpoint has everything needed to restore a training session including:
+
+- 16-bit scaling factor (apex)
+- Current epoch
+- Global step
+- Model state_dict
+- State of all optimizers
+- State of all learningRate schedulers
+- State of all callbacks
+- The hyperparameters used for that model if passed in as hparams (Argparse.Namespace)
+
+Automatic saving
+^^^^^^^^^^^^^^^^
+
+Checkpointing is enabled by default to the current working directory.
+To change the checkpoint path pass in:
+
+.. code-block:: python
+
+    Trainer(default_save_path='/your/path/to/save/checkpoints')
+
+To modify the behavior of checkpointing pass in your own callback.
+
+.. code-block:: python
+
+    from pytorch_lightning.callbacks import ModelCheckpoint
+
+    # DEFAULTS used by the Trainer
+    checkpoint_callback = ModelCheckpoint(
+        filepath=os.getcwd(),
+        save_best_only=True,
+        verbose=True,
+        monitor='val_loss',
+        mode='min',
+        prefix=''
+    )
+
+    trainer = Trainer(checkpoint_callback=checkpoint_callback)
+
+
+Or disable it by passing
+
+.. code-block:: python
+
+        trainer = Trainer(checkpoint_callback=False)
+
+
+The Lightning checkpoint also saves the hparams (hyperparams) passed into the LightningModule init.
+
+.. note:: hparams is a `Namespace <https://docs.python.org/2/library/argparse.html#argparse.Namespace>`_.
+
+.. code-block:: python
+   :emphasize-lines: 8
+
+   from argparse import Namespace
+
+   # usually these come from command line args
+   args = Namespace(learning_rate=0.001)
+
+   # define you module to have hparams as the first arg
+   # this means your checkpoint will have everything that went into making
+   # this model (in this case, learning rate)
+   class MyLightningModule(pl.LightningModule):
+
+       def __init__(self, hparams, ...):
+           self.hparams = hparams
+
+Manual saving
+^^^^^^^^^^^^^
+
+To save your own checkpoint call:
+
+.. code-block:: python
+
+   model.save_checkpoint(PATH)
+
+Checkpoint Loading
+------------------
+
+You might want to not only load a model but also continue training it. Use this method to
+restore the trainer state as well. This will continue from the epoch and global step you last left off.
+However, the dataloaders will start from the first batch again (if you shuffled it shouldn't matter).
+
+.. code-block:: python
+
+    model = MyLightingModule.load_from_checkpoint(PATH)
+    model.eval()
+    y_hat = model(x)
+
+A LightningModule is no different than a nn.Module. This means you can load it and use it for
+predictions as you would a nn.Module.
\ No newline at end of file
diff --git a/pl_examples/__init__.py b/pl_examples/__init__.py
index 65522ac..c75a843 100644
--- a/pl_examples/__init__.py
+++ b/pl_examples/__init__.py
@@ -3,8 +3,8 @@ Template model definition
 -------------------------
 
 In 99% of cases you want to just copy `one of the examples
- <https://github.com/PyTorchLightning/pytorch-lightning/tree/master/pl_examples>`_
- to start a new lightningModule and change the core of what your model is actually trying to do.
+<https://github.com/PyTorchLightning/pytorch-lightning/tree/master/pl_examples>`_
+to start a new lightningModule and change the core of what your model is actually trying to do.
 
 .. code-block:: bash
 
diff --git a/pl_examples/basic_examples/cpu_template.py b/pl_examples/basic_examples/cpu_template.py
index 0714b1a..7781ba3 100644
--- a/pl_examples/basic_examples/cpu_template.py
+++ b/pl_examples/basic_examples/cpu_template.py
@@ -28,7 +28,7 @@ def main(hparams):
     # ------------------------
     # 2 INIT TRAINER
     # ------------------------
-    trainer = pl.Trainer()
+    trainer = pl.Trainer(max_epochs=hparams.epochs)
 
     # ------------------------
     # 3 START TRAINING
diff --git a/pl_examples/basic_examples/gpu_template.py b/pl_examples/basic_examples/gpu_template.py
index c661eef..090b2ad 100644
--- a/pl_examples/basic_examples/gpu_template.py
+++ b/pl_examples/basic_examples/gpu_template.py
@@ -29,6 +29,7 @@ def main(hparams):
     # 2 INIT TRAINER
     # ------------------------
     trainer = pl.Trainer(
+        max_epochs=hparams.epochs,
         gpus=hparams.gpus,
         distributed_backend=hparams.distributed_backend,
         use_amp=hparams.use_16bit
diff --git a/pl_examples/basic_examples/lightning_module_template.py b/pl_examples/basic_examples/lightning_module_template.py
index 81cdf2a..bc1b85b 100644
--- a/pl_examples/basic_examples/lightning_module_template.py
+++ b/pl_examples/basic_examples/lightning_module_template.py
@@ -12,13 +12,12 @@ import torch.nn.functional as F
 import torchvision.transforms as transforms
 from torch import optim
 from torch.utils.data import DataLoader
-from torch.utils.data.distributed import DistributedSampler
 from torchvision.datasets import MNIST
 
-import pytorch_lightning as pl
+from pytorch_lightning.core import LightningModule
 
 
-class LightningTemplateModel(pl.LightningModule):
+class LightningTemplateModel(LightningModule):
     """
     Sample model to show how to define a template
     """
@@ -142,7 +141,7 @@ class LightningTemplateModel(pl.LightningModule):
         # can also return just a scalar instead of a dict (return loss_val)
         return output
 
-    def validation_end(self, outputs):
+    def validation_epoch_end(self, outputs):
         """
         Called at the end of validation to aggregate outputs
         :param outputs: list of individual outputs of each validation step
@@ -188,41 +187,39 @@ class LightningTemplateModel(pl.LightningModule):
         return [optimizer], [scheduler]
 
     def __dataloader(self, train):
+        # this is neede when you want some info about dataset before binding to trainer
+        self.prepare_data()
         # init data generators
         transform = transforms.Compose([transforms.ToTensor(),
                                         transforms.Normalize((0.5,), (1.0,))])
         dataset = MNIST(root=self.hparams.data_root, train=train,
-                        transform=transform, download=True)
+                        transform=transform, download=False)
 
         # when using multi-node (ddp) we need to add the  datasampler
-        train_sampler = None
         batch_size = self.hparams.batch_size
 
-        if self.use_ddp:
-            train_sampler = DistributedSampler(dataset)
-
-        should_shuffle = train_sampler is None
         loader = DataLoader(
             dataset=dataset,
             batch_size=batch_size,
-            shuffle=should_shuffle,
-            sampler=train_sampler,
             num_workers=0
         )
 
         return loader
 
-    @pl.data_loader
+    def prepare_data(self):
+        transform = transforms.Compose([transforms.ToTensor(),
+                                        transforms.Normalize((0.5,), (1.0,))])
+        _ = MNIST(root=self.hparams.data_root, train=True,
+                  transform=transform, download=True)
+
     def train_dataloader(self):
         log.info('Training data loader called.')
         return self.__dataloader(train=True)
 
-    @pl.data_loader
     def val_dataloader(self):
         log.info('Validation data loader called.')
         return self.__dataloader(train=False)
 
-    @pl.data_loader
     def test_dataloader(self):
         log.info('Test data loader called.')
         return self.__dataloader(train=False)
@@ -252,6 +249,7 @@ class LightningTemplateModel(pl.LightningModule):
         parser.add_argument('--data_root', default=os.path.join(root_dir, 'mnist'), type=str)
 
         # training params (opt)
+        parser.add_argument('--epochs', default=20, type=int)
         parser.add_argument('--optimizer_name', default='adam', type=str)
         parser.add_argument('--batch_size', default=64, type=int)
         return parser
diff --git a/pl_examples/domain_templates/gan.py b/pl_examples/domain_templates/gan.py
index 78a813e..0d7f783 100644
--- a/pl_examples/domain_templates/gan.py
+++ b/pl_examples/domain_templates/gan.py
@@ -19,7 +19,8 @@ import torchvision.transforms as transforms
 from torch.utils.data import DataLoader
 from torchvision.datasets import MNIST
 
-import pytorch_lightning as pl
+from pytorch_lightning.core import LightningModule
+from pytorch_lightning.trainer import Trainer
 
 
 class Generator(nn.Module):
@@ -69,7 +70,7 @@ class Discriminator(nn.Module):
         return validity
 
 
-class GAN(pl.LightningModule):
+class GAN(LightningModule):
 
     def __init__(self, hparams):
         super(GAN, self).__init__()
@@ -165,7 +166,6 @@ class GAN(pl.LightningModule):
         opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=lr, betas=(b1, b2))
         return [opt_g, opt_d], []
 
-    @pl.data_loader
     def train_dataloader(self):
         transform = transforms.Compose([transforms.ToTensor(),
                                         transforms.Normalize([0.5], [0.5])])
@@ -193,7 +193,7 @@ def main(hparams):
     # ------------------------
     # 2 INIT TRAINER
     # ------------------------
-    trainer = pl.Trainer()
+    trainer = Trainer()
 
     # ------------------------
     # 3 START TRAINING
diff --git a/pl_examples/full_examples/__init__.py b/pl_examples/full_examples/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/pl_examples/full_examples/imagenet/__init__.py b/pl_examples/full_examples/imagenet/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/pl_examples/full_examples/imagenet/imagenet_example.py b/pl_examples/full_examples/imagenet/imagenet_example.py
index ce2fbf6..e82a696 100644
--- a/pl_examples/full_examples/imagenet/imagenet_example.py
+++ b/pl_examples/full_examples/imagenet/imagenet_example.py
@@ -19,6 +19,7 @@ import torchvision.models as models
 import torchvision.transforms as transforms
 
 import pytorch_lightning as pl
+from pytorch_lightning.core import LightningModule
 
 # pull out resnet names from torchvision models
 MODEL_NAMES = sorted(
@@ -27,9 +28,11 @@ MODEL_NAMES = sorted(
 )
 
 
-class ImageNetLightningModel(pl.LightningModule):
-
+class ImageNetLightningModel(LightningModule):
     def __init__(self, hparams):
+        """
+        TODO: add docstring here
+        """
         super(ImageNetLightningModel, self).__init__()
         self.hparams = hparams
         self.model = models.__dict__[self.hparams.arch](pretrained=self.hparams.pretrained)
@@ -80,7 +83,7 @@ class ImageNetLightningModel(pl.LightningModule):
 
         return output
 
-    def validation_end(self, outputs):
+    def validation_epoch_end(self, outputs):
 
         tqdm_dict = {}
 
@@ -128,7 +131,6 @@ class ImageNetLightningModel(pl.LightningModule):
         scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.1)
         return [optimizer], [scheduler]
 
-    @pl.data_loader
     def train_dataloader(self):
         normalize = transforms.Normalize(
             mean=[0.485, 0.456, 0.406],
@@ -159,7 +161,6 @@ class ImageNetLightningModel(pl.LightningModule):
         )
         return train_loader
 
-    @pl.data_loader
     def val_dataloader(self):
         normalize = transforms.Normalize(
             mean=[0.485, 0.456, 0.406],
diff --git a/pl_examples/full_examples/semantic_segmentation/models/unet/model.py b/pl_examples/full_examples/semantic_segmentation/models/unet/model.py
index c83516d..6f8df92 100644
--- a/pl_examples/full_examples/semantic_segmentation/models/unet/model.py
+++ b/pl_examples/full_examples/semantic_segmentation/models/unet/model.py
@@ -1,6 +1,4 @@
-import torch
 import torch.nn as nn
-import torch.nn.functional as F
 
 from models.unet.parts import DoubleConv, Down, Up
 
diff --git a/pl_examples/full_examples/semantic_segmentation/semseg.py b/pl_examples/full_examples/semantic_segmentation/semseg.py
index 1f8a5e9..7e51255 100644
--- a/pl_examples/full_examples/semantic_segmentation/semseg.py
+++ b/pl_examples/full_examples/semantic_segmentation/semseg.py
@@ -1,18 +1,15 @@
 import os
 from argparse import ArgumentParser
-from collections import OrderedDict
-from PIL import Image
 
 import numpy as np
 import torch
-import torch.nn as nn
 import torch.nn.functional as F
-import torchvision
 import torchvision.transforms as transforms
+from PIL import Image
+from models.unet.model import UNet
 from torch.utils.data import DataLoader, Dataset
 
 import pytorch_lightning as pl
-from models.unet.model import UNet
 
 
 class KITTI(Dataset):
diff --git a/pytorch_lightning/__init__.py b/pytorch_lightning/__init__.py
index aab6dd6..6dc3df2 100644
--- a/pytorch_lightning/__init__.py
+++ b/pytorch_lightning/__init__.py
@@ -1,6 +1,6 @@
 """Root package info."""
 
-__version__ = '0.6.1.dev'
+__version__ = '0.7.1'
 __author__ = 'William Falcon et al.'
 __author_email__ = 'waf2107@columbia.edu'
 __license__ = 'Apache-2.0'
@@ -24,15 +24,15 @@ if __LIGHTNING_SETUP__:
     # We are not importing the rest of the scikit during the build
     # process, as it may not be compiled yet
 else:
-    import logging as log
-    log.basicConfig(level=log.INFO)
-
-    from .core import data_loader, LightningModule
+    from .core import LightningModule
     from .trainer import Trainer
+    from .callbacks import Callback
+    from .core import data_loader
 
     __all__ = [
         'Trainer',
         'LightningModule',
-        'data_loader',
+        'Callback',
+        'data_loader'
     ]
     # __call__ = __all__
diff --git a/pytorch_lightning/callbacks/__init__.py b/pytorch_lightning/callbacks/__init__.py
index 5618797..3a3d9d5 100644
--- a/pytorch_lightning/callbacks/__init__.py
+++ b/pytorch_lightning/callbacks/__init__.py
@@ -1,8 +1,7 @@
 from .base import Callback
 from .early_stopping import EarlyStopping
-from .model_checkpoint import ModelCheckpoint
 from .gradient_accumulation_scheduler import GradientAccumulationScheduler
-
+from .model_checkpoint import ModelCheckpoint
 
 __all__ = [
     'Callback',
diff --git a/pytorch_lightning/callbacks/base.py b/pytorch_lightning/callbacks/base.py
index 7150138..003241b 100644
--- a/pytorch_lightning/callbacks/base.py
+++ b/pytorch_lightning/callbacks/base.py
@@ -1,68 +1,61 @@
-"""
-Callbacks
-=========
-
-Callbacks supported by Lightning
+r"""
+Callback Base
+==============
+    Abstract base class used to build new callbacks.
 """
 
 import abc
 
 
-_NO_TRAINER_ERROR_MSG = ".set_trainer() should be called after the callback initialization"
-
-
 class Callback(abc.ABC):
-    """Abstract base class used to build new callbacks."""
+    r"""
+    Abstract base class used to build new callbacks.
+    """
 
-    def __init__(self):
-        self._trainer = None
-
-    @property
-    def trainer(self):
-        assert self._trainer is not None, _NO_TRAINER_ERROR_MSG
-        return self._trainer
+    def on_init_start(self, trainer):
+        """Called when the trainer initialization begins, model has not yet been set."""
+        pass
 
-    def set_trainer(self, trainer):
-        """Make a link to the trainer, so different things like `trainer.current_epoch`,
-        `trainer.batch_idx`, `trainer.global_step` can be used."""
-        self._trainer = trainer
+    def on_init_end(self, trainer):
+        """Called when the trainer initialization ends, model has not yet been set."""
+        pass
 
-    def on_epoch_begin(self):
+    def on_epoch_start(self, trainer, pl_module):
         """Called when the epoch begins."""
         pass
 
-    def on_epoch_end(self):
+    def on_epoch_end(self, trainer, pl_module):
         """Called when the epoch ends."""
         pass
 
-    def on_batch_begin(self):
+    def on_batch_start(self, trainer, pl_module):
         """Called when the training batch begins."""
         pass
 
-    def on_batch_end(self):
+    def on_batch_end(self, trainer, pl_module):
         """Called when the training batch ends."""
         pass
 
-    def on_train_begin(self):
+    def on_train_start(self, trainer, pl_module):
         """Called when the train begins."""
         pass
 
-    def on_train_end(self):
+    def on_train_end(self, trainer, pl_module):
         """Called when the train ends."""
         pass
 
-    def on_validation_begin(self):
+    def on_validation_start(self, trainer, pl_module):
         """Called when the validation loop begins."""
         pass
 
-    def on_validation_end(self):
+    def on_validation_end(self, trainer, pl_module):
         """Called when the validation loop ends."""
         pass
 
-    def on_test_begin(self):
+    def on_test_start(self, trainer, pl_module):
         """Called when the test begins."""
         pass
 
-    def on_test_end(self):
+    def on_test_end(self, trainer, pl_module):
         """Called when the test ends."""
         pass
diff --git a/pytorch_lightning/callbacks/early_stopping.py b/pytorch_lightning/callbacks/early_stopping.py
index 645eff2..1d976ce 100644
--- a/pytorch_lightning/callbacks/early_stopping.py
+++ b/pytorch_lightning/callbacks/early_stopping.py
@@ -1,3 +1,10 @@
+r"""
+Early Stopping
+==============
+Stop training when a monitored quantity has stopped improving.
+
+"""
+
 import logging as log
 import warnings
 
@@ -8,7 +15,6 @@ from .base import Callback
 
 class EarlyStopping(Callback):
     r"""
-    Stop training when a monitored quantity has stopped improving.
 
     Args:
         monitor (str): quantity to be monitored. Default: ``'val_loss'``.
@@ -64,8 +70,6 @@ class EarlyStopping(Callback):
         self.monitor_op = mode_dict[mode]
         self.min_delta *= 1 if self.monitor_op == np.greater else -1
 
-        self.on_train_begin()
-
     def check_metrics(self, logs):
         monitor_val = logs.get(self.monitor)
         error_msg = (f'Early stopping conditioned on metric `{self.monitor}`'
@@ -82,14 +86,14 @@ class EarlyStopping(Callback):
 
         return True
 
-    def on_train_begin(self):
+    def on_train_start(self, trainer, pl_module):
         # Allow instances to be re-used
         self.wait = 0
         self.stopped_epoch = 0
         self.best = np.Inf if self.monitor_op == np.less else -np.Inf
 
-    def on_epoch_end(self):
-        logs = self.trainer.callback_metrics
+    def on_epoch_end(self, trainer, pl_module):
+        logs = trainer.callback_metrics
         stop_training = False
         if not self.check_metrics(logs):
             return stop_training
@@ -101,13 +105,13 @@ class EarlyStopping(Callback):
         else:
             self.wait += 1
             if self.wait >= self.patience:
-                self.stopped_epoch = self.trainer.current_epoch
+                self.stopped_epoch = trainer.current_epoch
                 stop_training = True
-                self.on_train_end()
+                self.on_train_end(trainer, pl_module)
 
         return stop_training
 
-    def on_train_end(self):
+    def on_train_end(self, trainer, pl_module):
         if self.stopped_epoch > 0 and self.verbose > 0:
             warnings.warn('Displayed epoch numbers by `EarlyStopping` start from "1" until v0.6.x,'
                           ' but will start from "0" in v0.8.0.', DeprecationWarning)
diff --git a/pytorch_lightning/callbacks/gradient_accumulation_scheduler.py b/pytorch_lightning/callbacks/gradient_accumulation_scheduler.py
index f4e5ad3..00d7339 100644
--- a/pytorch_lightning/callbacks/gradient_accumulation_scheduler.py
+++ b/pytorch_lightning/callbacks/gradient_accumulation_scheduler.py
@@ -1,3 +1,9 @@
+r"""
+Gradient Accumulator
+====================
+Change gradient accumulation factor according to scheduling.
+"""
+
 import warnings
 
 from .base import Callback
@@ -8,9 +14,9 @@ class GradientAccumulationScheduler(Callback):
     Change gradient accumulation factor according to scheduling.
 
     Args:
-        scheduling (dict): scheduling in format {epoch: accumulation_factor}
-        .. warning:: Epochs indexing starts from "1" until v0.6.x, but will start from "0" in
-        v0.8.0.
+        scheduling: scheduling in format {epoch: accumulation_factor}
+            .. warning:: Epochs indexing starts from "1" until v0.6.x,
+                but will start from "0" in v0.8.0.
 
     Example::
 
@@ -44,8 +50,7 @@ class GradientAccumulationScheduler(Callback):
         self.scheduling = scheduling
         self.epochs = sorted(scheduling.keys())
 
-    def on_epoch_begin(self):
-        trainer = self.trainer
+    def on_epoch_start(self, trainer, pl_module):
         # indexing epochs from 1 (until v0.6.x)
         # In v0.8.0, ` + 1` should be removed.
         epoch = trainer.current_epoch + 1
diff --git a/pytorch_lightning/callbacks/model_checkpoint.py b/pytorch_lightning/callbacks/model_checkpoint.py
index a9f7d65..929ef6c 100644
--- a/pytorch_lightning/callbacks/model_checkpoint.py
+++ b/pytorch_lightning/callbacks/model_checkpoint.py
@@ -1,11 +1,19 @@
+"""
+Model Checkpointing
+===================
+
+Automatically save model checkpoints during training.
+"""
+
+import logging as log
 import os
 import shutil
-import logging as log
 import warnings
+import re
 
 import numpy as np
 
-from .base import Callback
+from pytorch_lightning.callbacks.base import Callback
 
 
 class ModelCheckpoint(Callback):
@@ -18,9 +26,15 @@ class ModelCheckpoint(Callback):
 
             Example::
 
-                # save epoch and val_loss in name
-                ModelCheckpoint(filepath='{epoch:02d}-{val_loss:.2f}.hdf5')
-                # saves file like: /path/epoch_2-val_loss_0.2.hdf5
+                # no path
+                ModelCheckpoint()
+                #  saves like /my/path/epoch_0.ckpt
+
+                # save any arbitrary metrics like and val_loss, etc in name
+                ModelCheckpoint(filepath='/my/path/{epoch}-{val_loss:.2f}-{other_metric:.2f}')
+                # saves file like: /my/path/epoch=2-val_loss=0.2_other_metric=0.3.ckpt
+
+
         monitor (str): quantity to monitor.
         verbose (bool): verbosity mode, False or True.
         save_top_k (int): if `save_top_k == k`,
@@ -53,6 +67,10 @@ class ModelCheckpoint(Callback):
         # saves checkpoints to my_path whenever 'val_loss' has a new min
         checkpoint_callback = ModelCheckpoint(filepath='my_path')
         Trainer(checkpoint_callback=checkpoint_callback)
+
+        # save epoch and val_loss in name
+        ModelCheckpoint(filepath='/my/path/here/sample-mnist_{epoch:02d}-{val_loss:.2f}')
+        # saves file like: /my/path/here/sample-mnist_epoch=02_val_loss=0.32.ckpt
     """
 
     def __init__(self, filepath, monitor: str = 'val_loss', verbose: bool = False,
@@ -67,8 +85,12 @@ class ModelCheckpoint(Callback):
 
         self.monitor = monitor
         self.verbose = verbose
-        self.filepath = filepath
-        os.makedirs(filepath, exist_ok=True)
+        if os.path.isdir(filepath):
+            self.dirpath, self.filename = filepath, '{epoch}'
+        else:
+            self.dirpath, self.filename = os.path.split(filepath)
+
+        os.makedirs(self.dirpath, exist_ok=True)
         self.save_top_k = save_top_k
         self.save_weights_only = save_weights_only
         self.period = period
@@ -96,10 +118,7 @@ class ModelCheckpoint(Callback):
         self.monitor_op, self.kth_value, self.mode = mode_dict[mode]
 
     def _del_model(self, filepath):
-        try:
-            shutil.rmtree(filepath)
-        except OSError:
-            os.remove(filepath)
+        os.remove(filepath)
 
     def _save_model(self, filepath):
         # make paths
@@ -117,9 +136,51 @@ class ModelCheckpoint(Callback):
             return True
         return self.monitor_op(current, self.best_k_models[self.kth_best_model])
 
-    def on_validation_end(self):
-        logs = self.trainer.callback_metrics
-        epoch = self.trainer.current_epoch
+    def format_checkpoint_name(self, epoch, metrics, ver=None):
+        """Generate a filename according define template.
+
+        Examples
+        --------
+        >>> tmpdir = os.path.dirname(__file__)
+        >>> ckpt = ModelCheckpoint(os.path.join(tmpdir, '{epoch}'))
+        >>> os.path.basename(ckpt.format_checkpoint_name(0, {}))
+        'epoch=0.ckpt'
+        >>> ckpt = ModelCheckpoint(os.path.join(tmpdir, '{epoch:03d}'))
+        >>> os.path.basename(ckpt.format_checkpoint_name(5, {}))
+        'epoch=005.ckpt'
+        >>> ckpt = ModelCheckpoint(os.path.join(tmpdir, '{epoch}-{val_loss:.2f}'))
+        >>> os.path.basename(ckpt.format_checkpoint_name(2, dict(val_loss=0.123456)))
+        'epoch=2-val_loss=0.12.ckpt'
+        >>> ckpt = ModelCheckpoint(os.path.join(tmpdir, '{missing:d}'))
+        >>> os.path.basename(ckpt.format_checkpoint_name(0, {}))
+        'missing=0.ckpt'
+        """
+        # check if user passed in keys to the string
+        groups = re.findall(r'(\{.*?)[:\}]', self.filename)
+
+        if len(groups) == 0:
+            # default name
+            filename = f'{self.prefix}_ckpt_epoch_{epoch}'
+        else:
+            metrics['epoch'] = epoch
+            filename = self.filename
+            for tmp in groups:
+                name = tmp[1:]
+                filename = filename.replace(tmp, name + '={' + name)
+                if name not in metrics:
+                    metrics[name] = 0
+            filename = filename.format(**metrics)
+        str_ver = f'_v{ver}' if ver is not None else ''
+        filepath = os.path.join(self.dirpath, self.prefix + filename + str_ver + '.ckpt')
+        return filepath
+
+    def on_validation_end(self, trainer, pl_module):
+        # only run on main process
+        if trainer.proc_rank != 0:
+            return
+
+        metrics = trainer.callback_metrics
+        epoch = trainer.current_epoch
         self.epochs_since_last_check += 1
 
         if self.save_top_k == 0:
@@ -127,15 +188,16 @@ class ModelCheckpoint(Callback):
             return
         if self.epochs_since_last_check >= self.period:
             self.epochs_since_last_check = 0
-            filepath = f'{self.filepath}/{self.prefix}_ckpt_epoch_{epoch}.ckpt'
+
+            filepath = self.format_checkpoint_name(epoch, metrics)
             version_cnt = 0
             while os.path.isfile(filepath):
+                filepath = self.format_checkpoint_name(epoch, metrics, ver=version_cnt)
                 # this epoch called before
-                filepath = f'{self.filepath}/{self.prefix}_ckpt_epoch_{epoch}_v{version_cnt}.ckpt'
                 version_cnt += 1
 
             if self.save_top_k != -1:
-                current = logs.get(self.monitor)
+                current = metrics.get(self.monitor)
 
                 if current is None:
                     warnings.warn(
diff --git a/pytorch_lightning/core/__init__.py b/pytorch_lightning/core/__init__.py
index a2fb711..fac76ff 100644
--- a/pytorch_lightning/core/__init__.py
+++ b/pytorch_lightning/core/__init__.py
@@ -1,16 +1,64 @@
 """
-A LightningModule is a strict superclass of torch.nn.Module but provides an interface to standardize
-the "ingredients" for a research or production system.
+A LightningModule organizes your PyTorch code into the following sections:
 
-- The model/system definition (__init__)
-- The model/system computations (forward)
-- What happens in the training loop (training_step, training_end)
-- What happens in the validation loop (validation_step, validation_end)
-- What happens in the test loop (test_step, test_end)
-- What optimizers to use (configure_optimizers)
-- What data to use (train_dataloader, val_dataloader, test_dataloader)
+.. figure:: /_images/lightning_module/pt_to_pl.png
+   :alt: Convert from PyTorch to Lightning
 
-Most methods are optional. Here's a minimal example.
+
+Notice a few things.
+
+    1. It's the SAME code.
+    2. The PyTorch code IS NOT abstracted - just organized.
+    3. All the other code that not in the LightningModule has been automated for you by the trainer
+         .. code-block:: python
+
+            net = Net()
+            trainer = Trainer()
+            trainer.fit(net)
+
+    4. There are no .cuda() or .to() calls... Lightning does these for you.
+        .. code-block:: python
+
+            # don't do in lightning
+            x = torch.Tensor(2, 3)
+            x = x.cuda()
+            x = x.to(device)
+
+            # do this instead
+            x = x  # leave it alone!
+
+            # or to init a new tensor
+            new_x = torch.Tensor(2, 3)
+            new_x = new_x.type_as(x.type())
+
+    5. There are no samplers for distributed, Lightning also does this for you.
+        .. code-block:: python
+
+            # Don't do in Lightning...
+            data = MNIST(...)
+            sampler = DistributedSampler(data)
+            DataLoader(data, sampler=sampler)
+
+            # do this instead
+            data = MNIST(...)
+            DataLoader(data)
+
+    6. A LightingModule is a torch.nn.Module but with added functionality. Use it as such!
+        .. code-block:: python
+
+            net = Net.load_from_checkpoint(PATH)
+            net.freeze()
+            out = net(x)
+
+Thus, to use Lightning, you just need to organize your code which takes about 30 minutes,
+(and let's be real, you probably should do anyhow).
+
+------------
+
+Minimal Example
+---------------
+
+Here are the only required methods.
 
 .. code-block:: python
 
@@ -23,10 +71,10 @@ Most methods are optional. Here's a minimal example.
 
     import pytorch_lightning as pl
 
-    class CoolModel(pl.LightningModule):
+    class LitModel(pl.LightningModule):
 
         def __init__(self):
-            super(CoolModel, self).__init__()
+            super(LitModel, self).__init__()
             self.l1 = torch.nn.Linear(28 * 28, 10)
 
         def forward(self, x):
@@ -37,64 +85,231 @@ Most methods are optional. Here's a minimal example.
             y_hat = self.forward(x)
             return {'loss': F.cross_entropy(y_hat, y)}
 
-        def validation_step(self, batch, batch_idx):
-            # OPTIONAL
-            x, y = batch
-            y_hat = self.forward(x)
-            return {'val_loss': F.cross_entropy(y_hat, y)}
+        def train_dataloader(self):
+            return DataLoader(MNIST(os.getcwd(), train=True, download=True,
+                              transform=transforms.ToTensor()), batch_size=32)
 
-        def validation_end(self, outputs):
-            # OPTIONAL
-            val_loss_mean = torch.stack([x['val_loss'] for x in outputs]).mean()
-            return {'val_loss': val_loss_mean}
+        def configure_optimizers(self):
+            return torch.optim.Adam(self.parameters(), lr=0.02)
 
-        def test_step(self, batch, batch_idx):
-            # OPTIONAL
-            x, y = batch
-            y_hat = self.forward(x)
-            return {'test_loss': F.cross_entropy(y_hat, y)}
+Which you can train by doing:
 
-        def test_end(self, outputs):
-            # OPTIONAL
-            test_loss_mean = torch.stack([x['test_loss'] for x in outputs]).mean()
-            return {'test_loss': test_loss_mean}
+.. code-block:: python
 
-        def configure_optimizers(self):
-            # REQUIRED
-            return torch.optim.Adam(self.parameters(), lr=0.02)
+   trainer = pl.Trainer()
+   model = LitModel()
 
-        @pl.data_loader
-        def train_dataloader(self):
-            return DataLoader(MNIST(os.getcwd(), train=True, download=True,
-                              transform=transforms.ToTensor()), batch_size=32)
+   trainer.fit(model)
 
-        @pl.data_loader
-        def val_dataloader(self):
-            # OPTIONAL
-            # can also return a list of val dataloaders
-            return DataLoader(MNIST(os.getcwd(), train=True, download=True,
-                              transform=transforms.ToTensor()), batch_size=32)
+----------
 
-        @pl.data_loader
-        def test_dataloader(self):
-            # OPTIONAL
-            # can also return a list of test dataloaders
-            return DataLoader(MNIST(os.getcwd(), train=False, download=True,
-                              transform=transforms.ToTensor()), batch_size=32)
+Training loop structure
+-----------------------
+
+The general pattern is that each loop (training, validation, test loop)
+has 2 methods:
 
-Once you've defined the LightningModule, fit  it using a trainer.
+- ``` ___step ```
+- ``` ___epoch_end```
+
+To show how lightning calls these, let's use the validation loop as an example
 
 .. code-block:: python
 
-   trainer = pl.Trainer()
-   model = CoolModel()
+    val_outs = []
+    for val_batch in val_data:
+        # do something with each batch
+        out = validation_step(val_batch)
+        val_outs.append(out)
 
-   trainer.fit(model)
+    # do something with the outputs for all batches
+    # like calculate validation set accuracy or loss
+    validation_epoch_end(val_outs)
+
+Add validation loop
+^^^^^^^^^^^^^^^^^^^
+
+Thus, if we wanted to add a validation loop you would add this to your LightningModule
+
+.. code-block:: python
+
+        class LitModel(pl.LightningModule):
+            def validation_step(self, batch, batch_idx):
+                x, y = batch
+                y_hat = self.forward(x)
+                return {'val_loss': F.cross_entropy(y_hat, y)}
+
+            def validation_epoch_end(self, outputs):
+                val_loss_mean = torch.stack([x['val_loss'] for x in outputs]).mean()
+                return {'val_loss': val_loss_mean}
+
+            def val_dataloader(self):
+                # can also return a list of val dataloaders
+                return DataLoader(...)
+
+Add test loop
+^^^^^^^^^^^^^
+
+.. code-block:: python
+
+        class LitModel(pl.LightningModule):
+            def test_step(self, batch, batch_idx):
+                x, y = batch
+                y_hat = self.forward(x)
+                return {'test_loss': F.cross_entropy(y_hat, y)}
+
+            def test_epoch_end(self, outputs):
+                test_loss_mean = torch.stack([x['test_loss'] for x in outputs]).mean()
+                return {'test_loss': test_loss_mean}
+
+            def test_dataloader(self):
+                # can also return a list of test dataloaders
+                return DataLoader(...)
+
+However, the test loop won't ever be called automatically to make sure you
+don't run your test data by accident. Instead you have to explicitly call:
+
+.. code-block:: python
+
+    # call after training
+    trainer = Trainer()
+    trainer.fit(model)
+    trainer.test()
+
+    # or call with pretrained model
+    model = MyLightningModule.load_from_checkpoint(PATH)
+    trainer = Trainer()
+    trainer.test(model)
+
+----------
+
+Training_step_end method
+------------------------
+When using dataParallel or distributedDataParallel2, the training_step
+will be operating on a portion of the batch. This is normally ok but in special
+cases like calculating NCE loss using negative samples, we might want to
+perform a softmax across all samples in the batch.
+
+For these types of situations, each loop has an additional ```__step_end``` method
+which allows you to operate on the pieces of the batch
+
+.. code-block:: python
+
+        training_outs = []
+        for train_batch in train_data:
+            # dp, ddp2 splits the batch
+            sub_batches = split_batches_for_dp(batch)
+
+            # run training_step on each piece of the batch
+            batch_parts_outputs = [training_step(sub_batch) for sub_batch in sub_batches]
+
+            # do softmax with all pieces
+            out = training_step_end(batch_parts_outputs)
+            training_outs.append(out)
+
+        # do something with the outputs for all batches
+        # like calculate validation set accuracy or loss
+        training_epoch_end(val_outs)
+
+----------
+
+Remove cuda calls
+-----------------
+In a LightningModule, all calls to ```.cuda()```
+and ```.to(device)``` should be removed. Lightning will do these
+automatically. This will allow your code to work on CPUs, TPUs and GPUs.
+
+When you init a new tensor in your code, just use type_as
+
+.. code-block:: python
+
+    def training_step(self, batch, batch_idx):
+        x, y = batch
+
+        # put the z on the appropriate gpu or tpu core
+        z = sample_noise()
+        z = z.type_as(x.type())
 
+----------
+
+Data preparation
+----------------
+Data preparation in PyTorch follows 5 steps:
+
+    1. Download
+    2. Clean and (maybe) save to disk
+    3. Load inside dataset
+    4. Apply transforms (rotate, tokenize, etc...)
+    5. Wrap inside a dataloader
+
+When working in distributed settings, steps 1 and 2 have to be done
+from a single GPU, otherwise you will overwrite these files from
+every GPU. The lightningModule has the ```prepare_data``` method to
+allow for this
+
+.. code-block:: python
+
+    def prepare_data(self):
+        # download
+        mnist_train = MNIST(os.getcwd(), train=True, download=True,
+                            transform=transforms.ToTensor())
+        mnist_test = MNIST(os.getcwd(), train=False, download=True,
+                            transform=transforms.ToTensor())
+
+        # train/val split
+        mnist_train, mnist_val = random_split(mnist_train, [55000, 5000])
+
+        # assign to use in dataloaders
+        self.train_dataset = mnist_train
+        self.val_dataset = mnist_val
+        self.test_dataset = mnist_test
+
+      def train_dataloader(self):
+        return DataLoader(self.train_dataset, batch_size=64)
+
+      def val_dataloader(self):
+        return DataLoader(self.mnist_val, batch_size=64)
+
+      def test_dataloader(self):
+        return DataLoader(self.mnist_test, batch_size=64)
+
+.. note:: ``prepare_data`` is called once.
+
+.. note:: Do anything with data that needs to happen ONLY once here, like download, tokenize, etc...
+
+Lifecycle
+---------
+The methods in the LightningModule are called in this order:
+
+    1. ```__init__```
+    2. ```prepare_data```
+    3. ```configure_optimizers```
+    4. ```train_dataloader```
+
+    If you define a validation loop then
+
+    5. ```val_dataloader```
+
+    And if you define a test loop:
+
+    6. ```test_dataloader```
+
+.. note:: ``test_dataloader`` is only called with ``.test()``
+
+In every epoch, the loop methods are called in this frequency:
+
+1. ```validation_step``` called every batch
+2. ```validation_epoch_end``` called every epoch
+
+Live demo
+---------
 Check out this
 `COLAB <https://colab.research.google.com/drive/1F_RNcHzTfFuQf-LeKvSlud6x7jXYkG31#scrollTo=HOk9c4_35FKg>`_
 for a live demo.
 
+LightningModule Class
+---------------------
+
 """
 
 from .decorators import data_loader
diff --git a/pytorch_lightning/core/decorators.py b/pytorch_lightning/core/decorators.py
index 3448fda..3cd22c2 100644
--- a/pytorch_lightning/core/decorators.py
+++ b/pytorch_lightning/core/decorators.py
@@ -1,34 +1,14 @@
-import traceback
-from functools import wraps
+import warnings
 
 
 def data_loader(fn):
     """Decorator to make any fx with this use the lazy property.
 
-    :param fn:
-    :return:
+    Warnings:
+        This decorator deprecated in v0.7.0 and it will be removed v0.9.0.
     """
-    wraps(fn)
-    attr_name = '_lazy_' + fn.__name__
-    @wraps(fn)
-    def _get_data_loader(self):
-        try:
-            value = getattr(self, attr_name)
-        except AttributeError:
-            try:
-                value = fn(self)  # Lazy evaluation, done only once.
-                if (
-                        value is not None and
-                        not isinstance(value, list) and
-                        fn.__name__ in ['test_dataloader', 'val_dataloader']
-                ):
-                    value = [value]
-            except AttributeError as e:
-                # Guard against AttributeError suppression. (Issue #142)
-                traceback.print_exc()
-                error = f'{fn.__name__}: An AttributeError was encountered: ' + str(e)
-                raise RuntimeError(error) from e
-            setattr(self, attr_name, value)  # Memoize evaluation.
-        return value
+    warnings.warn('`data_loader` decorator deprecated in v0.7.0. Will be removed v0.9.0', DeprecationWarning)
 
-    return _get_data_loader
+    def inner_fx(self):
+        return fn(self)
+    return inner_fx
diff --git a/pytorch_lightning/core/grads.py b/pytorch_lightning/core/grads.py
index d98a6ef..b5d2d56 100644
--- a/pytorch_lightning/core/grads.py
+++ b/pytorch_lightning/core/grads.py
@@ -1,13 +1,14 @@
 """
 Module to describe gradients
 """
+from typing import Dict
 
 from torch import nn
 
 
 class GradInformation(nn.Module):
 
-    def grad_norm(self, norm_type):
+    def grad_norm(self, norm_type: float) -> Dict[str, int]:
         results = {}
         total_norm = 0
         for name, p in self.named_parameters():
diff --git a/pytorch_lightning/core/hooks.py b/pytorch_lightning/core/hooks.py
index dca3b36..d903de2 100644
--- a/pytorch_lightning/core/hooks.py
+++ b/pytorch_lightning/core/hooks.py
@@ -6,15 +6,19 @@ There are cases when you might want to do something different at different parts
  To enable a hook, simply override the method in your LightningModule and the trainer will call it at the correct time.
 
 **Contributing** If there's a hook you'd like to add, simply:
+
 1. Fork PyTorchLightning.
+
 2. Add the hook :py:mod:`pytorch_lightning.base_module.hooks.py`.
+
 3. Add the correct place in the :py:mod:`pytorch_lightning.models.trainer` where it should be called.
 
 """
-
+from typing import Any
 
 import torch
-
+from torch import Tensor
+from torch.optim.optimizer import Optimizer
 
 try:
     from apex import amp
@@ -33,48 +37,45 @@ class ModelHooks(torch.nn.Module):
         :return:
         """
 
-    def on_train_start(self):
+    def on_train_start(self) -> None:
         """Called at the beginning of training before sanity check
-        :return:
         """
         # do something at the start of training
 
-    def on_train_end(self):
+    def on_train_end(self) -> None:
         """
         Called at the end of training before logger experiment is closed
-        :return:
         """
         # do something at the end of training
 
-    def on_batch_start(self, batch):
+    def on_batch_start(self, batch: Any) -> None:
         """Called in the training loop before anything happens for that batch.
 
         :param batch:
-        :return:
         """
         # do something when the batch starts
 
-    def on_batch_end(self):
+    def on_batch_end(self) -> None:
         """Called in the training loop after the batch."""
         # do something when the batch ends
 
-    def on_epoch_start(self):
+    def on_epoch_start(self) -> None:
         """Called in the training loop at the very beginning of the epoch."""
         # do something when the epoch starts
 
-    def on_epoch_end(self):
+    def on_epoch_end(self) -> None:
         """Called in the training loop at the very end of the epoch."""
         # do something when the epoch ends
 
-    def on_pre_performance_check(self):
+    def on_pre_performance_check(self) -> None:
         """Called at the very beginning of the validation loop."""
         # do something before validation starts
 
-    def on_post_performance_check(self):
+    def on_post_performance_check(self) -> None:
         """Called at the very end of the validation loop."""
         # do something before validation end
 
-    def on_before_zero_grad(self, optimizer):
+    def on_before_zero_grad(self, optimizer: Optimizer) -> None:
         """Called after optimizer.step() and before optimizer.zero_grad()
 
         Called in the training loop after taking an optimizer step and before zeroing grads.
@@ -86,17 +87,13 @@ class ModelHooks(torch.nn.Module):
             model.on_before_zero_grad(optimizer) # < ---- called here
             optimizer.zero_grad
 
-        :param optimizer:
-        :return:
+        :param optimizer: The optimizer for which grads should be zeroed.
         """
         # do something with the optimizer or inspect it.
 
-    def on_after_backward(self):
-        """Called after loss.backward() and before optimizers do anything.
+    def on_after_backward(self) -> None:
+        """Called in the training loop after loss.backward() and before optimizers do anything.
 
-        :return:
-
-        Called in the training loop after model.backward()
         This is the ideal place to inspect or log gradient information
 
         .. code-block:: python
@@ -113,14 +110,13 @@ class ModelHooks(torch.nn.Module):
 
         """
 
-    def backward(self, trainer, loss, optimizer, optimizer_idx):
+    def backward(self, trainer, loss: Tensor, optimizer: Optimizer, optimizer_idx: int) -> None:
         """Override backward with your own implementation if you need to
 
         :param trainer: Pointer to the trainer
         :param loss: Loss is already scaled by accumulated grads
         :param optimizer: Current optimizer being used
         :param optimizer_idx: Index of the current optimizer being used
-        :return:
 
         Called to perform backward step.
         Feel free to override as needed.
diff --git a/pytorch_lightning/core/lightning.py b/pytorch_lightning/core/lightning.py
index 7a09aab..b531c15 100644
--- a/pytorch_lightning/core/lightning.py
+++ b/pytorch_lightning/core/lightning.py
@@ -1,20 +1,33 @@
 import collections
+import inspect
 import logging as log
-import csv
 import os
 import warnings
 from abc import ABC, abstractmethod
 from argparse import Namespace
+from typing import Any, Callable, Dict, List, Optional, Tuple, Union
 
 import torch
 import torch.distributed as dist
+from torch import Tensor
+from torch.nn.parallel import DistributedDataParallel
+from torch.optim import Adam
+from torch.optim.optimizer import Optimizer
+from torch.utils.data import DataLoader
 
-from pytorch_lightning.core.decorators import data_loader
 from pytorch_lightning.core.grads import GradInformation
 from pytorch_lightning.core.hooks import ModelHooks
-from pytorch_lightning.core.saving import ModelIO
 from pytorch_lightning.core.memory import ModelSummary
+from pytorch_lightning.core.saving import ModelIO, load_hparams_from_tags_csv
 from pytorch_lightning.overrides.data_parallel import LightningDistributedDataParallel
+from pytorch_lightning.utilities.debugging import MisconfigurationException
+
+try:
+    import torch_xla.core.xla_model as xm
+    XLA_AVAILABLE = True
+
+except ImportError:
+    XLA_AVAILABLE = False
 
 
 class LightningModule(ABC, GradInformation, ModelIO, ModelHooks):
@@ -58,14 +71,35 @@ class LightningModule(ABC, GradInformation, ModelIO, ModelHooks):
         #: True if using amp
         self.use_amp = False
 
+        self.hparams = None
+
+    def print(self, *args, **kwargs) -> None:
+        r"""
+        Prints only from process 0. Use this in any distributed mode to log only once
+
+        Args:
+            x (object): The thing to print
+
+        Examples:
+        .. code-block:: python
+
+            # example if we were using this model as a feature extractor
+            def forward(self, x):
+                self.print(x, 'in loader')
+
+        """
+        if self.trainer.proc_rank == 0:
+            print(*args, **kwargs)
+
     @abstractmethod
     def forward(self, *args, **kwargs):
         r"""
         Same as torch.nn.Module.forward(), however in Lightning you want this to define
         the  operations you want to use for prediction (ie: on a server or as a feature extractor).
 
-        Normally you'd call self.forward() from your training_step() method. This makes it easy to write a complex
-        system for training with the outputs you'd want in a prediction setting.
+        Normally you'd call self.forward() from your training_step() method.
+        This makes it easy to write a complex system for training with the outputs
+        you'd want in a prediction setting.
 
         Args:
             x (tensor): Whatever  you decide to define in the forward method
@@ -73,212 +107,223 @@ class LightningModule(ABC, GradInformation, ModelIO, ModelHooks):
         Return:
             Predicted output
 
-        Example
-        -------
-
-        .. code-block:: python
+        Examples:
+            .. code-block:: python
 
-            # example if we were using this model as a feature extractor
-            def forward(self, x):
-                feature_maps = self.convnet(x)
-                return feature_maps
+                # example if we were using this model as a feature extractor
+                def forward(self, x):
+                    feature_maps = self.convnet(x)
+                    return feature_maps
 
-            def training_step(self, batch, batch_idx):
-                x, y = batch
-                feature_maps = self.forward(x)
-                logits = self.classifier(feature_maps)
+                def training_step(self, batch, batch_idx):
+                    x, y = batch
+                    feature_maps = self.forward(x)
+                    logits = self.classifier(feature_maps)
 
-                # ...
-                return loss
+                    # ...
+                    return loss
 
-            # splitting it this way allows model to be used a feature extractor
-            model = MyModelAbove()
+                # splitting it this way allows model to be used a feature extractor
+                model = MyModelAbove()
 
-            inputs = server.get_request()
-            results = model(inputs)
-            server.write_results(results)
+                inputs = server.get_request()
+                results = model(inputs)
+                server.write_results(results)
 
-            # -------------
-            # This is in stark contrast to torch.nn.Module where normally you would have this:
-            def forward(self, batch):
-                x, y = batch
-                feature_maps = self.convnet(x)
-                logits = self.classifier(feature_maps)
-                return logits
+                # -------------
+                # This is in stark contrast to torch.nn.Module where normally you would have this:
+                def forward(self, batch):
+                    x, y = batch
+                    feature_maps = self.convnet(x)
+                    logits = self.classifier(feature_maps)
+                    return logits
 
         """
 
-    @abstractmethod
-    def training_step(self, *args, **kwargs):
+    def training_step(self, *args, **kwargs) -> Union[
+        int, Dict[str, Union[Tensor, Dict[str, Tensor]]]
+    ]:
         r"""return loss, dict with metrics for tqdm
 
         Args:
-            batch (torch.nn.Tensor | (Tensor, Tensor) | [Tensor, Tensor]): The output of your dataloader.
-                A tensor, tuple or list
+            batch (torch.nn.Tensor | (Tensor, Tensor) | [Tensor, Tensor]): The output of your
+                dataloader. A tensor, tuple or list
             batch_idx (int): Integer displaying index of this batch
             optimizer_idx (int): If using multiple optimizers, this argument will also be present.
-            hiddens(:`Tensor <https://pytorch.org/docs/stable/tensors.html>`_): Passed in if truncated_bptt_steps > 0.
-
-        :param
+            hiddens(:`Tensor <https://pytorch.org/docs/stable/tensors.html>`_):
+                Passed in if truncated_bptt_steps > 0.
 
-        :return: dict with loss key and optional log, progress keys
-         if implementing training_step, return whatever you need in that step:
+        Return:
+            dict with loss key and optional log, progress keys
+             if implementing training_step, return whatever you need in that step:
 
-            - loss -> tensor scalar [REQUIRED]
-            - progress_bar -> Dict for progress bar display. Must have only tensors
-            - log -> Dict of metrics to add to logger. Must have only tensors (no images, etc)
+                - loss -> tensor scalar [REQUIRED]
+                - progress_bar -> Dict for progress bar display. Must have only tensors
+                - log -> Dict of metrics to add to logger. Must have only tensors (no images, etc)
 
         In this step you'd normally do the forward pass and calculate the loss for a batch.
-         You can also do fancier things like multiple forward passes or something specific to your model.
-
-        Example
-        -------
+        You can also do fancier things like multiple forward passes or something model specific.
 
-        .. code-block:: python
+        Examples:
+            .. code-block:: python
 
-            def training_step(self, batch, batch_idx):
-                x, y, z = batch
+                def training_step(self, batch, batch_idx):
+                    x, y, z = batch
 
-                # implement your own
-                out = self.forward(x)
-                loss = self.loss(out, x)
+                    # implement your own
+                    out = self.forward(x)
+                    loss = self.loss(out, x)
 
-                logger_logs = {'training_loss': loss} # optional (MUST ALL BE TENSORS)
+                    logger_logs = {'training_loss': loss} # optional (MUST ALL BE TENSORS)
 
-                # if using TestTubeLogger or TensorBoardLogger you can nest scalars
-                logger_logs = {'losses': logger_logs} # optional (MUST ALL BE TENSORS)
+                    # if using TestTubeLogger or TensorBoardLogger you can nest scalars
+                    logger_logs = {'losses': logger_logs} # optional (MUST ALL BE TENSORS)
 
-                output = {
-                    'loss': loss, # required
-                    'progress_bar': {'training_loss': loss}, # optional (MUST ALL BE TENSORS)
-                    'log': logger_logs
-                }
+                    output = {
+                        'loss': loss, # required
+                        'progress_bar': {'training_loss': loss}, # optional (MUST ALL BE TENSORS)
+                        'log': logger_logs
+                    }
 
-                # return a dict
-                return output
+                    # return a dict
+                    return output
 
-        If you define multiple optimizers, this step will also be called with an additional `optimizer_idx` param.
+            If you define multiple optimizers, this step will be called with an additional
+            `optimizer_idx` param.
 
-        .. code-block:: python
+            .. code-block:: python
 
-            # Multiple optimizers (ie: GANs)
-            def training_step(self, batch, batch_idx, optimizer_idx):
-                if optimizer_idx == 0:
-                    # do training_step with encoder
-                if optimizer_idx == 1:
-                    # do training_step with decoder
+                # Multiple optimizers (ie: GANs)
+                def training_step(self, batch, batch_idx, optimizer_idx):
+                    if optimizer_idx == 0:
+                        # do training_step with encoder
+                    if optimizer_idx == 1:
+                        # do training_step with decoder
 
 
-        If you add truncated back propagation through time you will also get an additional
-         argument with the hidden states of the previous step.
+            If you add truncated back propagation through time you will also get an additional
+             argument with the hidden states of the previous step.
 
-        .. code-block:: python
+            .. code-block:: python
 
-            # Truncated back-propagation through time
-            def training_step(self, batch, batch_idx, hiddens):
-                # hiddens are the hiddens from the previous truncated backprop step
-                ...
-                out, hiddens = self.lstm(data, hiddens)
-                ...
+                # Truncated back-propagation through time
+                def training_step(self, batch, batch_idx, hiddens):
+                    # hiddens are the hiddens from the previous truncated backprop step
+                    ...
+                    out, hiddens = self.lstm(data, hiddens)
+                    ...
 
-                return {
-                    "loss": ...,
-                    "hiddens": hiddens  # remember to detach() this
-                }
+                    return {
+                        "loss": ...,
+                        "hiddens": hiddens  # remember to detach() this
+                    }
 
-        You can also return a -1 instead of a dict to stop the current loop. This is useful
-         if you want to break out of the current training epoch early.
+            You can also return a -1 instead of a dict to stop the current loop. This is useful
+             if you want to break out of the current training epoch early.
         """
 
     def training_end(self, *args, **kwargs):
-        """return loss, dict with metrics for tqdm
-
-        :param outputs: What you return in `training_step`.
-        :return dict: dictionary with loss key and optional log, progress keys:
-            - loss -> tensor scalar [REQUIRED]
-            - progress_bar -> Dict for progress bar display. Must have only tensors
-            - log -> Dict of metrics to add to logger. Must have only tensors (no images, etc)
-
-        In certain cases (dp, ddp2), you might want to use all outputs of every process to do something.
-        For instance, if using negative samples, you could run a batch via dp and use ALL the outputs
-        for a single softmax across the full batch (ie: the denominator would use the full batch).
+        """
+        Warnings:
+            Deprecated in v0.7.0. use training_step_end instead
+        """
 
-        In this case you should define training_end to perform those calculations.
+    def training_step_end(self, *args, **kwargs) -> Dict[
+        str, Union[Tensor, Dict[str, Tensor]]
+    ]:
+        """
+        Use this when training with dp or ddp2 because training_step will operate
+        on only part of the batch. However, this is still optional
+        and only needed for things like softmax or NCE loss.
 
-        Example
-        -------
+        .. note:: If you later switch to ddp or some other mode, this will still be called
+            so that you don't have to change your code
 
         .. code-block:: python
 
-            # WITHOUT training_end
-            # if used in DP or DDP2, this batch is 1/num_gpus large
-            def training_step(self, batch, batch_idx):
-                # batch is 1/num_gpus big
-                x, y = batch
+            # pseudocode
+            sub_batches = split_batches_for_dp(batch)
+            batch_parts_outputs = [training_step(sub_batch) for sub_batch in sub_batches]
+            training_step_end(batch_parts_outputs)
 
-                out = self.forward(x)
-                loss = self.softmax(out)
-                loss = nce_loss(loss)
-                return {'loss': loss}
-
-            # --------------
-            # with training_end to do softmax over the full batch
-            def training_step(self, batch, batch_idx):
-                # batch is 1/num_gpus big
-                x, y = batch
+        Args:
+            batch_parts_outputs: What you return in `training_step` for each batch part.
 
-                out = self.forward(x)
-                return {'out': out}
+        Return:
+            dictionary with loss key and optional log, progress keys:
+                - loss -> tensor scalar [REQUIRED]
+                - progress_bar -> Dict for progress bar display. Must have only tensors
+                - log -> Dict of metrics to add to logger. Must have only tensors (no images, etc)
 
-            def training_end(self, outputs):
-                # this out is now the full size of the batch
-                out = outputs['out']
+        In this case you should define training_step_end to perform those calculations.
 
-                # this softmax now uses the full batch size
-                loss = self.softmax(out)
-                loss = nce_loss(loss)
-                return {'loss': loss}
+        Examples:
+            .. code-block:: python
 
-        If you define multiple optimizers, this step will also be called with an additional `optimizer_idx` param.
+                # WITHOUT training_step_end
+                # if used in DP or DDP2, this batch is 1/num_gpus large
+                def training_step(self, batch, batch_idx):
+                    # batch is 1/num_gpus big
+                    x, y = batch
 
-        .. code-block:: python
+                    out = self.forward(x)
+                    loss = self.softmax(out)
+                    loss = nce_loss(loss)
+                    return {'loss': loss}
 
-            # Multiple optimizers (ie: GANs)
-            def training_step(self, batch, batch_idx, optimizer_idx):
-                if optimizer_idx == 0:
-                    # do training_step with encoder
-                if optimizer_idx == 1:
-                    # do training_step with decoder
+                # --------------
+                # with training_step_end to do softmax over the full batch
+                def training_step(self, batch, batch_idx):
+                    # batch is 1/num_gpus big
+                    x, y = batch
 
-        If you add truncated back propagation through time you will also get an additional argument
-         with the hidden states of the previous step.
+                    out = self.forward(x)
+                    return {'out': out}
 
-        .. code-block:: python
+                def training_step_end(self, outputs):
+                    # this out is now the full size of the batch
+                    out = outputs['out']
 
-            # Truncated back-propagation through time
-            def training_step(self, batch, batch_idx, hiddens):
-                # hiddens are the hiddens from the previous truncated backprop step
+                    # this softmax now uses the full batch size
+                    loss = nce_loss(loss)
+                    return {'loss': loss}
 
-        You can also return a -1 instead of a dict to stop the current loop. This is useful if you want to
-        break out of the current training epoch early.
+        .. seealso:: see the `multi-gpu guide for more details <multi_gpu.rst#caveats>`_.
         """
 
-    def validation_step(self, *args, **kwargs):
+    def validation_step(self, *args, **kwargs) -> Dict[str, Tensor]:
         r"""
+        Operate on a single batch of data from the validation set
+        In this step you'd might generate examples or calculate anything of interest like accuracy.
+
+        .. code-block:: python
 
-        This is the validation loop. It is called for each batch of the validation set.
-        Whatever is returned from here will be passed in as a list on validation_end.
-        In this step you'd normally generate examples or calculate anything of interest such as accuracy.
+            # the pseudocode for these calls
+            val_outs = []
+            for val_batch in val_data:
+                out = validation_step(train_batch)
+                val_outs.append(out
+                validation_epoch_end(val_outs)
 
         Args:
-            batch (torch.nn.Tensor | (Tensor, Tensor) | [Tensor, Tensor]): The output of your dataloader.
-                A tensor, tuple or list
+            batch (torch.nn.Tensor | (Tensor, Tensor) | [Tensor, Tensor]): The output of your
+                dataloader. A tensor, tuple or list
             batch_idx (int): The index of this batch
-            dataloader_idx (int): The index of the dataloader that produced this batch (only if multiple
-                val datasets used)
+            dataloader_idx (int): The index of the dataloader that produced this batch
+                (only if multiple val datasets used)
 
         Return:
-            Dict or OrderedDict - passed to the validation_end step
+            Dict or OrderedDict - passed to validation_epoch_end.
+            If you defined validation_step_end it will go to that first.
+
+        .. code-block:: python
+
+            # pseudocode of order
+            out = validation_step()
+            if defined('validation_step_end'):
+                out = validation_step_end(out)
+            out = validation_epoch_end(out)
+
 
         .. code-block:: python
 
@@ -286,262 +331,423 @@ class LightningModule(ABC, GradInformation, ModelIO, ModelHooks):
             def validation_step(self, batch, batch_idx)
 
             # if you have multiple val dataloaders:
-            def validation_step(self, batch, batch_idx, dataloader_idxdx)
+            def validation_step(self, batch, batch_idx, dataloader_idx)
 
-        Example
-        -------
+        Examples:
+            .. code-block:: python
 
-        .. code-block:: python
+                # CASE 1: A single validation dataset
+                def validation_step(self, batch, batch_idx):
+                    x, y = batch
+
+                    # implement your own
+                    out = self.forward(x)
+                    loss = self.loss(out, y)
+
+                    # log 6 example images
+                    # or generated text... or whatever
+                    sample_imgs = x[:6]
+                    grid = torchvision.utils.make_grid(sample_imgs)
+                    self.logger.experiment.add_image('example_images', grid, 0)
 
-            # CASE 1: A single validation dataset
-            def validation_step(self, batch, batch_idx):
-                x, y = batch
+                    # calculate acc
+                    labels_hat = torch.argmax(out, dim=1)
+                    val_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0)
 
-                # implement your own
-                out = self.forward(x)
-                loss = self.loss(out, y)
+                    # all optional...
+                    # return whatever you need for the collation function validation_end
+                    output = OrderedDict({
+                        'val_loss': loss_val,
+                        'val_acc': torch.tensor(val_acc), # everything must be a tensor
+                    })
 
-                # log 6 example images
-                # or generated text... or whatever
-                sample_imgs = x[:6]
-                grid = torchvision.utils.make_grid(sample_imgs)
-                self.logger.experiment.add_image('example_images', grid, 0)
+                    # return an optional dict
+                    return output
 
-                # calculate acc
-                labels_hat = torch.argmax(out, dim=1)
-                val_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0)
+            If you pass in multiple val datasets, validation_step will have an additional argument.
+
+            .. code-block:: python
+
+                # CASE 2: multiple validation datasets
+                def validation_step(self, batch, batch_idx, dataset_idx):
+                    # dataset_idx tells you which dataset this is.
+
+        .. note:: If you don't need to validate you don't need to implement this method.
 
-                # all optional...
-                # return whatever you need for the collation function validation_end
-                output = OrderedDict({
-                    'val_loss': loss_val,
-                    'val_acc': torch.tensor(val_acc), # everything must be a tensor
-                })
+        .. note:: When the validation_step is called, the model has been put in eval mode
+            and PyTorch gradients have been disabled. At the end of validation,
+            the model goes back to training mode and gradients are enabled.
+        """
 
-                # return an optional dict
-                return output
+    def validation_step_end(self, *args, **kwargs) -> Dict[str, Tensor]:
+        """
+        Use this when validating with dp or ddp2 because validation_step will operate
+        on only part of the batch. However, this is still optional
+        and only needed for things like softmax or NCE loss.
 
-        If you pass in multiple validation datasets, validation_step will have an additional argument.
+        .. note:: If you later switch to ddp or some other mode, this will still be called
+            so that you don't have to change your code
 
         .. code-block:: python
 
-            # CASE 2: multiple validation datasets
-            def validation_step(self, batch, batch_idx, dataset_idx):
-                # dataset_idx tells you which dataset this is.
+            # pseudocode
+            sub_batches = split_batches_for_dp(batch)
+            batch_parts_outputs = [validation_step(sub_batch) for sub_batch in sub_batches]
+            validation_step_end(batch_parts_outputs)
 
-        .. note:: If you don't need to validate you don't need to implement this method.
+        Args:
+            batch_parts_outputs: What you return in `validation_step` for each batch part.
+
+        Return:
+           Dict or OrderedDict - passed to the validation_epoch_end
+
+        In this case you should define validation_step_end to perform those calculations.
+
+        Examples:
+            .. code-block:: python
+
+                # WITHOUT validation_step_end
+                # if used in DP or DDP2, this batch is 1/num_gpus large
+                def validation_step(self, batch, batch_idx):
+                    # batch is 1/num_gpus big
+                    x, y = batch
+
+                    out = self.forward(x)
+                    loss = self.softmax(out)
+                    loss = nce_loss(loss)
+                    return {'loss': loss}
+
+                # --------------
+                # with validation_step_end to do softmax over the full batch
+                def validation_step(self, batch, batch_idx):
+                    # batch is 1/num_gpus big
+                    x, y = batch
+
+                    out = self.forward(x)
+                    return {'out': out}
+
+                def validation_epoch_end(self, outputs):
+                    # this out is now the full size of the batch
+                    out = outputs['out']
+
+                    # this softmax now uses the full batch size
+                    loss = nce_loss(loss)
+                    return {'loss': loss}
 
-        .. note:: When the validation_step is called, the model has been put in eval mode and PyTorch gradients
-            have been disabled. At the end of validation, model goes back to training mode and gradients are enabled.
+        .. seealso:: see the `multi-gpu guide for more details <multi_gpu.rst#caveats>`_.
         """
 
-    def test_step(self, *args, **kwargs):
-        """return whatever outputs will need to be aggregated in test_end
+    def validation_end(self, outputs):
+        """
+        Warnings:
+            Deprecated in v0.7.0. use validation_epoch_end instead. Will be removed 1.0.0
+        """
 
-        :param batch: The output of your dataloader. A tensor, tuple or list
-        :param int batch_idx: Integer displaying which batch this is
-        :param int dataloader_idx: Integer displaying which dataloader this is (only if multiple test datasets used)
-        :return dict: Dict or OrderedDict with metrics to display in progress bar. All keys must be tensors.
+    def validation_epoch_end(
+            self,
+            outputs: Union[List[Dict[str, Tensor]], List[List[Dict[str, Tensor]]]]
+    ) -> Dict[str, Dict[str, Tensor]]:
+        """
+        Called at end of validation epoch with the output of all validation_steps
 
         .. code-block:: python
 
-            # if you have one test dataloader:
-            def test_step(self, batch, batch_idx)
+            # the pseudocode for these calls
 
-            # if you have multiple test dataloaders:
-            def test_step(self, batch, batch_idx, dataloader_idxdx)
+            val_outs = []
+            for val_batch in val_data:
+                out = validation_step(train_batch)
+                train_outs.append(out)
+            validation_epoch_end(val_outs)
+
+        Args:
+            outputs: List of outputs you defined in validation_step, or if there are multiple
+            dataloaders, a list containing a list of outputs for each dataloader
+
+        Return:
+            Dict or OrderedDict (dict): Dict has the following optional keys:
+            progress_bar -> Dict for progress bar display. Must have only tensors
+            log -> Dict of metrics to add to logger. Must have only tensors (no images, etc)
+
+        .. note:: If you didn't define a validation_step, this won't be called.
+
+        - The outputs here are strictly for logging or progress bar.
+        - If you don't need to display anything, don't return anything.
+        - If you want to manually set current step, you can specify the 'step' key in the 'log' Dict
+
+        Examples:
+            With a single dataloader
 
+            .. code-block:: python
 
-        **OPTIONAL**
-        If you don't need to test you don't need to implement this method. In this step you'd normally
-         generate examples or calculate anything of interest such as accuracy.
+                def validation_epoch_end(self, outputs):
+                    val_acc_mean = 0
+                    for output in outputs:
+                        val_acc_mean += output['val_acc']
+
+                    val_acc_mean /= len(outputs)
+                    tqdm_dict = {'val_acc': val_acc_mean.item()}
+
+                    # show val_loss and val_acc in progress bar but only log val_loss
+                    results = {
+                        'progress_bar': tqdm_dict,
+                        'log': {'val_acc': val_acc_mean.item()}
+                    }
+                    return results
+
+            With multiple dataloaders, `outputs` will be a list of lists. The outer list contains
+            one entry per dataloader, while the inner list contains the individual outputs of
+            each validation step for that dataloader.
+
+            .. code-block:: python
+
+                def validation_epoch_end(self, outputs):
+                    val_acc_mean = 0
+                    i = 0
+                    for dataloader_outputs in outputs:
+                        for output in dataloader_outputs:
+                            val_acc_mean += output['val_acc']
+                            i += 1
+
+                    val_acc_mean /= i
+                    tqdm_dict = {'val_acc': val_acc_mean.item()}
+
+                    # show val_loss and val_acc in progress bar but only log val_loss
+                    results = {
+                        'progress_bar': tqdm_dict,
+                        'log': {'val_acc': val_acc_mean.item(), 'step': self.current_epoch}
+                    }
+                    return results
+        """
+
+    def test_step(self, *args, **kwargs) -> Dict[str, Tensor]:
+        r"""
+        Operate on a single batch of data from the test set
+        In this step you'd normally generate examples or calculate anything of interest
+        such as accuracy.
+
+        .. code-block:: python
 
-        When the validation_step is called, the model has been put in eval mode and PyTorch gradients
-         have been disabled. At the end of validation, model goes back to training mode and gradients are enabled.
+            # the pseudocode for these calls
 
-        The dict you return here will be available in the `test_end` method.
+            test_outs = []
+            for test_batch in test_data:
+                out = test_step(train_batch)
+                test_outs.append(out)
+            test_epoch_end(test_outs)
 
-        This function is used when you execute `trainer.test()`.
+        Args:
+            batch (torch.nn.Tensor | (Tensor, Tensor) | [Tensor, Tensor]): The output of your
+                dataloader. A tensor, tuple or list
+            batch_idx (int): The index of this batch
+            dataloader_idx (int): The index of the dataloader that produced this batch
+                (only if multiple test datasets used)
 
-        Example
-        -------
+        Return:
+            Dict or OrderedDict - passed to the test_step_end
 
         .. code-block:: python
 
-            # CASE 1: A single test dataset
-            def test_step(self, batch, batch_idx):
-                x, y = batch
+            # if you have one test dataloader:
+            def test_step(self, batch, batch_idx)
+
+            # if you have multiple test dataloaders:
+            def test_step(self, batch, batch_idx, dataloader_idx)
+
+        Examples:
+            .. code-block:: python
+
+                # CASE 1: A single test dataset
+                def test_step(self, batch, batch_idx):
+                    x, y = batch
 
-                # implement your own
-                out = self.forward(x)
-                loss = self.loss(out, y)
+                    # implement your own
+                    out = self.forward(x)
+                    loss = self.loss(out, y)
 
-                # calculate acc
-                labels_hat = torch.argmax(out, dim=1)
-                test_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0)
+                    # log 6 example images
+                    # or generated text... or whatever
+                    sample_imgs = x[:6]
+                    grid = torchvision.utils.make_grid(sample_imgs)
+                    self.logger.experiment.add_image('example_images', grid, 0)
 
-                # all optional...
-                # return whatever you need for the collation function test_end
-                output = OrderedDict({
-                    'test_loss': loss_test,
-                    'test_acc': torch.tensor(test_acc), # everything must be a tensor
-                })
+                    # calculate acc
+                    labels_hat = torch.argmax(out, dim=1)
+                    val_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0)
 
-                # return an optional dict
-                return output
+                    # all optional...
+                    # return whatever you need for the collation function validation_end
+                    output = OrderedDict({
+                        'val_loss': loss_val,
+                        'val_acc': torch.tensor(val_acc), # everything must be a tensor
+                    })
 
+                    # return an optional dict
+                    return output
 
-        If you pass in multiple test datasets, `test_step` will have an additional argument.
+            If you pass in multiple validation datasets, validation_step will have an additional
+            argument.
 
         .. code-block:: python
 
-            # CASE 2: multiple test datasets
+            # CASE 2: multiple validation datasets
             def test_step(self, batch, batch_idx, dataset_idx):
                 # dataset_idx tells you which dataset this is.
 
+        .. note:: If you don't need to validate you don't need to implement this method.
 
-        The `dataset_idx` corresponds to the order of datasets returned in `test_dataloader`.
+        .. note:: When the test_step is called, the model has been put in eval mode and
+            PyTorch gradients have been disabled. At the end of the test epoch, the model goes back
+            to training mode and gradients are enabled.
         """
 
-    def validation_end(self, outputs):
-        """Outputs has the appended output after each validation step.
-
-        :param outputs: List of outputs you defined in validation_step, or if there are multiple dataloaders,
-         a list containing a list of outputs for each dataloader
-        :return dict: Dictionary or OrderedDict with optional:
-            progress_bar -> Dict for progress bar display. Must have only tensors
-            log -> Dict of metrics to add to logger. Must have only tensors (no images, etc)
+    def test_step_end(self, *args, **kwargs) -> Dict[str, Tensor]:
+        """
+        Use this when testing with dp or ddp2 because test_step will operate
+        on only part of the batch. However, this is still optional
+        and only needed for things like softmax or NCE loss.
 
-        If you didn't define a validation_step, this won't be called.
-         Called at the end of the validation loop with the outputs of validation_step.
+        .. note:: If you later switch to ddp or some other mode, this will still be called
+            so that you don't have to change your code
 
-        The outputs here are strictly for the progress bar.
-         If you don't need to display anything, don't return anything.
-         Any keys present in 'log', 'progress_bar' or the rest of the dictionary
-         are available for callbacks to access. If you want to manually set current step, you can specify it with
-         'step' key in the 'log' Dict.
+        .. code-block:: python
 
-        Example
-        -------
+            # pseudocode
+            sub_batches = split_batches_for_dp(batch)
+            batch_parts_outputs = [test_step(sub_batch) for sub_batch in sub_batches]
+            test_step_end(batch_parts_outputs)
 
-        With a single dataloader
+        Args:
+            batch_parts_outputs: What you return in `training_step` for each batch part.
 
-        .. code-block:: python
+        Return:
+             Dict or OrderedDict - passed to the test_epoch_end
 
-            def validation_end(self, outputs):
-                val_loss_mean = 0
-                val_acc_mean = 0
-                for output in outputs:
-                    val_loss_mean += output['val_loss']
-                    val_acc_mean += output['val_acc']
+        In this case you should define test_step_end to perform those calculations.
 
-                val_loss_mean /= len(outputs)
-                val_acc_mean /= len(outputs)
-                tqdm_dict = {'val_loss': val_loss_mean.item(), 'val_acc': val_acc_mean.item()}
+        Examples:
+            .. code-block:: python
 
-                # show val_loss and val_acc in progress bar but only log val_loss
-                results = {
-                    'progress_bar': tqdm_dict,
-                    'log': {'val_loss': val_loss_mean.item()}
-                }
-                return results
+                # WITHOUT test_step_end
+                # if used in DP or DDP2, this batch is 1/num_gpus large
+                def test_step(self, batch, batch_idx):
+                    # batch is 1/num_gpus big
+                    x, y = batch
 
-        With multiple dataloaders, `outputs` will be a list of lists. The outer list contains
-        one entry per dataloader, while the inner list contains the individual outputs of
-        each validation step for that dataloader.
+                    out = self.forward(x)
+                    loss = self.softmax(out)
+                    loss = nce_loss(loss)
+                    return {'loss': loss}
 
-        .. code-block:: python
+                # --------------
+                # with test_step_end to do softmax over the full batch
+                def test_step(self, batch, batch_idx):
+                    # batch is 1/num_gpus big
+                    x, y = batch
 
-            def validation_end(self, outputs):
-                val_loss_mean = 0
-                val_acc_mean = 0
-                i = 0
-                for dataloader_outputs in outputs:
-                    for output in dataloader_outputs:
-                        val_loss_mean += output['val_loss']
-                        val_acc_mean += output['val_acc']
-                        i += 1
+                    out = self.forward(x)
+                    return {'out': out}
 
-                val_loss_mean /= i
-                val_acc_mean /= i
-                tqdm_dict = {'val_loss': val_loss_mean.item(), 'val_acc': val_acc_mean.item()}
+                def test_step_end(self, outputs):
+                    # this out is now the full size of the batch
+                    out = outputs['out']
 
-                # show val_loss and val_acc in progress bar but only log val_loss
-                results = {
-                    'progress_bar': tqdm_dict,
-                    'log': {'val_loss': val_loss_mean.item(), 'step': self.current_epoch}
-                }
-                return results
+                    # this softmax now uses the full batch size
+                    loss = nce_loss(loss)
+                    return {'loss': loss}
 
+        .. seealso:: see the `multi-gpu guide for more details <multi_gpu.rst#caveats>`_.
         """
 
     def test_end(self, outputs):
-        """Outputs has the appended output after each test step.
-
-        :param outputs:  List of outputs you defined in test_step, or if there are multiple dataloaders,
-         a list containing a list of outputs for each dataloader
-        :return dict: Dict of OrderedDict with metrics to display in progress bar
-
-        If you didn't define a test_step, this won't be called.
-         Called at the end of the test step with the output of each test_step.
-         The outputs here are strictly for the progress bar.
-         If you don't need to display anything, don't return anything.
+        """
+        Warnings:
+             Deprecated in v0.7.0. use test_epoch_end instead. Will be removed 1.0.0
+        """
 
-        Example
-        -------
+    def test_epoch_end(
+            self,
+            outputs: Union[List[Dict[str, Tensor]], List[List[Dict[str, Tensor]]]]
+    ) -> Dict[str, Dict[str, Tensor]]:
+        """
+        Called at end of test epoch with the output of all test_steps.
 
         .. code-block:: python
 
-            def test_end(self, outputs):
-                test_loss_mean = 0
-                test_acc_mean = 0
-                for output in outputs:
-                    test_loss_mean += output['test_loss']
-                    test_acc_mean += output['test_acc']
+            # the pseudocode for these calls
 
-                test_loss_mean /= len(outputs)
-                test_acc_mean /= len(outputs)
-                tqdm_dict = {'test_loss': test_loss_mean.item(), 'test_acc': test_acc_mean.item()}
+            test_outs = []
+            for test_batch in test_data:
+                out = test_step(test_batch)
+                test_outs.append(out)
+            test_epoch_end(test_outs)
 
-                # show test_loss and test_acc in progress bar but only log test_loss
-                results = {
-                    'progress_bar': tqdm_dict,
-                    'log': {'test_loss': val_loss_mean.item()}
-                }
-                return results
+        Args:
+            outputs: List of outputs you defined in test_step, or if there are multiple
+            dataloaders, a list containing a list of outputs for each dataloader
 
-        With multiple dataloaders, `outputs` will be a list of lists. The outer list contains
-        one entry per dataloader, while the inner list contains the individual outputs of
-        each validation step for that dataloader.
+        Return:
+            Dict or OrderedDict (dict): Dict has the following optional keys:
+            progress_bar -> Dict for progress bar display. Must have only tensors
+            log -> Dict of metrics to add to logger. Must have only tensors (no images, etc)
 
-        .. code-block:: python
+        .. note:: If you didn't define a test_step, this won't be called.
 
-            def test_end(self, outputs):
-                test_loss_mean = 0
-                test_acc_mean = 0
-                i = 0
-                for dataloader_outputs in outputs:
-                    for output in dataloader_outputs:
-                        test_loss_mean += output['test_loss']
-                        test_acc_mean += output['test_acc']
-                        i += 1
+        - The outputs here are strictly for logging or progress bar.
+        - If you don't need to display anything, don't return anything.
+        - If you want to manually set current step, specify it with the 'step' key in the 'log' Dict
 
-                test_loss_mean /= i
-                test_acc_mean /= i
-                tqdm_dict = {'test_loss': test_loss_mean.item(), 'test_acc': test_acc_mean.item()}
+        Examples:
+            With a single dataloader
 
-                # show test_loss and test_acc in progress bar but only log test_loss
-                results = {
-                    'progress_bar': tqdm_dict,
-                    'log': {'test_loss': val_loss_mean.item()}
-                }
-                return results
+            .. code-block:: python
 
+                def test_epoch_end(self, outputs):
+                    test_acc_mean = 0
+                    for output in outputs:
+                        test_acc_mean += output['test_acc']
+
+                    test_acc_mean /= len(outputs)
+                    tqdm_dict = {'test_acc': test_acc_mean.item()}
+
+                    # show test_loss and test_acc in progress bar but only log test_loss
+                    results = {
+                        'progress_bar': tqdm_dict,
+                        'log': {'test_acc': test_acc_mean.item()}
+                    }
+                    return results
+
+            With multiple dataloaders, `outputs` will be a list of lists. The outer list contains
+            one entry per dataloader, while the inner list contains the individual outputs of
+            each test step for that dataloader.
+
+            .. code-block:: python
+
+                def test_epoch_end(self, outputs):
+                    test_acc_mean = 0
+                    i = 0
+                    for dataloader_outputs in outputs:
+                        for output in dataloader_outputs:
+                            test_acc_mean += output['test_acc']
+                            i += 1
+
+                    test_acc_mean /= i
+                    tqdm_dict = {'test_acc': test_acc_mean.item()}
+
+                    # show test_loss and test_acc in progress bar but only log test_loss
+                    results = {
+                        'progress_bar': tqdm_dict,
+                        'log': {'test_acc': test_acc_mean.item(), 'step': self.current_epoch}
+                    }
+                    return results
         """
 
-    def configure_ddp(self, model, device_ids):
+    def configure_ddp(
+            self,
+            model: 'LightningModule',
+            device_ids: List[int]
+    ) -> DistributedDataParallel:
         r"""
-
         Override to init DDP in your own way or with your own wrapper.
         The only requirements are that:
 
@@ -550,26 +756,24 @@ class LightningModule(ABC, GradInformation, ModelIO, ModelHooks):
         3. On a testing batch, the call goes to model.test_step
 
         Args:
-            model (LightningModule): the LightningModule currently being optimized
-            device_ids (list): the list of GPU ids
+            model: the LightningModule currently being optimized
+            device_ids: the list of GPU ids
 
         Return:
             DDP wrapped model
 
-        Example
-        -------
-        .. code-block:: python
-
-            # default implementation used in Trainer
-            def configure_ddp(self, model, device_ids):
-                # Lightning DDP simply routes to test_step, val_step, etc...
-                model = LightningDistributedDataParallel(
-                    model,
-                    device_ids=device_ids,
-                    find_unused_parameters=True
-                )
-                return model
+        Examples:
+            .. code-block:: python
 
+                # default implementation used in Trainer
+                def configure_ddp(self, model, device_ids):
+                    # Lightning DDP simply routes to test_step, val_step, etc...
+                    model = LightningDistributedDataParallel(
+                        model,
+                        device_ids=device_ids,
+                        find_unused_parameters=True
+                    )
+                    return model
 
         """
         model = LightningDistributedDataParallel(
@@ -579,7 +783,7 @@ class LightningModule(ABC, GradInformation, ModelIO, ModelHooks):
         )
         return model
 
-    def init_ddp_connection(self, proc_rank, world_size):
+    def init_ddp_connection(self, proc_rank: int, world_size: int) -> None:
         r"""
 
         Override to define your custom way of setting up a distributed environment.
@@ -587,45 +791,45 @@ class LightningModule(ABC, GradInformation, ModelIO, ModelHooks):
         Lightning's implementation uses env:// init by default and sets the first node as root.
 
         Args:
-            proc_rank (int): The current process rank within the node.
-            world_size (int): Number of GPUs being use across all nodes. (num_nodes*nb_gpu_nodes).
-        Example
-        -------
-        .. code-block:: python
-
-            def init_ddp_connection(self):
-                # use slurm job id for the port number
-                # guarantees unique ports across jobs from same grid search
-                try:
-                    # use the last 4 numbers in the job id as the id
-                    default_port = os.environ['SLURM_JOB_ID']
-                    default_port = default_port[-4:]
-
-                    # all ports should be in the 10k+ range
-                    default_port = int(default_port) + 15000
-
-                except Exception as e:
-                    default_port = 12910
-
-                # if user gave a port number, use that one instead
-                try:
-                    default_port = os.environ['MASTER_PORT']
-                except Exception:
-                    os.environ['MASTER_PORT'] = str(default_port)
-
-                # figure out the root node addr
-                try:
-                    root_node = os.environ['SLURM_NODELIST'].split(' ')[0]
-                except Exception:
-                    root_node = '127.0.0.2'
-
-                root_node = self.trainer.resolve_root_node_address(root_node)
-                os.environ['MASTER_ADDR'] = root_node
-                dist.init_process_group(
-                    'nccl',
-                    rank=self.proc_rank,
-                    world_size=self.world_size
-                )
+            proc_rank: The current process rank within the node.
+            world_size: Number of GPUs being use across all nodes. (num_nodes*nb_gpu_nodes).
+
+        Examples:
+            .. code-block:: python
+
+                def init_ddp_connection(self):
+                    # use slurm job id for the port number
+                    # guarantees unique ports across jobs from same grid search
+                    try:
+                        # use the last 4 numbers in the job id as the id
+                        default_port = os.environ['SLURM_JOB_ID']
+                        default_port = default_port[-4:]
+
+                        # all ports should be in the 10k+ range
+                        default_port = int(default_port) + 15000
+
+                    except Exception as e:
+                        default_port = 12910
+
+                    # if user gave a port number, use that one instead
+                    try:
+                        default_port = os.environ['MASTER_PORT']
+                    except Exception:
+                        os.environ['MASTER_PORT'] = str(default_port)
+
+                    # figure out the root node addr
+                    try:
+                        root_node = os.environ['SLURM_NODELIST'].split(' ')[0]
+                    except Exception:
+                        root_node = '127.0.0.2'
+
+                    root_node = self.trainer.resolve_root_node_address(root_node)
+                    os.environ['MASTER_ADDR'] = root_node
+                    dist.init_process_group(
+                        'nccl',
+                        rank=self.proc_rank,
+                        world_size=self.world_size
+                    )
 
         """
         # use slurm job id for the port number
@@ -657,31 +861,36 @@ class LightningModule(ABC, GradInformation, ModelIO, ModelHooks):
         os.environ['MASTER_ADDR'] = root_node
         dist.init_process_group('nccl', rank=proc_rank, world_size=world_size)
 
-    def configure_apex(self, amp, model, optimizers, amp_level):
+    def configure_apex(
+            self,
+            amp: object,
+            model: 'LightningModule',
+            optimizers: List[Optimizer],
+            amp_level: str
+    ) -> Tuple['LightningModule', List[Optimizer]]:
         r"""
         Override to init AMP your own way
         Must return a model and list of optimizers
 
         Args:
-            amp (object): pointer to amp library object
-            model (LightningModule): pointer to current lightningModule
-            optimizers (list): list of optimizers passed in configure_optimizers()
-            amp_level (str): AMP mode chosen ('O1', 'O2', etc...)
+            amp: pointer to amp library object
+            model: pointer to current lightningModule
+            optimizers: list of optimizers passed in configure_optimizers()
+            amp_level: AMP mode chosen ('O1', 'O2', etc...)
 
         Return:
             Apex wrapped model and optimizers
 
-        Example
-        -------
-        .. code-block:: python
+        Examples:
+            .. code-block:: python
 
-            # Default implementation used by Trainer.
-            def configure_apex(self, amp, model, optimizers, amp_level):
-                model, optimizers = amp.initialize(
-                    model, optimizers, opt_level=amp_level,
-                )
+                # Default implementation used by Trainer.
+                def configure_apex(self, amp, model, optimizers, amp_level):
+                    model, optimizers = amp.initialize(
+                        model, optimizers, opt_level=amp_level,
+                    )
 
-                return model, optimizers
+                    return model, optimizers
         """
         model, optimizers = amp.initialize(
             model, optimizers, opt_level=amp_level,
@@ -689,116 +898,147 @@ class LightningModule(ABC, GradInformation, ModelIO, ModelHooks):
 
         return model, optimizers
 
-    @abstractmethod
-    def configure_optimizers(self):
+    def configure_optimizers(self) -> Union[
+        Optimizer, List[Optimizer], Tuple[Optimizer, ...], Tuple[List[Optimizer], List]
+    ]:
         r"""
-        This is where you choose what optimizers and learning-rate schedulers to use in your optimization.
-        Normally you'd need one. But in the case of GANs or something more esoteric you might have multiple.
+        Choose what optimizers and learning-rate schedulers to use in your optimization.
+        Normally you'd need one. But in the case of GANs or similar you might have multiple.
+
+        If you don't define this method Lightning will automatically use Adam(lr=1e-3)
 
         Return: any of these 3 options:
             - Single optimizer
             - List or Tuple - List of optimizers
-            - Two lists - The first list has multiple optimizers, the second a list of learning-rate schedulers
-
-        Example
-        -------
-
-        .. code-block:: python
-
-            # most cases
-            def configure_optimizers(self):
-                opt = Adam(self.parameters(), lr=0.01)
-                return opt
-
-            # multiple optimizer case (eg: GAN)
-            def configure_optimizers(self):
-                generator_opt = Adam(self.model_gen.parameters(), lr=0.01)
-                disriminator_opt = Adam(self.model_disc.parameters(), lr=0.02)
-                return generator_opt, disriminator_opt
-
-            # example with learning_rate schedulers
-            def configure_optimizers(self):
-                generator_opt = Adam(self.model_gen.parameters(), lr=0.01)
-                disriminator_opt = Adam(self.model_disc.parameters(), lr=0.02)
-                discriminator_sched = CosineAnnealing(discriminator_opt, T_max=10)
-                return [generator_opt, disriminator_opt], [discriminator_sched]
-
-        .. note:: Lightning calls .backward() and .step() on each optimizer and learning rate scheduler as needed.
-
-        .. note:: If you use 16-bit precision (use_amp=True), Lightning will automatically
+            - Two lists - The first list has multiple optimizers, the second a list of LR schedulers
+
+        Examples:
+            .. code-block:: python
+
+                # most cases (default if not defined)
+                def configure_optimizers(self):
+                    opt = Adam(self.parameters(), lr=1e-3)
+                    return opt
+
+                # multiple optimizer case (eg: GAN)
+                def configure_optimizers(self):
+                    generator_opt = Adam(self.model_gen.parameters(), lr=0.01)
+                    disriminator_opt = Adam(self.model_disc.parameters(), lr=0.02)
+                    return generator_opt, disriminator_opt
+
+                # example with learning_rate schedulers
+                def configure_optimizers(self):
+                    generator_opt = Adam(self.model_gen.parameters(), lr=0.01)
+                    disriminator_opt = Adam(self.model_disc.parameters(), lr=0.02)
+                    discriminator_sched = CosineAnnealing(discriminator_opt, T_max=10)
+                    return [generator_opt, disriminator_opt], [discriminator_sched]
+
+                # example with step-based learning_rate schedulers
+                def configure_optimizers(self):
+                    gen_opt = Adam(self.model_gen.parameters(), lr=0.01)
+                    dis_opt = Adam(self.model_disc.parameters(), lr=0.02)
+                    gen_sched = {'scheduler': ExponentialLR(gen_opt, 0.99),
+                                 'interval': 'step'}  # called after each training step
+                    dis_sched = CosineAnnealing(discriminator_opt, T_max=10) # called every epoch
+                    return [gen_opt, dis_opt], [gen_sched, dis_sched]
+
+        Some things to know
+
+            - Lightning calls ``.backward()`` and ``.step()`` on each optimizer
+            and learning rate scheduler as needed.
+
+            - If you use 16-bit precision (``precision=16``), Lightning will automatically
             handle the optimizers for you.
 
-        .. note:: If you use multiple optimizers, training_step will have an additional `optimizer_idx` parameter.
+            - If you use multiple optimizers, training_step will have an additional
+            ``optimizer_idx`` parameter.
 
-        .. note:: If you use LBFGS lightning handles the closure function automatically for you
+            - If you use LBFGS lightning handles the closure function automatically for you
 
-        .. note:: If you use multiple optimizers, gradients will be calculated only
+            - If you use multiple optimizers, gradients will be calculated only
             for the parameters of current optimizer at each training step.
 
-        .. note:: If you need to control how often those optimizers step or override the default .step() schedule,
-            override the `optimizer_step` hook.
+            - If you need to control how often those optimizers step or override the
+            default .step() schedule, override the `optimizer_step` hook.
 
+            - If you only want to call a learning rate scheduler every `x` step or epoch,
+            you can input this as 'frequency' key: dict(scheduler=lr_scheduler,
+                                                        interval='step' or 'epoch', frequency=x)
 
         """
-
-    def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_idx, second_order_closure=None):
+        return Adam(self.parameters(), lr=1e-3)
+
+    def optimizer_step(
+            self,
+            epoch: int,
+            batch_idx: int,
+            optimizer: Optimizer,
+            optimizer_idx: int,
+            second_order_closure: Optional[Callable] = None,
+    ) -> None:
         r"""
 
-        Override this method to adjust the default way the Trainer calls each optimizer. By default, Lightning
-        calls .step() and zero_grad() as shown in the example once per optimizer.
+        Override this method to adjust the default way the Trainer calls each optimizer.
+        By default, Lightning calls .step() and zero_grad() as shown in the example
+        once per optimizer.
 
         Args:
-            epoch (int): Current epoch
-            batch_idx (int): Index of current batch
-            optimizer (torch.nn.Optimizer): A PyTorch optimizer
-            optimizer_idx (int): If you used multiple optimizers this indexes into that list
-            second_order_closure (int): closure for second order methods
-
-        Example
-        -------
-        .. code-block:: python
-
-            # DEFAULT
-            def optimizer_step(self, current_epoch, batch_idx, optimizer, optimizer_idx, second_order_closure=None):
-                optimizer.step()
-                optimizer.zero_grad()
-
-            # Alternating schedule for optimizer steps (ie: GANs)
-            def optimizer_step(self, current_epoch, batch_idx, optimizer, optimizer_idx, second_order_closure=None):
-                # update generator opt every 2 steps
-                if optimizer_idx == 0:
-                    if batch_idx % 2 == 0 :
-                        optimizer.step()
-                        optimizer.zero_grad()
-
-                # update discriminator opt every 4 steps
-                if optimizer_idx == 1:
-                    if batch_idx % 4 == 0 :
-                        optimizer.step()
-                        optimizer.zero_grad()
-
-                # ...
-                # add as many optimizers as you want
-
-
-        Here's another example showing how to use this for more advanced things such as learning-rate warm-up:
-
-        .. code-block:: python
-
-            # learning rate warm-up
-            def optimizer_step(self, current_epoch, batch_idx, optimizer, optimizer_idx, second_order_closure=None):
-                # warm up lr
-                if self.trainer.global_step < 500:
-                    lr_scale = min(1., float(self.trainer.global_step + 1) / 500.)
-                    for pg in optimizer.param_groups:
-                        pg['lr'] = lr_scale * self.hparams.learning_rate
-
-                # update params
-                optimizer.step()
-                optimizer.zero_grad()
+            epoch: Current epoch
+            batch_idx: Index of current batch
+            optimizer: A PyTorch optimizer
+            optimizer_idx: If you used multiple optimizers this indexes into that list
+            second_order_closure: closure for second order methods
+
+        Examples:
+            .. code-block:: python
+
+                # DEFAULT
+                def optimizer_step(self, current_epoch, batch_idx, optimizer, optimizer_idx,
+                                   second_order_closure=None):
+                    optimizer.step()
+                    optimizer.zero_grad()
+
+                # Alternating schedule for optimizer steps (ie: GANs)
+                def optimizer_step(self, current_epoch, batch_idx, optimizer, optimizer_idx,
+                                   second_order_closure=None):
+                    # update generator opt every 2 steps
+                    if optimizer_idx == 0:
+                        if batch_idx % 2 == 0 :
+                            optimizer.step()
+                            optimizer.zero_grad()
+
+                    # update discriminator opt every 4 steps
+                    if optimizer_idx == 1:
+                        if batch_idx % 4 == 0 :
+                            optimizer.step()
+                            optimizer.zero_grad()
+
+                    # ...
+                    # add as many optimizers as you want
+
+
+            Here's another example showing how to use this for more advanced things such as
+            learning-rate warm-up:
+
+            .. code-block:: python
+
+                # learning rate warm-up
+                def optimizer_step(self, current_epoch, batch_idx, optimizer,
+                                    optimizer_idx, second_order_closure=None):
+                    # warm up lr
+                    if self.trainer.global_step < 500:
+                        lr_scale = min(1., float(self.trainer.global_step + 1) / 500.)
+                        for pg in optimizer.param_groups:
+                            pg['lr'] = lr_scale * self.hparams.learning_rate
+
+                    # update params
+                    optimizer.step()
+                    optimizer.zero_grad()
 
         """
-        if isinstance(optimizer, torch.optim.LBFGS):
+        if self.trainer.use_tpu and XLA_AVAILABLE:
+            xm.optimizer_step(optimizer)
+        elif isinstance(optimizer, torch.optim.LBFGS):
             optimizer.step(second_order_closure)
         else:
             optimizer.step()
@@ -806,45 +1046,45 @@ class LightningModule(ABC, GradInformation, ModelIO, ModelHooks):
         # clear gradients
         optimizer.zero_grad()
 
-    def tbptt_split_batch(self, batch, split_size):
+    def tbptt_split_batch(self, batch: Tensor, split_size: int) -> list:
         r"""
 
-        When using truncated backpropagation through time, each batch must be split along the time dimension.
-        Lightning handles this by default, but  for custom behavior override this function.
+        When using truncated backpropagation through time, each batch must be split along the
+        time dimension. Lightning handles this by default, but  for custom behavior override
+        this function.
 
         Args:
-            batch (torch.nn.Tensor): Current batch
-            split_size (int): How big the split  is
+            batch: Current batch
+            split_size: How big the split  is
 
         Return:
             list of batch splits. Each split will be passed to forward_step to enable truncated
             back propagation through time. The default implementation splits root level Tensors and
             Sequences at dim=1 (i.e. time dim). It assumes that each time dim is the same length.
 
-        Example
-        -------
-        .. code-block:: python
+        Examples:
+            .. code-block:: python
 
-            def tbptt_split_batch(self, batch, split_size):
-              splits = []
-              for t in range(0, time_dims[0], split_size):
-                  batch_split = []
-                  for i, x in enumerate(batch):
-                      if isinstance(x, torch.Tensor):
-                          split_x = x[:, t:t + split_size]
-                      elif isinstance(x, collections.Sequence):
-                          split_x = [None] * len(x)
-                          for batch_idx in range(len(x)):
-                              split_x[batch_idx] = x[batch_idx][t:t + split_size]
+                def tbptt_split_batch(self, batch, split_size):
+                  splits = []
+                  for t in range(0, time_dims[0], split_size):
+                      batch_split = []
+                      for i, x in enumerate(batch):
+                          if isinstance(x, torch.Tensor):
+                              split_x = x[:, t:t + split_size]
+                          elif isinstance(x, collections.Sequence):
+                              split_x = [None] * len(x)
+                              for batch_idx in range(len(x)):
+                                  split_x[batch_idx] = x[batch_idx][t:t + split_size]
 
-                      batch_split.append(split_x)
+                          batch_split.append(split_x)
 
-                  splits.append(batch_split)
+                      splits.append(batch_split)
 
-              return splits
+                  return splits
 
-        .. note:: Called in the training loop after on_batch_start if `truncated_bptt_steps > 0`.
-            Each returned batch split is passed separately to training_step(...).
+        .. note:: Called in the training loop after on_batch_start if ``truncated_bptt_steps > 0``.
+            Each returned batch split is passed separately to ``training_step(...)``.
 
         """
         time_dims = [len(x[0]) for x in batch if isinstance(x, (torch.Tensor, collections.Sequence))]
@@ -868,278 +1108,315 @@ class LightningModule(ABC, GradInformation, ModelIO, ModelHooks):
 
         return splits
 
-    @data_loader
-    def train_dataloader(self):
-        """Implement a PyTorch DataLoader
-
-        :return: PyTorch DataLoader
+    def prepare_data(self) -> None:
+        """Use this to download and prepare data.
+        In distributed (GPU, TPU), this will only be called once
 
-        Called by lightning during training loop. Make sure to use the @pl.data_loader decorator,
-         this ensures not calling this function until the data are needed.
-         If you want to change the data during every epoch DON'T use the data_loader decorator.
+        Return:
+            PyTorch DataLoader
 
-        Example
-        -------
+        This is called before requesting the dataloaders
 
         .. code-block:: python
 
-            @pl.data_loader
-            def train_dataloader(self):
-                transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])
-                dataset = MNIST(root='/path/to/mnist/', train=True, transform=transform, download=True)
-                loader = torch.utils.data.DataLoader(
-                    dataset=dataset,
-                    batch_size=self.hparams.batch_size,
-                    shuffle=True
-                )
-                return loader
+            model.prepare_data()
+            model.train_dataloader()
+            model.val_dataloader()
+            model.test_dataloader()
 
-        """
-        return None
-
-    @data_loader
-    def tng_dataloader(self):  # todo: remove in v0.8.0
-        """Implement a PyTorch DataLoader.
+        Examples:
+            .. code-block:: python
 
-        .. warning:: Deprecated in v0.5.0. use train_dataloader instead.
+                def prepare_data(self):
+                    download_imagenet()
+                    clean_imagenet()
+                    cache_imagenet()
         """
-        output = self.train_dataloader()
-        warnings.warn("`tng_dataloader` has been renamed to `train_dataloader` since v0.5.0."
-                      " and this method will be removed in v0.8.0", DeprecationWarning)
-        return output
-
-    @data_loader
-    def test_dataloader(self):
-        r"""
 
-        Called by lightning during test loop. Make sure to use the @pl.data_loader decorator,
-        this ensures not calling this function until the data are needed.
+    def train_dataloader(self) -> DataLoader:
+        """Implement a PyTorch DataLoader
 
         Return:
             PyTorch DataLoader
 
-        Example
-        -------
+        Return a dataloader. It will not be called every epoch unless you set
+        ```Trainer(reload_dataloaders_every_epoch=True)```.
 
-        .. code-block:: python
+        It's recommended that all data downloads and preparation happen in prepare_data().
 
-            @pl.data_loader
-            def test_dataloader(self):
-                transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])
-                dataset = MNIST(root='/path/to/mnist/', train=False, transform=transform, download=True)
-                loader = torch.utils.data.DataLoader(
-                    dataset=dataset,
-                    batch_size=self.hparams.batch_size,
-                    shuffle=True
-                )
+        .. note:: Lightning adds the correct sampler for distributed and arbitrary hardware.
+            No need to set yourself.
 
-                return loader
+            - .fit()
+            - ...
+            - prepare_data()
+            - train_dataloader
 
-        .. note:: If you don't need a test dataset and a test_step, you don't need to implement this method.
+        Example:
+            .. code-block:: python
 
-        .. note:: If you want to change the data during every epoch DON'T use the data_loader decorator.
+                def train_dataloader(self):
+                    transform = transforms.Compose([transforms.ToTensor(),
+                                                    transforms.Normalize((0.5,), (1.0,))])
+                    dataset = MNIST(root='/path/to/mnist/', train=True, transform=transform,
+                                    download=True)
+                    loader = torch.utils.data.DataLoader(
+                        dataset=dataset,
+                        batch_size=self.hparams.batch_size,
+                        shuffle=True
+                    )
+                    return loader
 
         """
-        return None
-
-    @data_loader
-    def val_dataloader(self):
-        r"""
-
-        Called by lightning during validation loop. Make sure to use the @pl.data_loader decorator,
-        this ensures not calling this function until the data are needed.
 
-        Return:
-            PyTorch DataLoader
-
-        Example
-        -------
+    def tng_dataloader(self):  # todo: remove in v1.0.0
+        """Implement a PyTorch DataLoader.
 
-        .. code-block:: python
+        Warnings:
+            Deprecated in v0.5.0. use train_dataloader instead. Will be removed 1.0.0
+        """
+        output = self.train_dataloader()
+        warnings.warn("`tng_dataloader` has been renamed to `train_dataloader` since v0.5.0."
+                      " and this method will be removed in v1.0.0", DeprecationWarning)
+        return output
 
-            @pl.data_loader
-            def val_dataloader(self):
-                transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])
-                dataset = MNIST(root='/path/to/mnist/', train=False, transform=transform, download=True)
-                loader = torch.utils.data.DataLoader(
-                    dataset=dataset,
-                    batch_size=self.hparams.batch_size,
-                    shuffle=True
-                )
+    def test_dataloader(self) -> Union[DataLoader, List[DataLoader]]:
+        r"""
 
-                return loader
+        Return a dataloader. It will not be called every epoch unless you set
+        ```Trainer(reload_dataloaders_every_epoch=True)```.
 
-            # can also return multiple dataloaders
-            @pl.data_loader
-            def val_dataloader(self):
-                return [loader_a, loader_b, ..., loader_n]
+        It's recommended that all data downloads and preparation happen in prepare_data().
 
-        Example
-        -------
+            - .fit()
+            - ...
+            - prepare_data()
+            - train_dataloader
+            - val_dataloader
+            - test_dataloader
 
-        .. code-block:: python
+        .. note:: Lightning adds the correct sampler for distributed and arbitrary hardware.
+            No need to set yourself.
 
-            @pl.data_loader
-            def val_dataloader(self):
-                transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])
-                dataset = MNIST(root='/path/to/mnist/', train=False, transform=transform, download=True)
-                loader = torch.utils.data.DataLoader(
-                    dataset=dataset,
-                    batch_size=self.hparams.batch_size,
-                    shuffle=True
-                )
+        Return:
+            Single or multiple PyTorch DataLoader
 
-                return loader
+        Example:
+            .. code-block:: python
 
-            # can also return multiple dataloaders
-            @pl.data_loader
-            def val_dataloader(self):
-                return [loader_a, loader_b, ..., loader_n]
+                def test_dataloader(self):
+                    transform = transforms.Compose([transforms.ToTensor(),
+                                                    transforms.Normalize((0.5,), (1.0,))])
+                    dataset = MNIST(root='/path/to/mnist/', train=False, transform=transform,
+                                    download=True)
+                    loader = torch.utils.data.DataLoader(
+                        dataset=dataset,
+                        batch_size=self.hparams.batch_size,
+                        shuffle=True
+                    )
 
-        .. note:: If you don't need a validation dataset and a validation_step, you don't need to implement this method.
+                    return loader
 
-        .. note:: If you want to change the data during every epoch DON'T use the data_loader decorator.
+        .. note:: If you don't need a test dataset and a test_step, you don't need to implement
+            this method.
 
-        .. note:: In the case where you return multiple `val_dataloaders`, the `validation_step`
-            will have an argument `dataset_idx` which matches the order here.
         """
-        return None
 
-    @classmethod
-    def load_from_metrics(cls, weights_path, tags_csv, map_location=None):
+    def val_dataloader(self) -> Union[DataLoader, List[DataLoader]]:
         r"""
 
-        You should use `load_from_checkpoint` instead!
-        However, if your .ckpt weights don't have the hyperparameters saved, use this method  to pass
-        in a .csv with the hparams you'd like to use. These will  be converted  into a argparse.Namespace
-        and passed into  your LightningModule for use.
+        Return a dataloader. It will not be called every epoch unless you set
+        ```Trainer(reload_dataloaders_every_epoch=True)```.
 
-        Args:
+        It's recommended that all data downloads and preparation happen in prepare_data().
 
-            weights_path (str): Path to a PyTorch checkpoint
-            tags_csv (str): Path to a .csv with two columns (key, value) as in this
-                Example::
-                    key,value
-                    drop_prob,0.2
-                    batch_size,32
+            - .fit()
+            - ...
+            - prepare_data()
+            - train_dataloader
+            - val_dataloader
 
-            map_location (dict | str | torch.device | function):
-                If your checkpoint saved a GPU model and you now load on CPUs
-                or a different number of GPUs, use this to map to the new setup
-                (example: {'cuda:1':'cuda:0'}).
-                The behaviour is the same as in
-                `torch.load <https://pytorch.org/docs/stable/torch.html#torch.load>`_.
+        .. note:: Lightning adds the correct sampler for distributed and arbitrary hardware
+            No need to set yourself.
 
         Return:
-            LightningModule with loaded weights and hyperparameters (if available).
-
-        Example
-        -------
-        .. code-block:: python
+            Single or multiple PyTorch DataLoader
+
+        Examples:
+            .. code-block:: python
+
+                def val_dataloader(self):
+                    transform = transforms.Compose([transforms.ToTensor(),
+                                                    transforms.Normalize((0.5,), (1.0,))])
+                    dataset = MNIST(root='/path/to/mnist/', train=False,
+                                    transform=transform, download=True)
+                    loader = torch.utils.data.DataLoader(
+                        dataset=dataset,
+                        batch_size=self.hparams.batch_size,
+                        shuffle=True
+                    )
+
+                    return loader
+
+                # can also return multiple dataloaders
+                def val_dataloader(self):
+                    return [loader_a, loader_b, ..., loader_n]
+
+            .. code-block:: python
+
+                def val_dataloader(self):
+                    transform = transforms.Compose([transforms.ToTensor(),
+                                transforms.Normalize((0.5,), (1.0,))])
+                    dataset = MNIST(root='/path/to/mnist/', train=False,
+                              transform=transform, download=True)
+                    loader = torch.utils.data.DataLoader(
+                        dataset=dataset,
+                        batch_size=self.hparams.batch_size,
+                        shuffle=True
+                    )
+
+                    return loader
+
+                # can also return multiple dataloaders
+                def val_dataloader(self):
+                    return [loader_a, loader_b, ..., loader_n]
+
+        .. note:: If you don't need a validation dataset and a validation_step, you don't need to
+            implement this method.
 
-            pretrained_model = MyLightningModule.load_from_metrics(
-                weights_path='/path/to/pytorch_checkpoint.ckpt',
-                tags_csv='/path/to/hparams_file.csv',
-                on_gpu=True,
-                map_location=None
-            )
-
-            # predict
-            pretrained_model.eval()
-            pretrained_model.freeze()
-            y_hat = pretrained_model(x)
+        .. note:: In the case where you return multiple `val_dataloaders`, the `validation_step`
+            will have an argument `dataset_idx` which matches the order here.
         """
 
-        hparams = load_hparams_from_tags_csv(tags_csv)
-        hparams.__setattr__('on_gpu', False)
-
-        if map_location is not None:
-            checkpoint = torch.load(weights_path, map_location=map_location)
-        else:
-            checkpoint = torch.load(weights_path, map_location=lambda storage, loc: storage)
-
-        # load the state_dict on the model automatically
-        model = cls(hparams)
-        model.load_state_dict(checkpoint['state_dict'])
-
-        # give model a chance to load something
-        model.on_load_checkpoint(checkpoint)
-
-        return model
+    @classmethod
+    def load_from_metrics(cls, weights_path, tags_csv, map_location=None):
+        r"""
+        Warning:
+            Deprecated in version 0.7.0. You should use `load_from_checkpoint` instead.
+             Will be removed in v0.9.0.
+        """
+        warnings.warn(
+            "`load_from_metrics` method has been unified with `load_from_checkpoint` in v0.7.0."
+            " The deprecated method will be removed in v0.9.0.", DeprecationWarning
+        )
+        return cls.load_from_checkpoint(weights_path, tags_csv=tags_csv, map_location=map_location)
 
     @classmethod
-    def load_from_checkpoint(cls, checkpoint_path, map_location=None):
+    def load_from_checkpoint(
+            cls,
+            checkpoint_path: str,
+            map_location: Optional[Union[Dict[str, str], str, torch.device, int, Callable]] = None,
+            tags_csv: Optional[str] = None,
+    ) -> 'LightningModule':
         r"""
 
         Primary way of loading model from a checkpoint. When Lightning saves a checkpoint
-        it  stores  the hyperparameters in the checkpoint if you initialized your  LightningModule
-        with an argument  called `hparams` which is a Namespace or dictionary of hyperparameters
-
-        Example
-        -------
-        .. code-block:: python
-
-            # --------------
-            # Case 1
-            # when using Namespace (output of using Argparse to parse command line arguments)
-            from argparse import Namespace
-            hparams = Namespace(**{'learning_rate': 0.1})
+        it stores the hyperparameters in the checkpoint if you initialized your LightningModule
+        with an argument called `hparams` which is a Namespace (output of using argparse
+        to parse command line arguments).
 
-            model = MyModel(hparams)
+        Example:
+            .. code-block:: python
 
-            class MyModel(pl.LightningModule):
-                def __init__(self, hparams):
-                    self.learning_rate = hparams.learning_rate
+                from argparse import Namespace
+                hparams = Namespace(**{'learning_rate': 0.1})
 
-            # --------------
-            # Case 2
-            # when using a dict
-            model = MyModel({'learning_rate': 0.1})
+                model = MyModel(hparams)
 
-            class MyModel(pl.LightningModule):
-                def __init__(self, hparams):
-                    self.learning_rate = hparams['learning_rate']
+                class MyModel(LightningModule):
+                    def __init__(self, hparams):
+                        self.learning_rate = hparams.learning_rate
 
         Args:
-            checkpoint_path (str): Path to checkpoint.
-            map_location (dict | str | torch.device | function):
+            checkpoint_path: Path to checkpoint.
+            map_location:
                 If your checkpoint saved a GPU model and you now load on CPUs
                 or a different number of GPUs, use this to map to the new setup.
                 The behaviour is the same as in
                 `torch.load <https://pytorch.org/docs/stable/torch.html#torch.load>`_.
+            tags_csv: Optional path to a .csv file with two columns (key, value)
+                as in this example::
+
+                    key,value
+                    drop_prob,0.2
+                    batch_size,32
+
+                You most likely won't need this since Lightning will always save the hyperparameters
+                to the checkpoint.
+                However, if your checkpoint weights don't have the hyperparameters saved,
+                use this method to pass in a .csv file with the hparams you'd like to use.
+                These will be converted into a argparse.Namespace and passed into your
+                LightningModule for use.
 
         Return:
             LightningModule with loaded weights and hyperparameters (if available).
 
-        Example
-        -------
-        .. code-block:: python
+        Example:
+            .. code-block:: python
 
-            # load weights without mapping
-            MyLightningModule.load_from_checkpoint('path/to/checkpoint.ckpt')
+                # load weights without mapping ...
+                MyLightningModule.load_from_checkpoint('path/to/checkpoint.ckpt')
 
-            # load weights mapping all weights from GPU 1 to GPU 0
-            map_location = {'cuda:1':'cuda:0'}
-            MyLightningModule.load_from_checkpoint('path/to/checkpoint.ckpt', map_location=map_location)
+                # or load weights mapping all weights from GPU 1 to GPU 0 ...
+                map_location = {'cuda:1':'cuda:0'}
+                MyLightningModule.load_from_checkpoint(
+                    'path/to/checkpoint.ckpt',
+                    map_location=map_location
+                )
 
-        """
+                # or load weights and hyperparameters from separate files.
+                MyLightningModule.load_from_checkpoint(
+                    'path/to/checkpoint.ckpt',
+                    tags_csv='/path/to/hparams_file.csv'
+                )
 
+                # predict
+                pretrained_model.eval()
+                pretrained_model.freeze()
+                y_hat = pretrained_model(x)
+        """
         if map_location is not None:
             checkpoint = torch.load(checkpoint_path, map_location=map_location)
         else:
             checkpoint = torch.load(checkpoint_path, map_location=lambda storage, loc: storage)
 
-        try:
-            ckpt_hparams = checkpoint['hparams']
-        except KeyError:
-            raise IOError(
-                "Checkpoint does not contain hyperparameters. Are your model hyperparameters stored"
-                "in self.hparams?"
-            )
-        hparams = Namespace(**ckpt_hparams)
+        if tags_csv is not None:
+            # add the hparams from csv file to checkpoint
+            hparams = load_hparams_from_tags_csv(tags_csv)
+            hparams.__setattr__('on_gpu', False)
+            checkpoint['hparams'] = vars(hparams)
+
+        model = cls._load_model_state(checkpoint)
+        return model
+
+    @classmethod
+    def _load_model_state(cls, checkpoint: Dict[str, Any]) -> 'LightningModule':
+        cls_takes_hparams = 'hparams' in inspect.signature(cls.__init__).parameters
+        ckpt_hparams = checkpoint.get('hparams')
+
+        if cls_takes_hparams:
+            if ckpt_hparams is not None:
+                is_namespace = checkpoint.get('hparams_type') == 'namespace'
+                hparams = Namespace(**ckpt_hparams) if is_namespace else ckpt_hparams
+            else:
+                warnings.warn(
+                    f"Checkpoint does not contain hyperparameters but {cls.__name__}'s __init__ "
+                    f"contains argument 'hparams'. Will pass in an empty Namespace instead."
+                    " Did you forget to store your model hyperparameters in self.hparams?"
+                )
+                hparams = Namespace()
+        else:  # The user's LightningModule does not define a hparams argument
+            if ckpt_hparams is None:
+                hparams = None
+            else:
+                raise MisconfigurationException(
+                    f"Checkpoint contains hyperparameters but {cls.__name__}'s __init__ "
+                    f"is missing the argument 'hparams'. Are you loading the correct checkpoint?"
+                )
 
         # load the state_dict on the model automatically
-        model = cls(hparams)
+        model_args = [hparams] if hparams else []
+        model = cls(*model_args)
         model.load_state_dict(checkpoint['state_dict'])
 
         # give model a chance to load something
@@ -1147,20 +1424,19 @@ class LightningModule(ABC, GradInformation, ModelIO, ModelHooks):
 
         return model
 
-    def summarize(self, mode):
+    def summarize(self, mode: str) -> None:
         model_summary = ModelSummary(self, mode=mode)
         log.info('\n' + model_summary.__str__())
 
-    def freeze(self):
+    def freeze(self) -> None:
         r"""
         Freeze all params for inference
 
-        Example
-        -------
-        .. code-block:: python
+        Example:
+            .. code-block:: python
 
-            model = MyLightningModule(...)
-            model.freeze()
+                model = MyLightningModule(...)
+                model.freeze()
 
         """
         for param in self.parameters():
@@ -1168,8 +1444,8 @@ class LightningModule(ABC, GradInformation, ModelIO, ModelHooks):
 
         self.eval()
 
-    def unfreeze(self):
-        """Unfreeze all params for inference.
+    def unfreeze(self) -> None:
+        """Unfreeze all params for training.
 
         .. code-block:: python
 
@@ -1182,52 +1458,49 @@ class LightningModule(ABC, GradInformation, ModelIO, ModelHooks):
 
         self.train()
 
-    def on_load_checkpoint(self, checkpoint):
+    def on_load_checkpoint(self, checkpoint: Dict[str, Any]) -> None:
         r"""
         Called by lightning to restore your model.
         If you saved something with **on_save_checkpoint** this is your chance to restore this.
 
         Args:
-            checkpoint (dict): Loaded checkpoint
-
+            checkpoint: Loaded checkpoint
 
-        Example
-        -------
 
-        .. code-block:: python
+        Example:
+            .. code-block:: python
 
-            def on_load_checkpoint(self, checkpoint):
-                # 99% of the time you don't need to implement this method
-                self.something_cool_i_want_to_save = checkpoint['something_cool_i_want_to_save']
+                def on_load_checkpoint(self, checkpoint):
+                    # 99% of the time you don't need to implement this method
+                    self.something_cool_i_want_to_save = checkpoint['something_cool_i_want_to_save']
 
-        .. note:: Lighting auto-restores global step, epoch, and all training state including amp scaling.
+        .. note:: Lighting auto-restores global step, epoch, and train state including amp scaling.
             No need for you to restore anything regarding training.
         """
 
-    def on_save_checkpoint(self, checkpoint):
+    def on_save_checkpoint(self, checkpoint: Dict[str, Any]) -> None:
         r"""
 
-        Called by lightning when saving a  checkpoint  to give you a chance to store anything else you
-        might want to  save
+        Called by lightning when saving a  checkpoint  to give you a chance to store anything
+        else you might want to  save
 
         Args:
-            checkpoint (dic): Checkpoint to be saved
-
-        Example
-        -------
+            checkpoint: Checkpoint to be saved
 
-        .. code-block:: python
+        Example:
+            .. code-block:: python
 
-            def on_save_checkpoint(self, checkpoint):
-                # 99% of use cases you don't need to implement this method
-                checkpoint['something_cool_i_want_to_save'] = my_cool_pickable_object
+                def on_save_checkpoint(self, checkpoint):
+                    # 99% of use cases you don't need to implement this method
+                    checkpoint['something_cool_i_want_to_save'] = my_cool_pickable_object
 
-        .. note:: Lighting saves all aspects of training (epoch, global step, etc...) including amp scaling. No need
+        .. note:: Lighting saves all aspects of training (epoch, global step, etc...)
+            including amp scaling. No need
             for you to store anything about training.
 
         """
 
-    def get_tqdm_dict(self):
+    def get_tqdm_dict(self) -> Dict[str, Union[int, str]]:
         r"""
         Additional items to be displayed in the progress bar.
 
@@ -1245,34 +1518,3 @@ class LightningModule(ABC, GradInformation, ModelIO, ModelHooks):
             tqdm_dict['v_num'] = self.trainer.logger.version
 
         return tqdm_dict
-
-
-def load_hparams_from_tags_csv(tags_csv):
-    if not os.path.isfile(tags_csv):
-        log.warning(f'Missing Tags: {tags_csv}.')
-        return Namespace()
-
-    tags = {}
-    with open(tags_csv) as f:
-        csv_reader = csv.reader(f, delimiter=',')
-        for row in list(csv_reader)[1:]:
-            tags[row[0]] = convert(row[1])
-    ns = Namespace(**tags)
-    return ns
-
-
-def convert(val):
-    constructors = [int, float, str]
-
-    if isinstance(val, str):
-        if val.lower() == 'true':
-            return True
-        if val.lower() == 'false':
-            return False
-
-    for c in constructors:
-        try:
-            return c(val)
-        except ValueError:
-            pass
-    return val
diff --git a/pytorch_lightning/core/memory.py b/pytorch_lightning/core/memory.py
index fbfe79f..9267862 100644
--- a/pytorch_lightning/core/memory.py
+++ b/pytorch_lightning/core/memory.py
@@ -1,23 +1,25 @@
-'''
+"""
 Generates a summary of a model's layers and dimensionality
-'''
+"""
 
 import gc
 import logging as log
 import os
 import subprocess
 from subprocess import PIPE
+from typing import Tuple, Dict, Union, List
 
 import numpy as np
 import torch
+from torch.nn import Module
+
+import pytorch_lightning as pl
 
 
 class ModelSummary(object):
 
-    def __init__(self, model, mode='full'):
-        '''
-        Generates summaries of model layers and dimensions.
-        '''
+    def __init__(self, model: 'pl.LightningModule', mode: str = 'full'):
+        """ Generates summaries of model layers and dimensions. """
         self.model = model
         self.mode = mode
         self.in_sizes = []
@@ -31,7 +33,7 @@ class ModelSummary(object):
     def __repr__(self):
         return self.summary.__str__()
 
-    def named_modules(self):
+    def named_modules(self) -> List[Tuple[str, Module]]:
         if self.mode == 'full':
             mods = self.model.named_modules()
             mods = list(mods)[1:]  # do not include root module (LightningModule)
@@ -42,8 +44,8 @@ class ModelSummary(object):
             mods = []
         return list(mods)
 
-    def get_variable_sizes(self):
-        '''Run sample input through each layer to get output sizes'''
+    def get_variable_sizes(self) -> None:
+        """ Run sample input through each layer to get output sizes """
         mods = self.named_modules()
         in_sizes = []
         out_sizes = []
@@ -98,8 +100,8 @@ class ModelSummary(object):
         self.out_sizes = out_sizes
         assert len(in_sizes) == len(out_sizes)
 
-    def get_layer_names(self):
-        '''Collect Layer Names'''
+    def get_layer_names(self) -> None:
+        """ Collect Layer Names """
         mods = self.named_modules()
         names = []
         layers = []
@@ -112,8 +114,8 @@ class ModelSummary(object):
         self.layer_names = names
         self.layer_types = layer_types
 
-    def get_parameter_sizes(self):
-        '''Get sizes of all parameters in `model`'''
+    def get_parameter_sizes(self) -> None:
+        """ Get sizes of all parameters in `model` """
         mods = self.named_modules()
         sizes = []
         for _, m in mods:
@@ -123,8 +125,8 @@ class ModelSummary(object):
 
         self.param_sizes = sizes
 
-    def get_parameter_nums(self):
-        '''Get number of parameters in each layer'''
+    def get_parameter_nums(self) -> None:
+        """ Get number of parameters in each layer """
         param_nums = []
         for mod in self.param_sizes:
             all_params = 0
@@ -133,12 +135,12 @@ class ModelSummary(object):
             param_nums.append(all_params)
         self.param_nums = param_nums
 
-    def make_summary(self):
-        '''
+    def make_summary(self) -> None:
+        """
         Makes a summary listing with:
 
         Layer Name, Layer Type, Input Size, Output Size, Number of Parameters
-        '''
+        """
         arrays = [['Name', self.layer_names],
                   ['Type', self.layer_types],
                   ['Params', list(map(get_human_readable_count, self.param_nums))]]
@@ -147,9 +149,8 @@ class ModelSummary(object):
             arrays.append(['Out sizes', self.out_sizes])
 
         self.summary = _format_summary_table(*arrays)
-        return
 
-    def summarize(self):
+    def summarize(self) -> None:
         self.get_layer_names()
         self.get_parameter_sizes()
         self.get_parameter_nums()
@@ -159,12 +160,12 @@ class ModelSummary(object):
         self.make_summary()
 
 
-def _format_summary_table(*cols):
-    '''
+def _format_summary_table(*cols) -> str:
+    """
     Takes in a number of arrays, each specifying a column in
     the summary table, and combines them all into one big
     string defining the summary table that are nicely formatted.
-    '''
+    """
     n_rows = len(cols[0][1])
     n_cols = 1 + len(cols)
 
@@ -204,7 +205,7 @@ def _format_summary_table(*cols):
     return summary
 
 
-def print_mem_stack():  # pragma: no cover
+def print_mem_stack() -> None:  # pragma: no cover
     for obj in gc.get_objects():
         try:
             if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):
@@ -213,7 +214,7 @@ def print_mem_stack():  # pragma: no cover
             pass
 
 
-def count_mem_items():  # pragma: no cover
+def count_mem_items() -> Tuple[int, int]:  # pragma: no cover
     num_params = 0
     num_tensors = 0
     for obj in gc.get_objects():
@@ -230,11 +231,12 @@ def count_mem_items():  # pragma: no cover
     return num_params, num_tensors
 
 
-def get_memory_profile(mode):
-    """
-    'all' means return memory for all gpus
-    'min_max' means return memory for max and min
-    :param mode:
+def get_memory_profile(mode: str) -> Union[Dict[str, int], Dict[int, int]]:
+    """ Get a profile of the current memory usage.
+
+    :param mode: There are two modes:
+        - 'all' means return memory for all gpus
+        - 'min_max' means return memory for max and min
     :return:
     """
     memory_map = get_gpu_memory_map()
@@ -248,14 +250,12 @@ def get_memory_profile(mode):
     return memory_map
 
 
-def get_gpu_memory_map():
+def get_gpu_memory_map() -> Dict[str, int]:
     """Get the current gpu usage.
 
-    Returns
-    -------
-    usage: dict
-        Keys are device ids as integers.
-        Values are memory usage as integers in MB.
+    Return:
+        A dictionary in which the keys are device ids as integers and
+        values are memory usage as integers in MB.
     """
     result = subprocess.run(
         [
@@ -273,10 +273,11 @@ def get_gpu_memory_map():
     return gpu_memory_map
 
 
-def get_human_readable_count(number):
+def get_human_readable_count(number: int) -> str:
     """
     Abbreviates an integer number with K, M, B, T for thousands, millions,
     billions and trillions, respectively.
+
     Examples:
         123     -> 123
         1234    -> 1 K       (one thousand)
@@ -284,8 +285,9 @@ def get_human_readable_count(number):
         3e9     -> 3 B       (three billion)
         4e12    -> 4 T       (four trillion)
         5e15    -> 5,000 T
+
     :param number: a positive integer number
-    :returns a string formatted according to the pattern described above.
+    :return: a string formatted according to the pattern described above.
     """
     assert number >= 0
     labels = [' ', 'K', 'M', 'B', 'T']
diff --git a/pytorch_lightning/core/model_saving.py b/pytorch_lightning/core/model_saving.py
index 278e646..54f8fbc 100644
--- a/pytorch_lightning/core/model_saving.py
+++ b/pytorch_lightning/core/model_saving.py
@@ -8,4 +8,4 @@ import warnings
 warnings.warn("`model_saving` module has been renamed to `saving` since v0.6.0."
               " The deprecated module name will be removed in v0.8.0.", DeprecationWarning)
 
-from pytorch_lightning.core.saving import ModelIO  # noqa: E402
+from pytorch_lightning.core.saving import *  # noqa: F403
diff --git a/pytorch_lightning/core/root_module.py b/pytorch_lightning/core/root_module.py
index 07f2904..af9e89d 100644
--- a/pytorch_lightning/core/root_module.py
+++ b/pytorch_lightning/core/root_module.py
@@ -5,5 +5,7 @@
 
 import warnings
 
+from pytorch_lightning.core.lightning import *  # noqa: F403
+
 warnings.warn("`root_module` module has been renamed to `lightning` since v0.6.0."
               " The deprecated module name will be removed in v0.8.0.", DeprecationWarning)
diff --git a/pytorch_lightning/core/saving.py b/pytorch_lightning/core/saving.py
index ef44c7a..5695d01 100644
--- a/pytorch_lightning/core/saving.py
+++ b/pytorch_lightning/core/saving.py
@@ -1,6 +1,13 @@
+import csv
+import logging as log
+import os
+from argparse import Namespace
+from typing import Union, Dict, Any
+
+
 class ModelIO(object):
 
-    def on_load_checkpoint(self, checkpoint):
+    def on_load_checkpoint(self, checkpoint: Dict[str, Any]) -> None:
         """
         Do something with the checkpoint
         Gives model a chance to load something before state_dict is restored
@@ -8,7 +15,7 @@ class ModelIO(object):
         :return:
         """
 
-    def on_save_checkpoint(self, checkpoint):
+    def on_save_checkpoint(self, checkpoint: Dict[str, Any]) -> None:
         """
         Give the model a chance to add something to the checkpoint.
         state_dict is already there
@@ -17,14 +24,41 @@ class ModelIO(object):
     # -------------------------
     # OPTIONAL HOOKS
     # -------------------------
-    def on_hpc_save(self, checkpoint):
+    def on_hpc_save(self, checkpoint: Dict[str, Any]) -> None:
         """
         Hook to do whatever you need right before Slurm manager saves the model
-        :return:
         """
 
-    def on_hpc_load(self, checkpoint):
+    def on_hpc_load(self, checkpoint: Dict[str, Any]) -> None:
         """
         Hook to do whatever you need right before Slurm manager loads the model
-        :return:
         """
+
+
+def load_hparams_from_tags_csv(tags_csv: str) -> Namespace:
+    if not os.path.isfile(tags_csv):
+        log.warning(f'Missing Tags: {tags_csv}.')
+        return Namespace()
+
+    with open(tags_csv) as f:
+        csv_reader = csv.reader(f, delimiter=',')
+        tags = {row[0]: convert(row[1]) for row in list(csv_reader)[1:]}
+    ns = Namespace(**tags)
+    return ns
+
+
+def convert(val: str) -> Union[int, float, bool, str]:
+    constructors = [int, float, str]
+
+    if isinstance(val, str):
+        if val.lower() == 'true':
+            return True
+        if val.lower() == 'false':
+            return False
+
+    for c in constructors:
+        try:
+            return c(val)
+        except ValueError:
+            pass
+    return val
diff --git a/pytorch_lightning/loggers/__init__.py b/pytorch_lightning/loggers/__init__.py
index 23c4b72..adcba87 100644
--- a/pytorch_lightning/loggers/__init__.py
+++ b/pytorch_lightning/loggers/__init__.py
@@ -1,6 +1,7 @@
 """
 Lightning supports most popular logging frameworks (Tensorboard, comet, weights and biases, etc...).
-To use a logger, simply pass it into the trainer.
+To use a logger, simply pass it into the trainer. To use multiple loggers, simply pass in a ``list``
+or ``tuple`` of loggers.
 
 .. code-block:: python
 
@@ -14,14 +15,19 @@ To use a logger, simply pass it into the trainer.
     comet_logger = loggers.CometLogger()
     trainer = Trainer(logger=comet_logger)
 
-.. note:: All loggers log by default to `os.getcwd()`. To change the path without creating a logger set
-    Trainer(default_save_path='/your/path/to/save/checkpoints')
+    # or pass a list
+    tb_logger = loggers.TensorBoardLogger()
+    comet_logger = loggers.CometLogger()
+    trainer = Trainer(logger=[tb_logger, comet_logger])
+
+.. note:: All loggers log by default to ``os.getcwd()``. To change the path without creating a logger set
+    ``Trainer(default_save_path='/your/path/to/save/checkpoints')``
 
 Custom logger
 -------------
 
 You can implement your own logger by writing a class that inherits from
-`LightningLoggerBase`. Use the `rank_zero_only` decorator to make sure that
+``LightningLoggerBase``. Use the ``rank_zero_only`` decorator to make sure that
 only the first process in DDP training logs data.
 
 .. code-block:: python
@@ -52,13 +58,13 @@ only the first process in DDP training logs data.
             # finishes goes here
 
 
-If you write a logger than may be useful to others, please send
+If you write a logger that may be useful to others, please send
 a pull request to add it to Lighting!
 
 Using loggers
 -------------
 
-Call the logger anywhere from your LightningModule by doing:
+Call the logger anywhere except ``__init__`` in your LightningModule by doing:
 
 .. code-block:: python
 
@@ -69,12 +75,14 @@ Call the logger anywhere from your LightningModule by doing:
     def any_lightning_module_function_or_hook(...):
         self.logger.experiment.add_histogram(...)
 
+Read more in the `Experiment Logging use case <./experiment_logging.html>`_.
+
 Supported Loggers
 -----------------
 """
 from os import environ
 
-from .base import LightningLoggerBase, rank_zero_only
+from .base import LightningLoggerBase, LoggerCollection, rank_zero_only
 from .tensorboard import TensorBoardLogger
 
 __all__ = ['TensorBoardLogger']
diff --git a/pytorch_lightning/loggers/base.py b/pytorch_lightning/loggers/base.py
index 1835bba..8187be9 100644
--- a/pytorch_lightning/loggers/base.py
+++ b/pytorch_lightning/loggers/base.py
@@ -1,11 +1,15 @@
-from abc import ABC
+import argparse
+from abc import ABC, abstractmethod
+from argparse import Namespace
 from functools import wraps
+from typing import Union, Optional, Dict, Iterable, Any, Callable, List
 
 
-def rank_zero_only(fn):
+def rank_zero_only(fn: Callable):
     """Decorate a logger method to run it only on the process with rank 0.
 
-    :param fn: Function to decorate
+    Args:
+        fn: Function to decorate
     """
 
     @wraps(fn)
@@ -23,52 +27,143 @@ class LightningLoggerBase(ABC):
         self._rank = 0
 
     @property
-    def experiment(self):
-        raise NotImplementedError()
+    @abstractmethod
+    def experiment(self) -> Any:
+        """Return the experiment object associated with this logger"""
+        pass
 
-    def log_metrics(self, metrics, step):
+    @abstractmethod
+    def log_metrics(self, metrics: Dict[str, float], step: Optional[int] = None):
         """Record metrics.
 
-        :param float metric: Dictionary with metric names as keys and measured quanties as values
-        :param int|None step: Step number at which the metrics should be recorded
+        Args:
+            metrics: Dictionary with metric names as keys and measured quantities as values
+            step: Step number at which the metrics should be recorded
         """
-        raise NotImplementedError()
-
-    def log_hyperparams(self, params):
+        pass
+
+    def _convert_params(self, params: Union[Dict[str, Any], Namespace]) -> Dict[str, Any]:
+        # in case converting from namespace
+        if isinstance(params, Namespace):
+            params = vars(params)
+
+        # flatten dict e.g. {'a': {'b': 'c'}} -> {'a/b': 'c'}
+        params = self._flatten_dict(params)
+
+        if params is None:
+            params = {}
+
+        return params
+
+    def _flatten_dict(self, params: Dict[str, Any], delimiter: str = '/') -> Dict[str, Any]:
+        def _dict_generator(_dict, prefixes=None):
+            prefixes = prefixes[:] if prefixes else []
+            if isinstance(_dict, dict):
+                for key, value in _dict.items():
+                    if isinstance(value, dict):
+                        for d in _dict_generator(value, prefixes + [key]):
+                            yield d
+                    elif isinstance(value, Namespace):
+                        for d in _dict_generator(vars(value), prefixes + [key]):
+                            yield d
+                    else:
+                        yield prefixes + [key, value if value is not None else str(None)]
+            else:
+                yield prefixes + [_dict if _dict is None else str(_dict)]
+
+        return {delimiter.join(keys): val for *keys, val in _dict_generator(params)}
+
+    @abstractmethod
+    def log_hyperparams(self, params: argparse.Namespace):
         """Record hyperparameters.
 
-        :param params: argparse.Namespace containing the hyperparameters
+        Args:
+            params: argparse.Namespace containing the hyperparameters
         """
-        raise NotImplementedError()
+        pass
 
-    def save(self):
+    def save(self) -> None:
         """Save log data."""
+        pass
 
-    def finalize(self, status):
+    def finalize(self, status: str) -> None:
         """Do any processing that is necessary to finalize an experiment.
 
-        :param status: Status that the experiment finished with (e.g. success, failed, aborted)
+        Args:
+            status: Status that the experiment finished with (e.g. success, failed, aborted)
         """
+        pass
 
-    def close(self):
+    def close(self) -> None:
         """Do any cleanup that is necessary to close an experiment."""
+        pass
 
     @property
-    def rank(self):
+    def rank(self) -> int:
         """Process rank. In general, metrics should only be logged by the process with rank 0."""
         return self._rank
 
     @rank.setter
-    def rank(self, value):
+    def rank(self, value: int) -> None:
         """Set the process rank."""
         self._rank = value
 
     @property
-    def name(self):
+    @abstractmethod
+    def name(self) -> str:
         """Return the experiment name."""
-        raise NotImplementedError("Sub-classes must provide a name property")
+        pass
 
     @property
-    def version(self):
+    @abstractmethod
+    def version(self) -> Union[int, str]:
         """Return the experiment version."""
-        raise NotImplementedError("Sub-classes must provide a version property")
+        pass
+
+
+class LoggerCollection(LightningLoggerBase):
+    """The `LoggerCollection` class is used to iterate all logging actions over the given `logger_iterable`.
+
+    Args:
+        logger_iterable: An iterable collection of loggers
+    """
+
+    def __init__(self, logger_iterable: Iterable[LightningLoggerBase]):
+        super().__init__()
+        self._logger_iterable = logger_iterable
+
+    def __getitem__(self, index: int) -> LightningLoggerBase:
+        return [logger for logger in self._logger_iterable][index]
+
+    @property
+    def experiment(self) -> List[Any]:
+        return [logger.experiment for logger in self._logger_iterable]
+
+    def log_metrics(self, metrics: Dict[str, float], step: Optional[int] = None) -> None:
+        [logger.log_metrics(metrics, step) for logger in self._logger_iterable]
+
+    def log_hyperparams(self, params: Union[Dict[str, Any], Namespace]) -> None:
+        [logger.log_hyperparams(params) for logger in self._logger_iterable]
+
+    def save(self) -> None:
+        [logger.save() for logger in self._logger_iterable]
+
+    def finalize(self, status: str) -> None:
+        [logger.finalize(status) for logger in self._logger_iterable]
+
+    def close(self) -> None:
+        [logger.close() for logger in self._logger_iterable]
+
+    @LightningLoggerBase.rank.setter
+    def rank(self, value: int) -> None:
+        self._rank = value
+        for logger in self._logger_iterable:
+            logger.rank = value
+
+    @property
+    def name(self) -> str:
+        return '_'.join([str(logger.name) for logger in self._logger_iterable])
+
+    @property
+    def version(self) -> str:
+        return '_'.join([str(logger.version) for logger in self._logger_iterable])
diff --git a/pytorch_lightning/loggers/comet.py b/pytorch_lightning/loggers/comet.py
index fd8d456..a7e8118 100644
--- a/pytorch_lightning/loggers/comet.py
+++ b/pytorch_lightning/loggers/comet.py
@@ -6,26 +6,29 @@ CometLogger
 -------------
 """
 
-from logging import getLogger
+import logging as log
+from argparse import Namespace
+from typing import Optional, Dict, Union, Any
 
 try:
     from comet_ml import Experiment as CometExperiment
     from comet_ml import ExistingExperiment as CometExistingExperiment
     from comet_ml import OfflineExperiment as CometOfflineExperiment
+    from comet_ml import BaseExperiment as CometBaseExperiment
     try:
         from comet_ml.api import API
     except ImportError:
         # For more information, see: https://www.comet.ml/docs/python-sdk/releases/#release-300
         from comet_ml.papi import API
 except ImportError:
-    raise ImportError('Missing comet_ml package.')
+    raise ImportError('You want to use `comet_ml` logger which is not installed yet,'
+                      ' install it with `pip install comet-ml`.')
 
+import torch
 from torch import is_tensor
 
+from pytorch_lightning.utilities.debugging import MisconfigurationException
 from .base import LightningLoggerBase, rank_zero_only
-from ..utilities.debugging import MisconfigurationException
-
-logger = getLogger(__name__)
 
 
 class CometLogger(LightningLoggerBase):
@@ -33,9 +36,10 @@ class CometLogger(LightningLoggerBase):
     Log using `comet.ml <https://www.comet.ml>`_.
     """
 
-    def __init__(self, api_key=None, save_dir=None, workspace=None,
-                 rest_api_key=None, project_name=None, experiment_name=None,
-                 experiment_key=None, **kwargs):
+    def __init__(self, api_key: Optional[str] = None, save_dir: Optional[str] = None,
+                 workspace: Optional[str] = None, project_name: Optional[str] = None,
+                 rest_api_key: Optional[str] = None, experiment_name: Optional[str] = None,
+                 experiment_key: Optional[str] = None, **kwargs):
         r"""
 
         Requires either an API Key (online mode) or a local directory path (offline mode)
@@ -77,18 +81,14 @@ class CometLogger(LightningLoggerBase):
             If project name does not already exists Comet.ml will create a new project.
             rest_api_key (str): Optional. Rest API key found in Comet.ml settings.
                 This is used to determine version number
-            experiment_name (str): Optional. String representing the name for this particular experiment on Comet.ml
-
+            experiment_name (str): Optional. String representing the name for this particular experiment on Comet.ml.
+            experiment_key (str): Optional. If set, restores from existing experiment.
         """
         super().__init__()
         self._experiment = None
 
         # Determine online or offline mode based on which arguments were passed to CometLogger
-        if save_dir is not None and api_key is not None:
-            # If arguments are passed for both save_dir and api_key, preference is given to online mode
-            self.mode = "online"
-            self.api_key = api_key
-        elif api_key is not None:
+        if api_key is not None:
             self.mode = "online"
             self.api_key = api_key
         elif save_dir is not None:
@@ -98,7 +98,7 @@ class CometLogger(LightningLoggerBase):
             # If neither api_key nor save_dir are passed as arguments, raise an exception
             raise MisconfigurationException("CometLogger requires either api_key or save_dir during initialization.")
 
-        logger.info(f"CometLogger will be initialized in {self.mode} mode")
+        log.info(f"CometLogger will be initialized in {self.mode} mode")
 
         self.workspace = workspace
         self.project_name = project_name
@@ -117,10 +117,10 @@ class CometLogger(LightningLoggerBase):
             try:
                 self.name = experiment_name
             except TypeError as e:
-                logger.exception("Failed to set experiment name for comet.ml logger")
+                log.exception("Failed to set experiment name for comet.ml logger")
 
     @property
-    def experiment(self):
+    def experiment(self) -> CometBaseExperiment:
         r"""
 
         Actual comet object. To use comet features do the following.
@@ -161,11 +161,16 @@ class CometLogger(LightningLoggerBase):
         return self._experiment
 
     @rank_zero_only
-    def log_hyperparams(self, params):
-        self.experiment.log_parameters(vars(params))
+    def log_hyperparams(self, params: Union[Dict[str, Any], Namespace]) -> None:
+        params = self._convert_params(params)
+        self.experiment.log_parameters(params)
 
     @rank_zero_only
-    def log_metrics(self, metrics, step=None):
+    def log_metrics(
+            self,
+            metrics: Dict[str, Union[torch.Tensor, float]],
+            step: Optional[int] = None
+    ) -> None:
         # Comet.ml expects metrics to be a dictionary of detached tensors on CPU
         for key, val in metrics.items():
             if is_tensor(val):
@@ -177,7 +182,7 @@ class CometLogger(LightningLoggerBase):
         self._experiment = None
 
     @rank_zero_only
-    def finalize(self, status):
+    def finalize(self, status: str) -> None:
         r"""
         When calling self.experiment.end(), that experiment won't log any more data to Comet. That's why, if you need
         to log any more data you need to create an ExistingCometExperiment. For example, to log data when testing your
@@ -190,13 +195,13 @@ class CometLogger(LightningLoggerBase):
         self.reset_experiment()
 
     @property
-    def name(self):
+    def name(self) -> str:
         return self.experiment.project_name
 
     @name.setter
-    def name(self, value):
+    def name(self, value: str) -> None:
         self.experiment.set_name(value)
 
     @property
-    def version(self):
+    def version(self) -> str:
         return self.experiment.id
diff --git a/pytorch_lightning/loggers/comet_logger.py b/pytorch_lightning/loggers/comet_logger.py
deleted file mode 100644
index 47a524d..0000000
--- a/pytorch_lightning/loggers/comet_logger.py
+++ /dev/null
@@ -1,11 +0,0 @@
-"""
-.. warning:: `comet_logger` module has been renamed to `comet` since v0.6.0.
- The deprecated module name will be removed in v0.8.0.
-"""
-
-import warnings
-
-warnings.warn("`comet_logger` module has been renamed to `comet` since v0.6.0."
-              " The deprecated module name will be removed in v0.8.0.", DeprecationWarning)
-
-from pytorch_lightning.loggers.comet import CometLogger  # noqa: E402
diff --git a/pytorch_lightning/loggers/mlflow.py b/pytorch_lightning/loggers/mlflow.py
index 652e32f..ed878a0 100644
--- a/pytorch_lightning/loggers/mlflow.py
+++ b/pytorch_lightning/loggers/mlflow.py
@@ -1,5 +1,5 @@
 """
-Log using `mlflow <https://mlflow.org>'_
+Log using `mlflow <https://mlflow.org>`_
 
 .. code-block:: python
 
@@ -23,22 +23,23 @@ Use the logger anywhere in you LightningModule as follows:
         self.logger.experiment.whatever_ml_flow_supports(...)
 
 """
-
-from logging import getLogger
+import logging as log
+from argparse import Namespace
 from time import time
+from typing import Optional, Dict, Any, Union
 
 try:
     import mlflow
 except ImportError:
-    raise ImportError('Missing mlflow package.')
+    raise ImportError('You want to use `mlflow` logger which is not installed yet,'
+                      ' install it with `pip install mlflow`.')
 
 from .base import LightningLoggerBase, rank_zero_only
 
-logger = getLogger(__name__)
-
 
 class MLFlowLogger(LightningLoggerBase):
-    def __init__(self, experiment_name, tracking_uri=None, tags=None):
+    def __init__(self, experiment_name: str, tracking_uri: Optional[str] = None,
+                 tags: Dict[str, Any] = None):
         r"""
 
         Logs using MLFlow
@@ -55,7 +56,7 @@ class MLFlowLogger(LightningLoggerBase):
         self.tags = tags
 
     @property
-    def experiment(self):
+    def experiment(self) -> mlflow.tracking.MlflowClient:
         r"""
 
         Actual mlflow object. To use mlflow features do the following.
@@ -77,7 +78,7 @@ class MLFlowLogger(LightningLoggerBase):
         if expt:
             self._expt_id = expt.experiment_id
         else:
-            logger.warning(f"Experiment with name {self.experiment_name} not found. Creating it.")
+            log.warning(f'Experiment with name {self.experiment_name} not found. Creating it.')
             self._expt_id = self._mlflow_client.create_experiment(name=self.experiment_name)
 
         run = self._mlflow_client.create_run(experiment_id=self._expt_id, tags=self.tags)
@@ -85,18 +86,17 @@ class MLFlowLogger(LightningLoggerBase):
         return self._run_id
 
     @rank_zero_only
-    def log_hyperparams(self, params):
-        for k, v in vars(params).items():
+    def log_hyperparams(self, params: Union[Dict[str, Any], Namespace]) -> None:
+        params = self._convert_params(params)
+        for k, v in params.items():
             self.experiment.log_param(self.run_id, k, v)
 
     @rank_zero_only
-    def log_metrics(self, metrics, step=None):
+    def log_metrics(self, metrics: Dict[str, float], step: Optional[int] = None) -> None:
         timestamp_ms = int(time() * 1000)
         for k, v in metrics.items():
             if isinstance(v, str):
-                logger.warning(
-                    f"Discarding metric with string value {k}={v}"
-                )
+                log.warning(f'Discarding metric with string value {k}={v}.')
                 continue
             self.experiment.log_metric(self.run_id, k, v, timestamp_ms, step)
 
@@ -104,15 +104,15 @@ class MLFlowLogger(LightningLoggerBase):
         pass
 
     @rank_zero_only
-    def finalize(self, status="FINISHED"):
+    def finalize(self, status: str = 'FINISHED') -> None:
         if status == 'success':
             status = 'FINISHED'
         self.experiment.set_terminated(self.run_id, status)
 
     @property
-    def name(self):
+    def name(self) -> str:
         return self.experiment_name
 
     @property
-    def version(self):
+    def version(self) -> str:
         return self._run_id
diff --git a/pytorch_lightning/loggers/mlflow_logger.py b/pytorch_lightning/loggers/mlflow_logger.py
deleted file mode 100644
index d8fc635..0000000
--- a/pytorch_lightning/loggers/mlflow_logger.py
+++ /dev/null
@@ -1,11 +0,0 @@
-"""
-.. warning:: `mlflow_logger` module has been renamed to `mlflow` since v0.6.0.
- The deprecated module name will be removed in v0.8.0.
-"""
-
-import warnings
-
-warnings.warn("`mlflow_logger` module has been renamed to `mlflow` since v0.6.0."
-              " The deprecated module name will be removed in v0.8.0.", DeprecationWarning)
-
-from pytorch_lightning.loggers.mlflow import MLFlowLogger  # noqa: E402
diff --git a/pytorch_lightning/loggers/neptune.py b/pytorch_lightning/loggers/neptune.py
index f81730b..5e011d7 100644
--- a/pytorch_lightning/loggers/neptune.py
+++ b/pytorch_lightning/loggers/neptune.py
@@ -6,22 +6,22 @@ Log using `neptune-logger <https://www.neptune.ml>`_
 NeptuneLogger
 --------------
 """
-
-from logging import getLogger
+import logging as log
+from argparse import Namespace
+from typing import Optional, List, Dict, Any, Union, Iterable
 
 try:
     import neptune
+    from neptune.experiments import Experiment
 except ImportError:
     raise ImportError('You want to use `neptune` logger which is not installed yet,'
-                      ' please install it e.g. `pip install neptune-client`.')
+                      ' install it with `pip install neptune-client`.')
 
+import torch
 from torch import is_tensor
 
-# from .base import LightningLoggerBase, rank_zero_only
 from pytorch_lightning.loggers.base import LightningLoggerBase, rank_zero_only
 
-logger = getLogger(__name__)
-
 
 class NeptuneLogger(LightningLoggerBase):
     r"""
@@ -29,9 +29,10 @@ class NeptuneLogger(LightningLoggerBase):
     To log experiment data in online mode, NeptuneLogger requries an API key:
     """
 
-    def __init__(self, api_key=None, project_name=None, offline_mode=False,
-                 experiment_name=None, upload_source_files=None,
-                 params=None, properties=None, tags=None, **kwargs):
+    def __init__(self, api_key: Optional[str] = None, project_name: Optional[str] = None,
+                 offline_mode: bool = False, experiment_name: Optional[str] = None,
+                 upload_source_files: Optional[List[str]] = None, params: Optional[Dict[str, Any]] = None,
+                 properties: Optional[Dict[str, Any]] = None, tags: Optional[List[str]] = None, **kwargs):
         r"""
 
         Initialize a neptune.ml logger.
@@ -100,8 +101,10 @@ class NeptuneLogger(LightningLoggerBase):
                Must be list of str or single str. Uploaded sources are displayed in the experiment’s Source code tab.
                If None is passed, Python file from which experiment was created will be uploaded.
                Pass empty list ([]) to upload no files. Unix style pathname pattern expansion is supported.
-               For example, you can pass '*.py' to upload all python source files from the current directory.
-               For recursion lookup use '**/*.py' (for Python 3.5 and later). For more information see glob library.
+               For example, you can pass '\*.py'
+                to upload all python source files from the current directory.
+               For recursion lookup use '\**/\*.py' (for Python 3.5 and later).
+               For more information see glob library.
             params (dict|None): Optional. Parameters of the experiment. After experiment creation params are read-only.
                Parameters are displayed in the experiment’s Parameters section and each key-value pair can be
                viewed in experiments view as a column.
@@ -125,18 +128,18 @@ class NeptuneLogger(LightningLoggerBase):
         self._kwargs = kwargs
 
         if offline_mode:
-            self.mode = "offline"
+            self.mode = 'offline'
             neptune.init(project_qualified_name='dry-run/project',
                          backend=neptune.OfflineBackend())
         else:
-            self.mode = "online"
+            self.mode = 'online'
             neptune.init(api_token=self.api_key,
                          project_qualified_name=self.project_name)
 
-        logger.info(f"NeptuneLogger was initialized in {self.mode} mode")
+        log.info(f'NeptuneLogger was initialized in {self.mode} mode')
 
     @property
-    def experiment(self):
+    def experiment(self) -> Experiment:
         r"""
 
         Actual neptune object. To use neptune features do the following.
@@ -159,83 +162,86 @@ class NeptuneLogger(LightningLoggerBase):
         return self._experiment
 
     @rank_zero_only
-    def log_hyperparams(self, params):
-        for key, val in vars(params).items():
-            self.experiment.set_property(f"param__{key}", val)
+    def log_hyperparams(self, params: Union[Dict[str, Any], Namespace]) -> None:
+        params = self._convert_params(params)
+        for key, val in params.items():
+            self.experiment.set_property(f'param__{key}', val)
 
     @rank_zero_only
-    def log_metrics(self, metrics, step=None):
+    def log_metrics(
+            self,
+            metrics: Dict[str, Union[torch.Tensor, float]],
+            step: Optional[int] = None
+    ) -> None:
         """Log metrics (numeric values) in Neptune experiments
 
-        :param float metric: Dictionary with metric names as keys and measured quanties as values
-        :param int|None step: Step number at which the metrics should be recorded, must be strictly increasing
-
+        Args:
+            metrics: Dictionary with metric names as keys and measured quantities as values
+            step: Step number at which the metrics should be recorded, must be strictly increasing
         """
-
         for key, val in metrics.items():
-            if is_tensor(val):
-                val = val.cpu().detach()
-
-            if step is None:
-                self.experiment.log_metric(key, val)
-            else:
-                self.experiment.log_metric(key, x=step, y=val)
+            self.log_metric(key, val, step=step)
 
     @rank_zero_only
-    def finalize(self, status):
+    def finalize(self, status: str) -> None:
         self.experiment.stop()
 
     @property
-    def name(self):
-        if self.mode == "offline":
-            return "offline-name"
+    def name(self) -> str:
+        if self.mode == 'offline':
+            return 'offline-name'
         else:
             return self.experiment.name
 
     @property
-    def version(self):
-        if self.mode == "offline":
-            return "offline-id-1234"
+    def version(self) -> str:
+        if self.mode == 'offline':
+            return 'offline-id-1234'
         else:
             return self.experiment.id
 
     @rank_zero_only
-    def log_metric(self, metric_name, metric_value, step=None):
+    def log_metric(
+            self,
+            metric_name: str,
+            metric_value: Union[torch.Tensor, float, str],
+            step: Optional[int] = None
+    ) -> None:
         """Log metrics (numeric values) in Neptune experiments
 
-        :param str metric_name:  The name of log, i.e. mse, loss, accuracy.
-        :param str metric_value: The value of the log (data-point).
-        :param int|None step: Step number at which the metrics should be recorded, must be strictly increasing
-
+        Args:
+            metric_name:  The name of log, i.e. mse, loss, accuracy.
+            metric_value: The value of the log (data-point).
+            step: Step number at which the metrics should be recorded, must be strictly increasing
         """
+        if is_tensor(metric_value):
+            metric_value = metric_value.cpu().detach()
+
         if step is None:
             self.experiment.log_metric(metric_name, metric_value)
         else:
             self.experiment.log_metric(metric_name, x=step, y=metric_value)
 
     @rank_zero_only
-    def log_text(self, log_name, text, step=None):
+    def log_text(self, log_name: str, text: str, step: Optional[int] = None) -> None:
         """Log text data in Neptune experiment
 
-        :param str log_name:  The name of log, i.e. mse, my_text_data, timing_info.
-        :param str text: The value of the log (data-point).
-        :param int|None step: Step number at which the metrics should be recorded, must be strictly increasing
-
+        Args:
+            log_name:  The name of log, i.e. mse, my_text_data, timing_info.
+            text: The value of the log (data-point).
+            step: Step number at which the metrics should be recorded, must be strictly increasing
         """
-        if step is None:
-            self.experiment.log_metric(log_name, text)
-        else:
-            self.experiment.log_metric(log_name, x=step, y=text)
+        self.log_metric(log_name, text, step=step)
 
     @rank_zero_only
-    def log_image(self, log_name, image, step=None):
+    def log_image(self, log_name: str, image: Union[str, Any], step: Optional[int] = None) -> None:
         """Log image data in Neptune experiment
 
-        :param str log_name: The name of log, i.e. bboxes, visualisations, sample_images.
-        :param str|PIL.Image|matplotlib.figure.Figure image: The value of the log (data-point).
-           Can be one of the following types: PIL image, matplotlib.figure.Figure, path to image file (str)
-        :param int|None step: Step number at which the metrics should be recorded, must be strictly increasing
-
+        Args:
+            log_name: The name of log, i.e. bboxes, visualisations, sample_images.
+            image (str|PIL.Image|matplotlib.figure.Figure): The value of the log (data-point).
+                Can be one of the following types: PIL image, matplotlib.figure.Figure, path to image file (str)
+            step: Step number at which the metrics should be recorded, must be strictly increasing
         """
         if step is None:
             self.experiment.log_image(log_name, image)
@@ -243,36 +249,35 @@ class NeptuneLogger(LightningLoggerBase):
             self.experiment.log_image(log_name, x=step, y=image)
 
     @rank_zero_only
-    def log_artifact(self, artifact, destination=None):
+    def log_artifact(self, artifact: str, destination: Optional[str] = None) -> None:
         """Save an artifact (file) in Neptune experiment storage.
 
-        :param str artifact: A path to the file in local filesystem.
-        :param str|None destination: Optional default None.
-           A destination path. If None is passed, an artifact file name will be used.
-
+        Args:
+            artifact: A path to the file in local filesystem.
+            destination: Optional default None. A destination path.
+                If None is passed, an artifact file name will be used.
         """
         self.experiment.log_artifact(artifact, destination)
 
     @rank_zero_only
-    def set_property(self, key, value):
+    def set_property(self, key: str, value: Any) -> None:
         """Set key-value pair as Neptune experiment property.
 
-        :param str key: Property key.
-        :param obj value: New value of a property.
-
+        Args:
+            key: Property key.
+            value: New value of a property.
         """
         self.experiment.set_property(key, value)
 
     @rank_zero_only
-    def append_tags(self, tags):
+    def append_tags(self, tags: Union[str, Iterable[str]]) -> None:
         """appends tags to neptune experiment
 
-        :param str|tuple|list(str) tags: Tags to add to the current experiment.
-           If str is passed, singe tag is added.
-           If multiple - comma separated - str are passed, all of them are added as tags.
-           If list of str is passed, all elements of the list are added as tags.
-
+        Args:
+            tags: Tags to add to the current experiment. If str is passed, singe tag is added.
+                If multiple - comma separated - str are passed, all of them are added as tags.
+                If list of str is passed, all elements of the list are added as tags.
         """
-        if not isinstance(tags, (list, set, tuple)):
+        if str(tags) == tags:
             tags = [tags]  # make it as an iterable is if it is not yet
         self.experiment.append_tags(*tags)
diff --git a/pytorch_lightning/loggers/tensorboard.py b/pytorch_lightning/loggers/tensorboard.py
index d7222ee..9be1d82 100644
--- a/pytorch_lightning/loggers/tensorboard.py
+++ b/pytorch_lightning/loggers/tensorboard.py
@@ -1,10 +1,11 @@
+import csv
 import os
-from warnings import warn
 from argparse import Namespace
-from pkg_resources import parse_version
+from typing import Optional, Dict, Union, Any
+from warnings import warn
 
 import torch
-import csv
+from pkg_resources import parse_version
 from torch.utils.tensorboard import SummaryWriter
 
 from .base import LightningLoggerBase, rank_zero_only
@@ -42,7 +43,10 @@ class TensorBoardLogger(LightningLoggerBase):
     """
     NAME_CSV_TAGS = 'meta_tags.csv'
 
-    def __init__(self, save_dir, name="default", version=None, **kwargs):
+    def __init__(
+            self, save_dir: str, name: Optional[str] = "default",
+            version: Optional[Union[int, str]] = None, **kwargs
+    ):
         super().__init__()
         self.save_dir = save_dir
         self._name = name
@@ -53,7 +57,7 @@ class TensorBoardLogger(LightningLoggerBase):
         self.kwargs = kwargs
 
     @property
-    def root_dir(self):
+    def root_dir(self) -> str:
         """
         Parent directory for all tensorboard checkpoint subdirectories.
         If the experiment name parameter is None or the empty string, no experiment subdirectory is used
@@ -65,7 +69,7 @@ class TensorBoardLogger(LightningLoggerBase):
             return os.path.join(self.save_dir, self.name)
 
     @property
-    def log_dir(self):
+    def log_dir(self) -> str:
         """
         The directory for this run's tensorboard checkpoint.  By default, it is named 'version_${self.version}'
         but it can be overridden by passing a string value for the constructor's version parameter
@@ -77,7 +81,7 @@ class TensorBoardLogger(LightningLoggerBase):
         return log_dir
 
     @property
-    def experiment(self):
+    def experiment(self) -> SummaryWriter:
         r"""
 
          Actual tensorboard object. To use tensorboard features do the following.
@@ -95,14 +99,8 @@ class TensorBoardLogger(LightningLoggerBase):
         return self._experiment
 
     @rank_zero_only
-    def log_hyperparams(self, params):
-        if params is None:
-            return
-
-        # in case converting from namespace
-        if isinstance(params, Namespace):
-            params = vars(params)
-        params = dict(params)
+    def log_hyperparams(self, params: Union[Dict[str, Any], Namespace]) -> None:
+        params = self._convert_params(params)
 
         if parse_version(torch.__version__) < parse_version("1.3.0"):
             warn(
@@ -121,14 +119,14 @@ class TensorBoardLogger(LightningLoggerBase):
         self.tags.update(params)
 
     @rank_zero_only
-    def log_metrics(self, metrics, step=None):
+    def log_metrics(self, metrics: Dict[str, float], step: Optional[int] = None) -> None:
         for k, v in metrics.items():
             if isinstance(v, torch.Tensor):
                 v = v.item()
             self.experiment.add_scalar(k, v, step)
 
     @rank_zero_only
-    def save(self):
+    def save(self) -> None:
         try:
             self.experiment.flush()
         except AttributeError:
@@ -151,15 +149,15 @@ class TensorBoardLogger(LightningLoggerBase):
                 writer.writerow({'key': k, 'value': v})
 
     @rank_zero_only
-    def finalize(self, status):
+    def finalize(self, status: str) -> None:
         self.save()
 
     @property
-    def name(self):
+    def name(self) -> str:
         return self._name
 
     @property
-    def version(self):
+    def version(self) -> int:
         if self._version is None:
             self._version = self._get_next_version()
         return self._version
diff --git a/pytorch_lightning/loggers/test_tube.py b/pytorch_lightning/loggers/test_tube.py
index 9247efb..fbb57de 100644
--- a/pytorch_lightning/loggers/test_tube.py
+++ b/pytorch_lightning/loggers/test_tube.py
@@ -1,7 +1,11 @@
+from argparse import Namespace
+from typing import Optional, Dict, Any, Union
+
 try:
     from test_tube import Experiment
 except ImportError:
-    raise ImportError('Missing test-tube package.')
+    raise ImportError('You want to use `test_tube` logger which is not installed yet,'
+                      ' install it with `pip install test-tube`.')
 
 from .base import LightningLoggerBase, rank_zero_only
 
@@ -15,8 +19,8 @@ class TestTubeLogger(LightningLoggerBase):
     __test__ = False
 
     def __init__(
-            self, save_dir, name="default", description=None, debug=False,
-            version=None, create_git_tag=False
+            self, save_dir: str, name: str = "default", description: Optional[str] = None,
+            debug: bool = False, version: Optional[int] = None, create_git_tag: bool = False
     ):
         r"""
 
@@ -62,7 +66,7 @@ class TestTubeLogger(LightningLoggerBase):
         self._experiment = None
 
     @property
-    def experiment(self):
+    def experiment(self) -> Experiment:
         r"""
 
           Actual test-tube object. To use test-tube features do the following.
@@ -88,32 +92,33 @@ class TestTubeLogger(LightningLoggerBase):
         return self._experiment
 
     @rank_zero_only
-    def log_hyperparams(self, params):
+    def log_hyperparams(self, params: Union[Dict[str, Any], Namespace]) -> None:
         # TODO: HACK figure out where this is being set to true
         self.experiment.debug = self.debug
-        self.experiment.argparse(params)
+        params = self._convert_params(params)
+        self.experiment.argparse(Namespace(**params))
 
     @rank_zero_only
-    def log_metrics(self, metrics, step=None):
+    def log_metrics(self, metrics: Dict[str, float], step: Optional[int] = None) -> None:
         # TODO: HACK figure out where this is being set to true
         self.experiment.debug = self.debug
         self.experiment.log(metrics, global_step=step)
 
     @rank_zero_only
-    def save(self):
+    def save(self) -> None:
         # TODO: HACK figure out where this is being set to true
         self.experiment.debug = self.debug
         self.experiment.save()
 
     @rank_zero_only
-    def finalize(self, status):
+    def finalize(self, status: str) -> None:
         # TODO: HACK figure out where this is being set to true
         self.experiment.debug = self.debug
         self.save()
         self.close()
 
     @rank_zero_only
-    def close(self):
+    def close(self) -> None:
         # TODO: HACK figure out where this is being set to true
         self.experiment.debug = self.debug
         if not self.debug:
@@ -121,24 +126,24 @@ class TestTubeLogger(LightningLoggerBase):
             exp.close()
 
     @property
-    def rank(self):
+    def rank(self) -> int:
         return self._rank
 
     @rank.setter
-    def rank(self, value):
+    def rank(self, value: int) -> None:
         self._rank = value
         if self._experiment is not None:
             self.experiment.rank = value
 
     @property
-    def name(self):
+    def name(self) -> str:
         if self._experiment is None:
             return self._name
         else:
             return self.experiment.name
 
     @property
-    def version(self):
+    def version(self) -> int:
         if self._experiment is None:
             return self._version
         else:
@@ -148,12 +153,12 @@ class TestTubeLogger(LightningLoggerBase):
     # methods to get DDP working. See
     # https://docs.python.org/3/library/pickle.html#handling-stateful-objects
     # for more info.
-    def __getstate__(self):
+    def __getstate__(self) -> Dict[Any, Any]:
         state = self.__dict__.copy()
         state["_experiment"] = self.experiment.get_meta_copy()
         return state
 
-    def __setstate__(self, state):
+    def __setstate__(self, state: Dict[Any, Any]):
         self._experiment = state["_experiment"].get_non_ddp_exp()
         del state["_experiment"]
         self.__dict__.update(state)
diff --git a/pytorch_lightning/loggers/test_tube_logger.py b/pytorch_lightning/loggers/test_tube_logger.py
deleted file mode 100644
index cdd0682..0000000
--- a/pytorch_lightning/loggers/test_tube_logger.py
+++ /dev/null
@@ -1,11 +0,0 @@
-"""
-.. warning:: `test_tube_logger` module has been renamed to `test_tube` since v0.6.0.
- The deprecated module name will be removed in v0.8.0.
-"""
-
-import warnings
-
-warnings.warn("`test_tube_logger` module has been renamed to `test_tube` since v0.6.0."
-              " The deprecated module name will be removed in v0.8.0.", DeprecationWarning)
-
-from pytorch_lightning.loggers.test_tube import TestTubeLogger  # noqa: E402
diff --git a/pytorch_lightning/loggers/wandb.py b/pytorch_lightning/loggers/wandb.py
index f3ddede..6f22050 100644
--- a/pytorch_lightning/loggers/wandb.py
+++ b/pytorch_lightning/loggers/wandb.py
@@ -5,14 +5,18 @@ r"""
 WandbLogger
 -------------
 """
-
 import os
+from argparse import Namespace
+from typing import Optional, List, Dict, Union, Any
+
+import torch.nn as nn
 
 try:
     import wandb
+    from wandb.wandb_run import Run
 except ImportError:
     raise ImportError('You want to use `wandb` logger which is not installed yet,'
-                      ' please install it e.g. `pip install wandb`.')
+                      ' install it with `pip install wandb`.')
 
 from .base import LightningLoggerBase, rank_zero_only
 
@@ -41,12 +45,14 @@ class WandbLogger(LightningLoggerBase):
         trainer = Trainer(logger=wandb_logger)
     """
 
-    def __init__(self, name=None, save_dir=None, offline=False, id=None, anonymous=False,
-                 version=None, project=None, tags=None, experiment=None, entity=None):
+    def __init__(self, name: Optional[str] = None, save_dir: Optional[str] = None,
+                 offline: bool = False, id: Optional[str] = None, anonymous: bool = False,
+                 version: Optional[str] = None, project: Optional[str] = None,
+                 tags: Optional[List[str]] = None, experiment=None, entity=None):
         super().__init__()
         self._name = name
         self._save_dir = save_dir
-        self._anonymous = "allow" if anonymous else None
+        self._anonymous = 'allow' if anonymous else None
         self._id = version or id
         self._tags = tags
         self._project = project
@@ -63,7 +69,7 @@ class WandbLogger(LightningLoggerBase):
         return state
 
     @property
-    def experiment(self):
+    def experiment(self) -> Run:
         r"""
 
           Actual wandb object. To use wandb features do the following.
@@ -75,29 +81,28 @@ class WandbLogger(LightningLoggerBase):
           """
         if self._experiment is None:
             if self._offline:
-                os.environ["WANDB_MODE"] = "dryrun"
+                os.environ['WANDB_MODE'] = 'dryrun'
             self._experiment = wandb.init(
                 name=self._name, dir=self._save_dir, project=self._project, anonymous=self._anonymous,
-                id=self._id, resume="allow", tags=self._tags, entity=self._entity)
+                id=self._id, resume='allow', tags=self._tags, entity=self._entity)
         return self._experiment
 
-    def watch(self, model, log="gradients", log_freq=100):
-        wandb.watch(model, log, log_freq)
+    def watch(self, model: nn.Module, log: str = 'gradients', log_freq: int = 100):
+        wandb.watch(model, log=log, log_freq=log_freq)
 
     @rank_zero_only
-    def log_hyperparams(self, params):
+    def log_hyperparams(self, params: Union[Dict[str, Any], Namespace]) -> None:
+        params = self._convert_params(params)
         self.experiment.config.update(params)
 
     @rank_zero_only
-    def log_metrics(self, metrics, step=None):
-        metrics["global_step"] = step
+    def log_metrics(self, metrics: Dict[str, float], step: Optional[int] = None) -> None:
+        if step is not None:
+            metrics['global_step'] = step
         self.experiment.log(metrics)
 
-    def save(self):
-        pass
-
     @rank_zero_only
-    def finalize(self, status='success'):
+    def finalize(self, status: str = 'success') -> None:
         try:
             exit_code = 0 if status == 'success' else 1
             wandb.join(exit_code)
@@ -105,9 +110,9 @@ class WandbLogger(LightningLoggerBase):
             wandb.join()
 
     @property
-    def name(self):
+    def name(self) -> str:
         return self.experiment.project_name()
 
     @property
-    def version(self):
+    def version(self) -> str:
         return self.experiment.id
diff --git a/pytorch_lightning/logging/__init__.py b/pytorch_lightning/logging/__init__.py
index 69c451e..2058fff 100644
--- a/pytorch_lightning/logging/__init__.py
+++ b/pytorch_lightning/logging/__init__.py
@@ -1,12 +1,12 @@
 """
-.. warning:: `logging` package has been renamed to `loggers` since v0.6.1.
- The deprecated package name will be removed in v0.8.0.
+.. warning:: `logging` package has been renamed to `loggers` since v0.7.0.
+ The deprecated package name will be removed in v0.9.0.
 """
 
 import warnings
 
-warnings.warn("`logging` package has been renamed to `loggers` since v0.6.1"
-              " The deprecated package name will be removed in v0.8.0.", DeprecationWarning)
+warnings.warn("`logging` package has been renamed to `loggers` since v0.7.0"
+              " The deprecated package name will be removed in v0.9.0.", DeprecationWarning)
 
 from pytorch_lightning.loggers import *  # noqa: F403
 from pytorch_lightning.loggers import base, tensorboard  # noqa: F403
diff --git a/pytorch_lightning/logging/comet.py b/pytorch_lightning/logging/comet.py
index 3961fcd..48a426d 100644
--- a/pytorch_lightning/logging/comet.py
+++ b/pytorch_lightning/logging/comet.py
@@ -1,5 +1,5 @@
 """
-.. warning:: `logging` package has been renamed to `loggers` since v0.6.1 and will be removed in v0.8.0
+.. warning:: `logging` package has been renamed to `loggers` since v0.7.0 and will be removed in v0.9.0
 """
 
-from pytorch_lightning.loggers import comet  # noqa: F403
+from pytorch_lightning.loggers.comet import CometLogger  # noqa: F403
diff --git a/pytorch_lightning/logging/comet_logger.py b/pytorch_lightning/logging/comet_logger.py
new file mode 100644
index 0000000..47a524d
--- /dev/null
+++ b/pytorch_lightning/logging/comet_logger.py
@@ -0,0 +1,11 @@
+"""
+.. warning:: `comet_logger` module has been renamed to `comet` since v0.6.0.
+ The deprecated module name will be removed in v0.8.0.
+"""
+
+import warnings
+
+warnings.warn("`comet_logger` module has been renamed to `comet` since v0.6.0."
+              " The deprecated module name will be removed in v0.8.0.", DeprecationWarning)
+
+from pytorch_lightning.loggers.comet import CometLogger  # noqa: E402
diff --git a/pytorch_lightning/logging/mlflow.py b/pytorch_lightning/logging/mlflow.py
index 70ab735..895f41f 100644
--- a/pytorch_lightning/logging/mlflow.py
+++ b/pytorch_lightning/logging/mlflow.py
@@ -1,5 +1,5 @@
 """
-.. warning:: `logging` package has been renamed to `loggers` since v0.6.1 and will be removed in v0.8.0
+.. warning:: `logging` package has been renamed to `loggers` since v0.7.0 and will be removed in v0.9.0
 """
 
-from pytorch_lightning.loggers import mlflow  # noqa: F403
+from pytorch_lightning.loggers.mlflow import MLFlowLogger  # noqa: F403
diff --git a/pytorch_lightning/logging/mlflow_logger.py b/pytorch_lightning/logging/mlflow_logger.py
new file mode 100644
index 0000000..d8fc635
--- /dev/null
+++ b/pytorch_lightning/logging/mlflow_logger.py
@@ -0,0 +1,11 @@
+"""
+.. warning:: `mlflow_logger` module has been renamed to `mlflow` since v0.6.0.
+ The deprecated module name will be removed in v0.8.0.
+"""
+
+import warnings
+
+warnings.warn("`mlflow_logger` module has been renamed to `mlflow` since v0.6.0."
+              " The deprecated module name will be removed in v0.8.0.", DeprecationWarning)
+
+from pytorch_lightning.loggers.mlflow import MLFlowLogger  # noqa: E402
diff --git a/pytorch_lightning/logging/neptune.py b/pytorch_lightning/logging/neptune.py
index 0f5a73d..f1b6452 100644
--- a/pytorch_lightning/logging/neptune.py
+++ b/pytorch_lightning/logging/neptune.py
@@ -1,5 +1,5 @@
 """
-.. warning:: `logging` package has been renamed to `loggers` since v0.6.1 and will be removed in v0.8.0
+.. warning:: `logging` package has been renamed to `loggers` since v0.7.0 and will be removed in v0.9.0
 """
 
-from pytorch_lightning.loggers import neptune  # noqa: F403
+from pytorch_lightning.loggers.neptune import NeptuneLogger  # noqa: F403
diff --git a/pytorch_lightning/logging/test_tube.py b/pytorch_lightning/logging/test_tube.py
index a821a43..a9bc71e 100644
--- a/pytorch_lightning/logging/test_tube.py
+++ b/pytorch_lightning/logging/test_tube.py
@@ -1,5 +1,5 @@
 """
-.. warning:: `logging` package has been renamed to `loggers` since v0.6.1 and will be removed in v0.8.0
+.. warning:: `logging` package has been renamed to `loggers` since v0.7.0 and will be removed in v0.9.0
 """
 
-from pytorch_lightning.loggers import test_tube  # noqa: F403
+from pytorch_lightning.loggers.test_tube import TestTubeLogger  # noqa: F403
diff --git a/pytorch_lightning/logging/test_tube_logger.py b/pytorch_lightning/logging/test_tube_logger.py
new file mode 100644
index 0000000..cdd0682
--- /dev/null
+++ b/pytorch_lightning/logging/test_tube_logger.py
@@ -0,0 +1,11 @@
+"""
+.. warning:: `test_tube_logger` module has been renamed to `test_tube` since v0.6.0.
+ The deprecated module name will be removed in v0.8.0.
+"""
+
+import warnings
+
+warnings.warn("`test_tube_logger` module has been renamed to `test_tube` since v0.6.0."
+              " The deprecated module name will be removed in v0.8.0.", DeprecationWarning)
+
+from pytorch_lightning.loggers.test_tube import TestTubeLogger  # noqa: E402
diff --git a/pytorch_lightning/logging/wandb.py b/pytorch_lightning/logging/wandb.py
index b0a96d2..e4527b7 100644
--- a/pytorch_lightning/logging/wandb.py
+++ b/pytorch_lightning/logging/wandb.py
@@ -1,5 +1,5 @@
 """
-.. warning:: `logging` package has been renamed to `loggers` since v0.6.1 and will be removed in v0.8.0
+.. warning:: `logging` package has been renamed to `loggers` since v0.7.0 and will be removed in v0.9.0
 """
 
-from pytorch_lightning.loggers import wandb  # noqa: F403
+from pytorch_lightning.loggers.wandb import WandbLogger  # noqa: F403
diff --git a/pytorch_lightning/profiler/__init__.py b/pytorch_lightning/profiler/__init__.py
index 0341f07..5854209 100644
--- a/pytorch_lightning/profiler/__init__.py
+++ b/pytorch_lightning/profiler/__init__.py
@@ -16,7 +16,7 @@ PyTorch Lightning supports profiling standard actions in the training loop out o
 - on_after_backward
 - optimizer_step
 - on_batch_end
-- training_end
+- training_step_end
 - on_training_end
 
 Enable simple profiling
diff --git a/pytorch_lightning/profiler/profiler.py b/pytorch_lightning/profiler/profiler.py
index ffecba5..dee6c45 100644
--- a/pytorch_lightning/profiler/profiler.py
+++ b/pytorch_lightning/profiler/profiler.py
@@ -1,14 +1,13 @@
-from contextlib import contextmanager
-from collections import defaultdict
-import time
-import numpy as np
 import cProfile
-import pstats
 import io
+import logging as log
+import pstats
+import time
 from abc import ABC, abstractmethod
-import logging
+from collections import defaultdict
+from contextlib import contextmanager
 
-logger = logging.getLogger(__name__)
+import numpy as np
 
 
 class BaseProfiler(ABC):
@@ -124,7 +123,7 @@ class Profiler(BaseProfiler):
                 action, f"{np.mean(durations):.5}", f"{np.sum(durations):.5}",
             )
         output_string += "\n"
-        logger.info(output_string)
+        log.info(output_string)
 
 
 class AdvancedProfiler(BaseProfiler):
@@ -177,4 +176,4 @@ class AdvancedProfiler(BaseProfiler):
             output_string = "\nProfiler Report\n"
             for action, stats in self.recorded_stats.items():
                 output_string += f"\nProfile stats for: {action}\n{stats}"
-            logger.info(output_string)
+            log.info(output_string)
diff --git a/pytorch_lightning/pt_overrides/__init__.py b/pytorch_lightning/pt_overrides/__init__.py
index 9db26c1..b68986d 100644
--- a/pytorch_lightning/pt_overrides/__init__.py
+++ b/pytorch_lightning/pt_overrides/__init__.py
@@ -7,5 +7,3 @@ import warnings
 
 warnings.warn("`pt_overrides` package has been renamed to `overrides` since v0.6.0."
               " The deprecated module name will be removed in v0.8.0.", DeprecationWarning)
-
-from pytorch_lightning.overrides import override_data_parallel  # noqa: E402
diff --git a/pytorch_lightning/pt_overrides/override_data_parallel.py b/pytorch_lightning/pt_overrides/override_data_parallel.py
new file mode 100644
index 0000000..bc435b7
--- /dev/null
+++ b/pytorch_lightning/pt_overrides/override_data_parallel.py
@@ -0,0 +1,12 @@
+"""
+.. warning:: `override_data_parallel` module has been renamed to `data_parallel` since v0.6.0.
+ The deprecated module name will be removed in v0.8.0.
+"""
+
+import warnings
+
+warnings.warn("`override_data_parallel` module has been renamed to `data_parallel` since v0.6.0."
+              " The deprecated module name will be removed in v0.8.0.", DeprecationWarning)
+
+from pytorch_lightning.overrides.data_parallel import (  # noqa: F402
+    get_a_var, parallel_apply, LightningDataParallel, LightningDistributedDataParallel)
diff --git a/pytorch_lightning/root_module/decorators.py b/pytorch_lightning/root_module/decorators.py
new file mode 100644
index 0000000..88afe09
--- /dev/null
+++ b/pytorch_lightning/root_module/decorators.py
@@ -0,0 +1,11 @@
+"""
+.. warning:: `root_module.decorators` module has been renamed to `core.decorators` since v0.6.0.
+ The deprecated module name will be removed in v0.8.0.
+"""
+
+import warnings
+
+warnings.warn("`root_module.decorators` module has been renamed to `core.decorators` since v0.6.0."
+              " The deprecated module name will be removed in v0.8.0.", DeprecationWarning)
+
+from pytorch_lightning.core.decorators import *  # noqa: F403
diff --git a/pytorch_lightning/root_module/grads.py b/pytorch_lightning/root_module/grads.py
new file mode 100644
index 0000000..1f96173
--- /dev/null
+++ b/pytorch_lightning/root_module/grads.py
@@ -0,0 +1,11 @@
+"""
+.. warning:: `root_module.grads` module has been renamed to `core.grads` since v0.6.0.
+ The deprecated module name will be removed in v0.8.0.
+"""
+
+import warnings
+
+warnings.warn("`root_module.grads` module has been renamed to `core.grads` since v0.6.0."
+              " The deprecated module name will be removed in v0.8.0.", DeprecationWarning)
+
+from pytorch_lightning.core.grads import *  # noqa: F403
diff --git a/pytorch_lightning/root_module/hooks.py b/pytorch_lightning/root_module/hooks.py
new file mode 100644
index 0000000..e4beaee
--- /dev/null
+++ b/pytorch_lightning/root_module/hooks.py
@@ -0,0 +1,11 @@
+"""
+.. warning:: `root_module.hooks` module has been renamed to `core.hooks` since v0.6.0.
+ The deprecated module name will be removed in v0.8.0.
+"""
+
+import warnings
+
+warnings.warn("`root_module.hooks` module has been renamed to `core.hooks` since v0.6.0."
+              " The deprecated module name will be removed in v0.8.0.", DeprecationWarning)
+
+from pytorch_lightning.core.hooks import *  # noqa: F403
diff --git a/pytorch_lightning/root_module/memory.py b/pytorch_lightning/root_module/memory.py
new file mode 100644
index 0000000..ef739ac
--- /dev/null
+++ b/pytorch_lightning/root_module/memory.py
@@ -0,0 +1,11 @@
+"""
+.. warning:: `root_module.memory` module has been renamed to `core.memory` since v0.6.0.
+ The deprecated module name will be removed in v0.8.0.
+"""
+
+import warnings
+
+warnings.warn("`root_module.memory` module has been renamed to `core.memory` since v0.6.0."
+              " The deprecated module name will be removed in v0.8.0.", DeprecationWarning)
+
+from pytorch_lightning.core.memory import *  # noqa: F403
diff --git a/pytorch_lightning/root_module/model_saving.py b/pytorch_lightning/root_module/model_saving.py
new file mode 100644
index 0000000..5af97ab
--- /dev/null
+++ b/pytorch_lightning/root_module/model_saving.py
@@ -0,0 +1,11 @@
+"""
+.. warning:: `root_module.model_saving` module has been renamed to `core.saving` since v0.6.0.
+ The deprecated module name will be removed in v0.8.0.
+"""
+
+import warnings
+
+warnings.warn("`root_module.model_saving` module has been renamed to `core.saving` since v0.6.0."
+              " The deprecated module name will be removed in v0.8.0.", DeprecationWarning)
+
+from pytorch_lightning.core.saving import *  # noqa: F403
diff --git a/pytorch_lightning/root_module/root_module.py b/pytorch_lightning/root_module/root_module.py
new file mode 100644
index 0000000..4dd4724
--- /dev/null
+++ b/pytorch_lightning/root_module/root_module.py
@@ -0,0 +1,11 @@
+"""
+.. warning:: `root_module.root_module` module has been renamed to `core.lightning` since v0.6.0.
+ The deprecated module name will be removed in v0.8.0.
+"""
+
+import warnings
+
+warnings.warn("`root_module.root_module` module has been renamed to `core.lightning` since v0.6.0."
+              " The deprecated module name will be removed in v0.8.0.", DeprecationWarning)
+
+from pytorch_lightning.core.lightning import *  # noqa: F403
diff --git a/pytorch_lightning/trainer/__init__.py b/pytorch_lightning/trainer/__init__.py
index 98c2b99..27465aa 100644
--- a/pytorch_lightning/trainer/__init__.py
+++ b/pytorch_lightning/trainer/__init__.py
@@ -1,17 +1,23 @@
 """
+Once you've organized your PyTorch code into a LightningModule,
+the Trainer automates everything else.
 
-The trainer de-couples the engineering code (16-bit, early stopping, GPU distribution, etc...) from the
-science code (GAN, BERT, your project, etc...). It uses many assumptions which are best practices in
-AI research today.
+.. figure:: /_images/lightning_module/pt_trainer.png
+   :alt: Convert from PyTorch to Lightning
 
-The trainer automates all parts of training except:
+This abstraction achieves the following:
 
-- what happens in training , test, val loop
-- where the data come from
-- which optimizers to use
-- how to do the computations
+    1. You maintain control over all aspects via PyTorch code without an added abstraction.
 
-The Trainer delegates those calls to your LightningModule which defines how to do those parts.
+    2. The trainer uses best practices embedded by contributors and users
+       from top AI labs such as Facebook AI Research, NYU, MIT, Stanford, etc...
+
+    3. The trainer allows overriding any key part that you don't want automated.
+
+-----------
+
+Basic use
+---------
 
 This is the basic use of the trainer:
 
@@ -23,6 +29,850 @@ This is the basic use of the trainer:
 
     trainer = Trainer()
     trainer.fit(model)
+
+--------
+
+Best Practices
+--------------
+For cluster computing, it's recommended you structure your
+main.py file this way
+
+.. code-block:: python
+
+    from argparse import ArgumentParser
+
+    def main(hparams):
+        model = LightningModule()
+        trainer = Trainer(gpus=hparams.gpus)
+        trainer.fit(model)
+
+    if __name__ == '__main__':
+        parser = ArgumentParser()
+        parser.add_argument('--gpus', default=None)
+        args = parser.parse_args()
+
+        main(args)
+
+So you can run it like so:distributed_backend
+
+.. code-block:: bash
+
+    $ python main.py --gpus 2
+
+------------
+
+Testing
+-------
+Once you're done training, feel free to run the test set!
+(Only right before publishing your paper or pushing to production)
+
+.. code-block:: python
+
+    trainer.test()
+
+------------
+
+Deployment / prediction
+-----------------------
+You just trained a LightningModule which is also just a torch.nn.Module.
+Use it to do whatever!
+
+.. code-block:: python
+
+    # load model
+    pretrained_model = LightningModule.load_from_checkpoint(PATH)
+    pretrained_model.freeze()
+
+    # use it for finetuning
+    def forward(self, x):
+        features = pretrained_model(x)
+        classes = classifier(features)
+
+    # or for prediction
+    out = pretrained_model(x)
+    api_write({'response': out}
+
+-------
+
+Trainer flags
+-------------
+
+accumulate_grad_batches
+^^^^^^^^^^^^^^^^^^^^^^^
+Accumulates grads every k batches or as set up in the dict.
+
+.. code-block:: python
+
+    # default used by the Trainer (no accumulation)
+    trainer = Trainer(accumulate_grad_batches=1)
+
+Example::
+
+    # accumulate every 4 batches (effective batch size is batch*4)
+    trainer = Trainer(accumulate_grad_batches=4)
+
+    # no accumulation for epochs 1-4. accumulate 3 for epochs 5-10. accumulate 20 after that
+    trainer = Trainer(accumulate_grad_batches={5: 3, 10: 20})
+
+amp_level
+^^^^^^^^^
+The optimization level to use (O1, O2, etc...)
+for 16-bit GPU precision (using NVIDIA apex under the hood).
+
+Check `NVIDIA apex docs <https://nvidia.github.io/apex/amp.html#opt-levels>`_ for level
+
+Example::
+
+    # default used by the Trainer
+    trainer = Trainer(amp_level='O1')
+
+benchmark
+^^^^^^^^^
+
+If true enables cudnn.benchmark.
+This flag is likely to increase the speed of your system if your
+input sizes don't change. However, if it does, then it will likely
+make your system slower.
+
+The speedup comes from allowing the cudnn auto-tuner to find the best
+algorithm for the hardware `[see discussion here]
+<https://discuss.pytorch.org/t/what-does-torch-backends-cudnn-benchmark-do/5936>`_.
+
+Example::
+
+    # default used by the Trainer
+    trainer = Trainer(benchmark=False)
+
+callbacks
+^^^^^^^^^
+
+Add a list of user defined callbacks.
+
+.. note:: Only user defined callbacks (ie: Not EarlyStopping or ModelCheckpoint)
+
+.. code-block:: python
+
+    # a list of callbacks
+    callbacks = [PrintCallback()]
+    trainer = Trainer(callbacks=callbacks)
+
+Example::
+
+    from pytorch_lightning.callbacks import Callback
+
+    class PrintCallback(Callback):
+        def on_train_start(self):
+            print("Training is started!")
+        def on_train_end(self):
+            print(f"Training is done. The logs are: {self.trainer.logs}")
+
+check_val_every_n_epoch
+^^^^^^^^^^^^^^^^^^^^^^^
+
+Check val every n train epochs.
+
+Example::
+
+    # default used by the Trainer
+    trainer = Trainer(check_val_every_n_epoch=1)
+
+    # run val loop every 10 training epochs
+    trainer = Trainer(check_val_every_n_epoch=10)
+
+checkpoint_callback
+^^^^^^^^^^^^^^^^^^^
+Callback for checkpointing.
+
+.. code-block:: python
+
+    trainer = Trainer(checkpoint_callback=checkpoint_callback)
+
+Example::
+
+    from pytorch_lightning.callbacks import ModelCheckpoint
+
+    # default used by the Trainer
+    checkpoint_callback = ModelCheckpoint(
+        filepath=os.getcwd(),
+        save_best_only=True,
+        verbose=True,
+        monitor='val_loss',
+        mode='min',
+        prefix=''
+    )
+
+default_save_path
+^^^^^^^^^^^^^^^^^
+
+Default path for logs and weights when no logger
+or :class:`pytorch_lightning.callbacks.ModelCheckpoint` callback passed.
+On certain clusters you might want to separate where logs and checkpoints
+are stored. If you don't then use this method for convenience.
+
+Example::
+
+    # default used by the Trainer
+    trainer = Trainer(default_save_path=os.getcwd())
+
+distributed_backend
+^^^^^^^^^^^^^^^^^^^
+The distributed backend to use.
+
+- (```dp```) is DataParallel (split batch among GPUs of same machine)
+- (```ddp```) is DistributedDataParallel (each gpu on each node trains, and syncs grads)
+- (```ddp2```) dp on node, ddp across nodes. Useful for things like increasing
+    the number of negative samples
+
+.. code-block:: python
+
+    # default used by the Trainer
+    trainer = Trainer(distributed_backend=None)
+
+Example::
+
+    # dp = DataParallel
+    trainer = Trainer(gpus=2, distributed_backend='dp')
+
+    # ddp = DistributedDataParallel
+    trainer = Trainer(gpus=2, num_nodes=2, distributed_backend='ddp')
+
+    # ddp2 = DistributedDataParallel + dp
+    trainer = Trainer(gpus=2, num_nodes=2, distributed_backend='ddp2')
+
+early_stop_callback
+^^^^^^^^^^^^^^^^^^^
+
+Callback for early stopping.
+early_stop_callback (:class:`pytorch_lightning.callbacks.EarlyStopping`)
+
+- ``True``: A default callback monitoring ``'val_loss'`` is created.
+   Will raise an error if ``'val_loss'`` is not found.
+- ``False``: Early stopping will be disabled.
+- ``None``: The default callback monitoring ``'val_loss'`` is created.
+- Default: ``None``.
+
+.. code-block:: python
+
+    trainer = Trainer(early_stop_callback=early_stop_callback)
+
+Example::
+
+    from pytorch_lightning.callbacks import EarlyStopping
+
+    # default used by the Trainer
+    early_stop_callback = EarlyStopping(
+        monitor='val_loss',
+        patience=3,
+        strict=False,
+        verbose=False,
+        mode='min'
+    )
+
+.. note:: If ``'val_loss'`` is not found will work as if early stopping is disabled.
+
+fast_dev_run
+^^^^^^^^^^^^
+
+Runs 1 batch of train, test  and val to find any bugs (ie: a sort of unit test).
+
+Under the hood the pseudocode looks like this:
+
+.. code-block:: python
+
+    # loading
+    __init__()
+    prepare_data
+
+    # test training step
+    training_batch = next(train_dataloader)
+    training_step(training_batch)
+
+    # test val step
+    val_batch = next(val_dataloader)
+    out = validation_step(val_batch)
+    validation_epoch_end([out])
+
+Example::
+
+    # default used by the Trainer
+    trainer = Trainer(fast_dev_run=False)
+
+    # runs 1 train, val, test  batch and program ends
+    trainer = Trainer(fast_dev_run=True)
+
+gpus
+^^^^
+
+- Number of GPUs to train on
+- or Which GPUs to train on
+- can handle strings
+
+Example::
+
+    # default used by the Trainer (ie: train on CPU)
+    trainer = Trainer(gpus=None)
+
+    # int: train on 2 gpus
+    trainer = Trainer(gpus=2)
+
+    # list: train on GPUs 1, 4 (by bus ordering)
+    trainer = Trainer(gpus=[1, 4])
+    trainer = Trainer(gpus='1, 4') # equivalent
+
+    # -1: train on all gpus
+    trainer = Trainer(gpus=-1)
+    trainer = Trainer(gpus='-1') # equivalent
+
+    # combine with num_nodes to train on multiple GPUs across nodes
+    # uses 8 gpus in total
+    trainer = Trainer(gpus=2, num_nodes=4)
+
+.. note:: See the `multi-gpu computing guide <multi_gpu.rst>`_
+
+gradient_clip_val
+^^^^^^^^^^^^^^^^^
+Gradient clipping value
+
+- 0 means don't clip.
+
+Example::
+
+    # default used by the Trainer
+    trainer = Trainer(gradient_clip_val=0.0)
+
+
+gradient_clip:
+
+.. warning:: .. deprecated:: 0.5.0
+    Use `gradient_clip_val` instead. Will remove 0.8.0.
+
+log_gpu_memory
+^^^^^^^^^^^^^^
+Options:
+
+- None
+- 'min_max'
+- 'all'
+
+Example::
+
+    # default used by the Trainer
+    trainer = Trainer(log_gpu_memory=None)
+
+    # log all the GPUs (on master node only)
+    trainer = Trainer(log_gpu_memory='all')
+
+    # log only the min and max memory on the master node
+    trainer = Trainer(log_gpu_memory='min_max')
+
+.. note:: Might slow performance because it uses the output of nvidia-smi.
+
+log_save_interval
+^^^^^^^^^^^^^^^^^
+
+Writes logs to disk this often.
+
+Example::
+
+    # default used by the Trainer
+    trainer = Trainer(log_save_interval=100)
+
+logger
+^^^^^^
+
+`Logger <loggers.rst>`_ (or iterable collection of loggers) for experiment tracking.
+
+.. code-block:: python
+
+    Trainer(logger=logger)
+
+Example::
+
+    from pytorch_lightning.loggers import TensorBoardLogger
+
+    # default logger used by trainer
+    logger = TensorBoardLogger(
+        save_dir=os.getcwd(),
+        version=self.slurm_job_id,
+        name='lightning_logs'
+    )
+
+max_epochs
+^^^^^^^^^^
+Stop training once this number of epochs is reached
+
+Example::
+
+    # default used by the Trainer
+    trainer = Trainer(max_epochs=1000)
+
+max_nb_epochs:
+
+.. warning:: .. deprecated:: 0.5.0
+    Use `max_epochs` instead. Will remove 0.8.0.
+
+min_epochs
+^^^^^^^^^^
+Force training for at least these many epochs
+
+Example::
+
+    # default used by the Trainer
+    trainer = Trainer(min_epochs=1)
+
+min_nb_epochs:
+
+.. warning:: deprecated:: 0.5.0
+    Use `min_epochs` instead. Will remove 0.8.0.
+
+max_steps
+^^^^^^^^^
+Stop training after this number of steps
+Training will stop if max_steps or max_epochs have reached (earliest).
+
+.. code-block:: python
+
+    # Default (disabled)
+    trainer = Trainer(max_steps=None)
+
+Example::
+
+    # Stop after 100 steps
+    trainer = Trainer(max_steps=100)
+
+min_steps
+^^^^^^^^^
+
+Force training for at least these number of steps.
+Trainer will train model for at least min_steps or min_epochs (latest).
+
+.. code-block:: python
+
+    # Default (disabled)
+    trainer = Trainer(min_steps=None)
+
+Example::
+
+    # Run at least for 100 steps (disable min_epochs)
+    trainer = Trainer(min_steps=100, min_epochs=0)
+
+num_nodes
+^^^^^^^^^
+
+Number of GPU nodes for distributed training.
+
+Example::
+
+    # default used by the Trainer
+    trainer = Trainer(num_nodes=1)
+
+    # to train on 8 nodes
+    trainer = Trainer(num_nodes=8)
+
+nb_gpu_nodes:
+
+.. warning:: .. deprecated:: 0.5.0
+    Use `num_nodes` instead. Will remove 0.8.0.
+
+num_sanity_val_steps
+^^^^^^^^^^^^^^^^^^^^
+
+Sanity check runs n batches of val before starting the training routine.
+This catches any bugs in your validation without having to wait for the first validation check.
+The Trainer uses 5 steps by default. Turn it off or modify it here.
+
+Example::
+
+    # default used by the Trainer
+    trainer = Trainer(num_sanity_val_steps=5)
+
+    # turn it off
+    trainer = Trainer(num_sanity_val_steps=0)
+
+nb_sanity_val_steps:
+
+.. warning:: .. deprecated:: 0.5.0
+    Use `num_sanity_val_steps` instead. Will remove 0.8.0.
+
+num_tpu_cores
+^^^^^^^^^^^^^
+How many TPU cores to train on (1 or 8).
+
+A single TPU v2 or v3 has 8 cores. A TPU pod has
+up to 2048 cores. A slice of a POD means you get as many cores
+as you request.
+
+Your effective batch size is batch_size * total tpu cores.
+
+.. note:: No need to add a DistributedDataSampler, Lightning automatically does it for you.
+
+This parameter can be either 1 or 8.
+
+Example::
+
+    # your_trainer_file.py
+
+    # default used by the Trainer (ie: train on CPU)
+    trainer = Trainer(num_tpu_cores=None)
+
+    # int: train on a single core
+    trainer = Trainer(num_tpu_cores=1)
+
+    # int: train on all cores few cores
+    trainer = Trainer(num_tpu_cores=8)
+
+    # for 8+ cores must submit via xla script with
+    # a max of 8 cores specified. The XLA script
+    # will duplicate script onto each TPU in the POD
+    trainer = Trainer(num_tpu_cores=8)
+
+    # -1: train on all available TPUs
+    trainer = Trainer(num_tpu_cores=-1)
+
+To train on more than 8 cores (ie: a POD),
+submit this script using the xla_dist script.
+
+Example::
+
+    $ python -m torch_xla.distributed.xla_dist
+    --tpu=$TPU_POD_NAME
+    --conda-env=torch-xla-nightly
+    --env=XLA_USE_BF16=1
+    -- python your_trainer_file.py
+
+overfit_pct
+^^^^^^^^^^^
+Uses this much data of all datasets.
+Useful for quickly debugging or trying to overfit on purpose
+
+Example::
+
+    # default used by the Trainer
+    trainer = Trainer(overfit_pct=0.0)
+
+    # use only 1% of the train, test, val datasets
+    trainer = Trainer(overfit_pct=0.01)
+
+precision
+^^^^^^^^^
+Full precision (32), half precision (16).
+Can be used on CPU, GPU or TPUs.
+
+If used on TPU will use torch.bfloat16 but tensor printing
+will still show torch.float32.
+
+Example::
+
+    # default used by the Trainer
+    trainer = Trainer(precision=32)
+
+    # 16-bit precision
+    trainer = Trainer(precision=16)
+
+    # one day
+    trainer = Trainer(precision=8|4|2)
+
+print_nan_grads
+^^^^^^^^^^^^^^^
+
+Prints gradients with nan values
+
+Example::
+
+    # default used by the Trainer
+    trainer = Trainer(print_nan_grads=False)
+
+process_position
+^^^^^^^^^^^^^^^^
+Orders the tqdm bar. Useful when running multiple trainers
+on the same node.
+
+Example::
+
+    # default used by the Trainer
+    trainer = Trainer(process_position=0)
+
+profiler
+^^^^^^^^
+To profile individual steps during training and assist in identifying bottlenecks.
+
+See the `profiler documentation <profiler.rst>`_. for more details.
+
+Example::
+
+    from pytorch_lightning.profiler import Profiler, AdvancedProfiler
+
+    # default used by the Trainer
+    trainer = Trainer(profiler=None)
+
+    # to profile standard training events
+    trainer = Trainer(profiler=True)
+
+    # equivalent to profiler=True
+    profiler = Profiler()
+    trainer = Trainer(profiler=profiler)
+
+    # advanced profiler for function-level stats
+    profiler = AdvancedProfiler()
+    trainer = Trainer(profiler=profiler)
+
+progress_bar_refresh_rate
+^^^^^^^^^^^^^^^^^^^^^^^^^
+How often to refresh progress bar (in steps).
+In notebooks, faster refresh rates (lower number) is known to crash them
+because of their screen refresh rates, so raise it to 50 or more.
+
+Example::
+
+    # default used by the Trainer
+    trainer = Trainer(progress_bar_refresh_rate=1)
+
+
+reload_dataloaders_every_epoch
+^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
+Set to True to reload dataloaders every epoch.
+
+.. code-block:: python
+
+    # if False (default)
+    train_loader = model.train_dataloader()
+    for epoch in epochs:
+        for batch in train_loader:
+            ...
+
+    # if True
+    for epoch in epochs:
+        train_loader = model.train_dataloader()
+        for batch in train_loader:
+
+resume_from_checkpoint
+^^^^^^^^^^^^^^^^^^^^^^
+To resume training from a specific checkpoint pass in the path here.k
+
+Example::
+
+    # default used by the Trainer
+    trainer = Trainer(resume_from_checkpoint=None)
+
+    # resume from a specific checkpoint
+    trainer = Trainer(resume_from_checkpoint='some/path/to/my_checkpoint.ckpt')
+
+row_log_interval
+^^^^^^^^^^^^^^^^
+
+How often to add logging rows (does not write to disk)
+
+Example::
+
+    # default used by the Trainer
+    trainer = Trainer(row_log_interval=10)
+
+
+add_row_log_interval:
+
+.. warning:: .. deprecated:: 0.5.0
+    Use `row_log_interval` instead. Will remove 0.8.0.
+
+use_amp:
+
+.. warning:: .. deprecated:: 0.7.0
+    Use `precision` instead. Will remove 0.9.0.
+
+show_progress_bar
+^^^^^^^^^^^^^^^^^
+
+If true shows tqdm progress bar
+
+Example::
+
+    # default used by the Trainer
+    trainer = Trainer(show_progress_bar=True)
+
+test_percent_check
+^^^^^^^^^^^^^^^^^^
+
+How much of test dataset to check.
+
+Example::
+
+    # default used by the Trainer
+    trainer = Trainer(test_percent_check=1.0)
+
+    # run through only 25% of the test set each epoch
+    trainer = Trainer(test_percent_check=0.25)
+
+val_check_interval
+^^^^^^^^^^^^^^^^^^
+
+How often within one training epoch to check the validation set.
+Can specify as float or int.
+
+- use (float) to check within a training epoch
+- use (int) to check every n steps (batches)
+
+.. code-block:: python
+
+    # default used by the Trainer
+    trainer = Trainer(val_check_interval=1.0)
+
+Example::
+
+    # check validation set 4 times during a training epoch
+    trainer = Trainer(val_check_interval=0.25)
+
+    # check validation set every 1000 training batches
+    # use this when using iterableDataset and your dataset has no length
+    # (ie: production cases with streaming data)
+    trainer = Trainer(val_check_interval=1000)
+
+track_grad_norm
+^^^^^^^^^^^^^^^
+
+- no tracking (-1)
+- Otherwise tracks that norm (2 for 2-norm)
+
+.. code-block:: python
+
+    # default used by the Trainer
+    trainer = Trainer(track_grad_norm=-1)
+
+Example::
+
+    # track the 2-norm
+    trainer = Trainer(track_grad_norm=2)
+
+train_percent_check
+^^^^^^^^^^^^^^^^^^^
+
+How much of training dataset to check.
+Useful when debugging or testing something that happens at the end of an epoch.
+
+.. code-block::python
+
+    # default used by the Trainer
+    trainer = Trainer(train_percent_check=1.0)
+
+Example::
+
+    # default used by the Trainer
+    trainer = Trainer(train_percent_check=1.0)
+
+    # run through only 25% of the training set each epoch
+    trainer = Trainer(train_percent_check=0.25)
+
+truncated_bptt_steps
+^^^^^^^^^^^^^^^^^^^^
+
+Truncated back prop breaks performs backprop every k steps of
+a much longer sequence.
+
+If this is enabled, your batches will automatically get truncated
+and the trainer will apply Truncated Backprop to it.
+
+(`Williams et al. "An efficient gradient-based algorithm for on-line training of
+recurrent network trajectories."
+<http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.56.7941&rep=rep1&type=pdf>`_)
+
+Example::
+
+    # default used by the Trainer (ie: disabled)
+    trainer = Trainer(truncated_bptt_steps=None)
+
+    # backprop every 5 steps in a batch
+    trainer = Trainer(truncated_bptt_steps=5)
+
+.. note::  Make sure your batches have a sequence dimension.
+
+Lightning takes care to split your batch along the time-dimension.
+
+.. code-block:: python
+
+    # we use the second as the time dimension
+    # (batch, time, ...)
+    sub_batch = batch[0, 0:t, ...]
+
+Using this feature requires updating your LightningModule's
+:meth:`pytorch_lightning.core.LightningModule.training_step` to include a `hiddens` arg
+with the hidden
+
+.. code-block:: python
+
+        # Truncated back-propagation through time
+        def training_step(self, batch, batch_idx, hiddens):
+            # hiddens are the hiddens from the previous truncated backprop step
+            out, hiddens = self.lstm(data, hiddens)
+
+            return {
+                "loss": ...,
+                "hiddens": hiddens  # remember to detach() this
+            }
+
+To modify how the batch is split,
+override :meth:`pytorch_lightning.core.LightningModule.tbptt_split_batch`:
+
+.. code-block:: python
+
+        class LitMNIST(pl.LightningModule):
+            def tbptt_split_batch(self, batch, split_size):
+                # do your own splitting on the batch
+                return splits
+
+
+val_percent_check
+^^^^^^^^^^^^^^^^^
+
+How much of validation dataset to check.
+Useful when debugging or testing something that happens at the end of an epoch.
+
+Example::
+
+    # default used by the Trainer
+    trainer = Trainer(val_percent_check=1.0)
+
+    # run through only 25% of the validation set each epoch
+    trainer = Trainer(val_percent_check=0.25)
+
+weights_save_path
+^^^^^^^^^^^^^^^^^
+Directory of where to save weights if specified.
+
+.. code-block:: python
+
+    # default used by the Trainer
+    trainer = Trainer(weights_save_path=os.getcwd())
+
+Example::
+
+    # save to your custom path
+    trainer = Trainer(weights_save_path='my/path')
+
+    # if checkpoint callback used, then overrides the weights path
+    # **NOTE: this saves weights to some/path NOT my/path
+    checkpoint_callback = ModelCheckpoint(filepath='some/path')
+    trainer = Trainer(
+        checkpoint_callback=checkpoint_callback,
+        weights_save_path='my/path'
+    )
+
+weights_summary
+^^^^^^^^^^^^^^^
+Prints a summary of the weights when training begins.
+Options: 'full', 'top', None.
+
+Example::
+
+    # default used by the Trainer (ie: print all weights)
+    trainer = Trainer(weights_summary='full')
+
+    # print only the top level modules
+    trainer = Trainer(weights_summary='top')
+
+    # don't print a summary
+    trainer = Trainer(weights_summary=None)
+
+Trainer class
+-------------
+
 """
 
 from .trainer import Trainer
diff --git a/pytorch_lightning/trainer/auto_mix_precision.py b/pytorch_lightning/trainer/auto_mix_precision.py
index 135a0bc..a84f44a 100644
--- a/pytorch_lightning/trainer/auto_mix_precision.py
+++ b/pytorch_lightning/trainer/auto_mix_precision.py
@@ -12,8 +12,9 @@ import logging as log
 
 class TrainerAMPMixin(ABC):
 
-    def __init__(self):
-        self.use_amp = None
+    # this is just a summary on variables used in this abstract class,
+    #  the proper values/initialisation should be done in child class
+    use_amp: bool
 
     def init_amp(self, use_amp):
         self.use_amp = use_amp and APEX_AVAILABLE
diff --git a/pytorch_lightning/trainer/callback_config.py b/pytorch_lightning/trainer/callback_config.py
index 4e6f5a9..6006702 100644
--- a/pytorch_lightning/trainer/callback_config.py
+++ b/pytorch_lightning/trainer/callback_config.py
@@ -1,17 +1,29 @@
 import os
-from abc import ABC
+from abc import ABC, abstractmethod
+from typing import Union
 
 from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping
+from pytorch_lightning.loggers import LightningLoggerBase
 
 
 class TrainerCallbackConfigMixin(ABC):
 
-    def __init__(self):
-        # this is just a summary on variables used in this abstract class,
-        #  the proper values/initialisation should be done in child class
-        self.default_save_path = None
-        self.save_checkpoint = None
-        self.slurm_job_id = None
+    # this is just a summary on variables used in this abstract class,
+    #  the proper values/initialisation should be done in child class
+    default_save_path: str
+    logger: Union[LightningLoggerBase, bool]
+    weights_save_path: str
+    ckpt_path: str
+    checkpoint_callback: ModelCheckpoint
+
+    @property
+    @abstractmethod
+    def slurm_job_id(self) -> int:
+        """Warning: this is just empty shell for code implemented in other class."""
+
+    @abstractmethod
+    def save_checkpoint(self, *args):
+        """Warning: this is just empty shell for code implemented in other class."""
 
     def configure_checkpoint_callback(self):
         """
@@ -20,6 +32,7 @@ class TrainerCallbackConfigMixin(ABC):
         User provided weights_saved_path
         Otherwise use os.getcwd()
         """
+        ckpt_path = self.default_save_path
         if self.checkpoint_callback is True:
             # init a default one
             if self.logger is not None:
@@ -35,28 +48,34 @@ class TrainerCallbackConfigMixin(ABC):
             else:
                 ckpt_path = os.path.join(self.default_save_path, "checkpoints")
 
+            # when no val step is defined, use 'loss' otherwise 'val_loss'
+            train_step_only = not self.is_overriden('validation_step')
+            monitor_key = 'loss' if train_step_only else 'val_loss'
+
+            self.ckpt_path = ckpt_path
+            os.makedirs(ckpt_path, exist_ok=True)
             self.checkpoint_callback = ModelCheckpoint(
-                filepath=ckpt_path
+                filepath=ckpt_path,
+                monitor=monitor_key
             )
         elif self.checkpoint_callback is False:
             self.checkpoint_callback = None
 
+        self.ckpt_path = ckpt_path
+
         if self.checkpoint_callback:
             # set the path for the callbacks
             self.checkpoint_callback.save_function = self.save_checkpoint
 
             # if checkpoint callback used, then override the weights path
-            self.weights_save_path = self.checkpoint_callback.filepath
-
-            # link to the trainer
-            self.checkpoint_callback.set_trainer(self)
+            self.weights_save_path = self.checkpoint_callback.dirpath
 
         # if weights_save_path is still none here, set to current working dir
         if self.weights_save_path is None:
             self.weights_save_path = self.default_save_path
 
     def configure_early_stopping(self, early_stop_callback):
-        if early_stop_callback is True:
+        if early_stop_callback is True or None:
             self.early_stop_callback = EarlyStopping(
                 monitor='val_loss',
                 patience=3,
@@ -65,21 +84,9 @@ class TrainerCallbackConfigMixin(ABC):
                 mode='min'
             )
             self.enable_early_stop = True
-        elif early_stop_callback is None:
-            self.early_stop_callback = EarlyStopping(
-                monitor='val_loss',
-                patience=3,
-                strict=False,
-                verbose=False,
-                mode='min'
-            )
-            self.enable_early_stop = True
         elif not early_stop_callback:
             self.early_stop_callback = None
             self.enable_early_stop = False
         else:
             self.early_stop_callback = early_stop_callback
             self.enable_early_stop = True
-
-        if self.early_stop_callback is not None:
-            self.early_stop_callback.set_trainer(self)
diff --git a/pytorch_lightning/trainer/callback_hook.py b/pytorch_lightning/trainer/callback_hook.py
new file mode 100644
index 0000000..48d703b
--- /dev/null
+++ b/pytorch_lightning/trainer/callback_hook.py
@@ -0,0 +1,73 @@
+from abc import ABC
+from typing import Callable
+
+from pytorch_lightning.callbacks import Callback
+
+
+class TrainerCallbackHookMixin(ABC):
+
+    def __init__(self):
+        # this is just a summary on variables used in this abstract class,
+        # the proper values/initialisation should be done in child class
+        self.callbacks: list[Callback] = []
+        self.get_model: Callable = ...
+
+    def on_init_start(self):
+        """Called when the trainer initialization begins, model has not yet been set."""
+        for callback in self.callbacks:
+            callback.on_init_start(self)
+
+    def on_init_end(self):
+        """Called when the trainer initialization ends, model has not yet been set."""
+        for callback in self.callbacks:
+            callback.on_init_end(self)
+
+    def on_epoch_start(self):
+        """Called when the epoch begins."""
+        for callback in self.callbacks:
+            callback.on_epoch_start(self, self.get_model())
+
+    def on_epoch_end(self):
+        """Called when the epoch ends."""
+        for callback in self.callbacks:
+            callback.on_epoch_end(self, self.get_model())
+
+    def on_train_start(self):
+        """Called when the train begins."""
+        for callback in self.callbacks:
+            callback.on_train_start(self, self.get_model())
+
+    def on_train_end(self):
+        """Called when the train ends."""
+        for callback in self.callbacks:
+            callback.on_train_end(self, self.get_model())
+
+    def on_batch_start(self):
+        """Called when the training batch begins."""
+        for callback in self.callbacks:
+            callback.on_batch_start(self, self.get_model())
+
+    def on_batch_end(self):
+        """Called when the training batch ends."""
+        for callback in self.callbacks:
+            callback.on_batch_end(self, self.get_model())
+
+    def on_validation_start(self):
+        """Called when the validation loop begins."""
+        for callback in self.callbacks:
+            callback.on_validation_start(self, self.get_model())
+
+    def on_validation_end(self):
+        """Called when the validation loop ends."""
+        for callback in self.callbacks:
+            callback.on_validation_end(self, self.get_model())
+
+    def on_test_start(self):
+        """Called when the test begins."""
+        for callback in self.callbacks:
+            callback.on_test_start(self, self.get_model())
+
+    def on_test_end(self):
+        """Called when the test ends."""
+        for callback in self.callbacks:
+            callback.on_test_end(self, self.get_model())
diff --git a/pytorch_lightning/trainer/data_loading.py b/pytorch_lightning/trainer/data_loading.py
index 43e8792..0dcd31b 100644
--- a/pytorch_lightning/trainer/data_loading.py
+++ b/pytorch_lightning/trainer/data_loading.py
@@ -1,77 +1,127 @@
-import warnings
-from abc import ABC
+from abc import ABC, abstractmethod
+from typing import Union, List, Tuple, Callable
 
 import torch.distributed as dist
-
-try:
-    # loading for pyTorch 1.3
-    from torch.utils.data import IterableDataset
-except ImportError:
-    # loading for pyTorch 1.1
-    import torch
-    warnings.warn('Your version of pyTorch %s does not support `IterableDataset`,'
-                  ' please upgrade to 1.2+' % torch.__version__, ImportWarning)
-    EXIST_ITER_DATASET = False
-else:
-    EXIST_ITER_DATASET = True
+from torch.utils.data import SequentialSampler, DataLoader
 from torch.utils.data.distributed import DistributedSampler
 
+from pytorch_lightning.core import LightningModule
 from pytorch_lightning.utilities.debugging import MisconfigurationException
 
 try:
     from apex import amp
-
-    APEX_AVAILABLE = True
 except ImportError:
     APEX_AVAILABLE = False
+else:
+    APEX_AVAILABLE = True
 
 try:
     import torch_xla
     import torch_xla.core.xla_model as xm
     import torch_xla.distributed.xla_multiprocessing as xmp
-
-    XLA_AVAILABLE = True
 except ImportError:
     XLA_AVAILABLE = False
+else:
+    XLA_AVAILABLE = True
+
+
+def _has_len(dataloader: DataLoader) -> bool:
+    try:
+        # try getting the length
+        _ = len(dataloader)
+        return True
+    except TypeError:
+        return False
 
 
 class TrainerDataLoadingMixin(ABC):
 
-    def __init__(self):
-        # this is just a summary on variables used in this abstract class,
-        #  the proper values/initialisation should be done in child class
-        self.proc_rank = None
-        self.use_ddp = None
-        self.use_ddp2 = None
-        self.shown_warnings = None
-        self.val_check_interval = None
-        self.use_tpu = None
-        self.tpu_local_core_rank = None
-
-    def _percent_range_check(self, name):
+    # this is just a summary on variables used in this abstract class,
+    #  the proper values/initialisation should be done in child class
+    proc_rank: int
+    use_ddp: bool
+    use_ddp2: bool
+    shown_warnings: ...
+    val_check_interval: float
+    use_tpu: bool
+    tpu_local_core_rank: int
+    train_dataloader: DataLoader
+    num_training_batches: Union[int, float]
+    val_check_batch: ...
+    val_dataloaders: List[DataLoader]
+    num_val_batches: Union[int, float]
+    test_dataloaders: List[DataLoader]
+    num_test_batches: Union[int, float]
+    train_percent_check: float
+    val_percent_check: float
+    test_percent_check: float
+
+    @abstractmethod
+    def is_overriden(self, *args):
+        """Warning: this is just empty shell for code implemented in other class."""
+
+    def _percent_range_check(self, name: str) -> None:
         value = getattr(self, name)
-        msg = f"`{name}` must lie in the range [0.0, 1.0], but got {value:.3f}."
-        if name == "val_check_interval":
-            msg += " If you want to disable validation set `val_percent_check` to 0.0 instead."
+        msg = f'`{name}` must lie in the range [0.0, 1.0], but got {value:.3f}.'
+        if name == 'val_check_interval':
+            msg += ' If you want to disable validation set `val_percent_check` to 0.0 instead.'
 
         if not 0. <= value <= 1.:
             raise ValueError(msg)
 
-    def init_train_dataloader(self, model):
-        """
-        Dataloaders are provided by the model
-        :param model:
-        :return:
+    def auto_add_sampler(self, dataloader: DataLoader, train: bool) -> DataLoader:
+        if self.use_ddp or self.use_ddp2 or self.use_tpu:
+            dl_args = {
+                'dataset': dataloader.dataset,
+                'batch_size': dataloader.batch_size,
+                'shuffle': False,
+                'num_workers': dataloader.num_workers,
+                'collate_fn': dataloader.collate_fn,
+                'pin_memory': dataloader.pin_memory,
+                'drop_last': dataloader.drop_last,
+                'timeout': dataloader.timeout,
+                'worker_init_fn': dataloader.worker_init_fn
+            }
+
+            if self.use_tpu:
+                sampler = DistributedSampler(
+                    dataloader.dataset,
+                    num_replicas=xm.xrt_world_size(),
+                    rank=xm.get_ordinal()
+                )
+                dl_args['shuffle'] = False
+            else:
+                if train:
+                    sampler = DistributedSampler(dataloader.dataset)
+                    dl_args['shuffle'] = False
+                else:
+                    sampler = SequentialSampler(dataloader.dataset)
+
+            dl_args['sampler'] = sampler
+
+            dataloader = DataLoader(**dl_args)
+        return dataloader
+
+    def reset_train_dataloader(self, model: LightningModule) -> None:
+        """Resets the train dataloader and initialises required variables
+        (number of batches, when to validate, etc.).
+
+        Args:
+            model: The current `LightningModule`
         """
-        self.get_train_dataloader = model.train_dataloader
+        self.train_dataloader = self.request_dataloader(model.train_dataloader)
+        self.num_training_batches = 0
+
+        # automatically add samplers
+        self.train_dataloader = self.auto_add_sampler(self.train_dataloader, train=True)
+
+        self._percent_range_check('train_percent_check')
 
-        # determine number of training batches
-        if EXIST_ITER_DATASET and isinstance(self.get_train_dataloader().dataset, IterableDataset):
+        if not _has_len(self.train_dataloader):
             self.num_training_batches = float('inf')
         else:
-            self._percent_range_check('train_percent_check')
-
-            self.num_training_batches = len(self.get_train_dataloader())
+            # try getting the length
+            self.num_training_batches = len(self.train_dataloader)
             self.num_training_batches = int(self.num_training_batches * self.train_percent_check)
 
         # determine when to check validation
@@ -81,183 +131,119 @@ class TrainerDataLoadingMixin(ABC):
             self.val_check_batch = self.val_check_interval
             if self.val_check_batch > self.num_training_batches:
                 raise ValueError(
-                    f"`val_check_interval` ({self.val_check_interval}) must be less than or equal "
-                    f"to the number of the training batches ({self.num_training_batches}). "
-                    f"If you want to disable validation set `val_percent_check` to 0.0 instead.")
+                    f'`val_check_interval` ({self.val_check_interval}) must be less than or equal '
+                    f'to the number of the training batches ({self.num_training_batches}). '
+                    'If you want to disable validation set `val_percent_check` to 0.0 instead.')
         else:
+            if not _has_len(self.train_dataloader):
+                raise MisconfigurationException(
+                    'When using an infinite DataLoader (e.g. with an IterableDataset or when '
+                    'DataLoader does not implement `__len__`) for `train_dataloader`, '
+                    '`Trainer(val_check_interval)` must be an int. An int k specifies checking '
+                    'validation every k training batches.')
+
             self._percent_range_check('val_check_interval')
 
             self.val_check_batch = int(self.num_training_batches * self.val_check_interval)
             self.val_check_batch = max(1, self.val_check_batch)
 
-        on_ddp = self.use_ddp or self.use_ddp2
-        needs_sampler = on_ddp or self.use_tpu
-        if needs_sampler and not isinstance(self.get_train_dataloader().sampler, DistributedSampler):
-            msg = """
-            You're using multiple gpus and multiple nodes, or TPUs without using a
-            to assign a subset of your data to each process. To silence this warning, pass a
-            DistributedSampler to your DataLoader.
-
-            ie: this:
-            dataset = myDataset()
-            dataloader = Dataloader(dataset)
-
-            becomes:
-            dataset = myDataset()
-            dist_sampler = torch.utils.data.distributed.DistributedSampler(dataset)
-            dataloader = Dataloader(dataset, sampler=dist_sampler)
-
-            If you want each process to load the full dataset, ignore this warning.
-            """
-            if msg not in self.shown_warnings and self.proc_rank == 0:
-                self.shown_warnings.add(msg)
-                warnings.warn(msg)
-
-    def init_val_dataloader(self, model):
-        """
-        Dataloaders are provided by the model
-        :param model:
-        :return:
-        """
-        self.get_val_dataloaders = model.val_dataloader
-        self.num_val_batches = 0
-
-        # determine number of validation batches
-        # val datasets could be none, 1 or 2+
-        if self.get_val_dataloaders() is not None:
-            self._percent_range_check('val_percent_check')
-
-            self.num_val_batches = sum(len(dataloader) for dataloader in self.get_val_dataloaders())
-            self.num_val_batches = int(self.num_val_batches * self.val_percent_check)
-
-        on_ddp = self.use_ddp or self.use_ddp2
-        needs_sampler = on_ddp or self.use_tpu
-        if needs_sampler and self.get_val_dataloaders() is not None:
-            for dataloader in self.get_val_dataloaders():
-                if not isinstance(dataloader.sampler, DistributedSampler):
-                    msg = """
-                    Your val_dataloader(s) don't use DistributedSampler.
-
-                    You're using multiple gpus and multiple nodes, or TPUs without using a
-                    DistributedSampler to assign a subset of your data to each process.
-                    To silence this warning, pass a DistributedSampler to your DataLoader.
-
-                    ie: this:
-                    dataset = myDataset()
-                    dataloader = Dataloader(dataset)
-
-                    becomes:
-                    dataset = myDataset()
-                    dist_sampler = torch.utils.data.distributed.DistributedSampler(dataset)
-                    dataloader = Dataloader(dataset, sampler=dist_sampler)
-
-                    If you want each process to load the full dataset, ignore this warning.
-                    """
-                    if msg not in self.shown_warnings and self.proc_rank == 0:
-                        self.shown_warnings.add(msg)
-                        warnings.warn(msg)
-                    break
+    def _reset_eval_dataloader(self, model: LightningModule,
+                               mode: str) -> Tuple[int, List[DataLoader]]:
+        """Generic method to reset a dataloader for evaluation.
 
-    def init_test_dataloader(self, model):
-        """Dataloaders are provided by the model.
+        Args:
+            model: The current `LightningModule`
+            mode: Either `'val'` or `'test'`
 
-        :param model:
+        Returns:
+            Tuple (num_batches, dataloaders)
         """
+        dataloaders = self.request_dataloader(getattr(model, f'{mode}_dataloader'))
 
-        self.get_test_dataloaders = model.test_dataloader
+        if not isinstance(dataloaders, list):
+            dataloaders = [dataloaders]
 
-        # determine number of test batches
-        if self.get_test_dataloaders() is not None:
-            self._percent_range_check('test_percent_check')
+        # add samplers
+        dataloaders = [self.auto_add_sampler(dl, train=False) for dl in dataloaders if dl]
 
-            len_sum = sum(len(dataloader) for dataloader in self.get_test_dataloaders())
-            self.num_test_batches = len_sum
-            self.num_test_batches = int(self.num_test_batches * self.test_percent_check)
+        num_batches = 0
 
-        on_ddp = self.use_ddp or self.use_ddp2
-        needs_sampler = on_ddp or self.use_tpu
-        if needs_sampler and self.get_test_dataloaders() is not None:
-            for dataloader in self.get_test_dataloaders():
-                if not isinstance(dataloader.sampler, DistributedSampler):
-                    msg = """
-                    Your `test_dataloader(s)` don't use DistributedSampler.
+        # determine number of batches
+        # datasets could be none, 1 or 2+
+        if len(dataloaders) != 0:
+            for dataloader in dataloaders:
+                if not _has_len(dataloader):
+                    num_batches = float('inf')
+                    break
 
-                    You're using multiple gpus and multiple nodes, or TPUs without using a
-                    DistributedSampler to assign a subset of your data to each process.
-                    To silence this warning, pass a DistributedSampler to your DataLoader.
+            percent_check = getattr(self, f'{mode}_percent_check')
 
-                    ie: this::
+            if num_batches != float('inf'):
+                self._percent_range_check(f'{mode}_percent_check')
 
-                        dataset = myDataset()
-                        dataloader = Dataloader(dataset)
+                num_batches = sum(len(dataloader) for dataloader in dataloaders)
+                num_batches = int(num_batches * percent_check)
+            elif percent_check not in (0.0, 1.0):
+                raise MisconfigurationException(
+                    'When using an infinite DataLoader (e.g. with an IterableDataset or when '
+                    f'DataLoader does not implement `__len__`) for `{mode}_dataloader`, '
+                    f'`Trainer({mode}_percent_check)` must be `0.0` or `1.0`.')
+        return num_batches, dataloaders
 
-                    becomes::
+    def reset_val_dataloader(self, model: LightningModule) -> None:
+        """Resets the validation dataloader and determines the number of batches.
 
-                        dataset = myDataset()
-                        dist_sampler = torch.utils.data.distributed.DistributedSampler(dataset)
-                        dataloader = Dataloader(dataset, sampler=dist_sampler)
+        Args:
+            model: The current `LightningModule`
+        """
+        if self.is_overriden('validation_step'):
+            self.num_val_batches, self.val_dataloaders =\
+                self._reset_eval_dataloader(model, 'val')
 
-                    If you want each process to load the full dataset, ignore this warning.
-                    """
-                    if msg not in self.shown_warnings and self.proc_rank == 0:
-                        self.shown_warnings.add(msg)
-                        warnings.warn(msg)
-                    break
+    def reset_test_dataloader(self, model) -> None:
+        """Resets the validation dataloader and determines the number of batches.
 
-    def get_dataloaders(self, model):
-        """
-        Dataloaders are provided by the model
-        :param model:
-        :return:
+        Args:
+            model: The current `LightningModule`
         """
+        if self.is_overriden('test_step'):
+            self.num_test_batches, self.test_dataloaders =\
+                self._reset_eval_dataloader(model, 'test')
+
+    def request_dataloader(self, dataloader_fx: Callable) -> DataLoader:
+        """Handles downloading data in the GPU or TPU case.
 
-        self.init_train_dataloader(model)
-        self.init_test_dataloader(model)
-        self.init_val_dataloader(model)
+        Args:
+            dataloader_fx: The bound dataloader getter
+
+        Returns:
+            The dataloader
+        """
+        dataloader = dataloader_fx()
 
+        # get the function we'll use to get data
         if self.use_ddp or self.use_ddp2:
-            # wait for all processes to catch up
+            # all processes wait until data download has happened
             dist.barrier()
 
-            # load each dataloader
-            self.get_train_dataloader()
-            self.get_test_dataloaders()
-            self.get_val_dataloaders()
-
-        # on TPUs load each dataloader only on process 0
-        # this will trigger the data downloads
-        if self.use_tpu and XLA_AVAILABLE:
-            if self.tpu_local_core_rank == 0:
-                self.get_train_dataloader()
-                self.get_test_dataloaders()
-                self.get_val_dataloaders()
-
-            # wait for all processes to catch up
-            torch_xla.core.xla_model.rendezvous("pl.TrainerDataLoadingMixin.get_dataloaders")
-
-        # support IterableDataset for train data
-        self.is_iterable_train_dataloader = (
-            EXIST_ITER_DATASET and isinstance(self.get_train_dataloader().dataset, IterableDataset))
-        if self.is_iterable_train_dataloader and not isinstance(self.val_check_interval, int):
-            m = '''
-            When using an iterableDataset for `train_dataloader`,
-            `Trainer(val_check_interval)` must be an int.
-            An int k specifies checking validation every k training batches
-            '''
-            raise MisconfigurationException(m)
-
-    def determine_data_use_amount(self, train_percent_check, val_percent_check,
-                                  test_percent_check, overfit_pct):
-        """
-        Use less data for debugging purposes
+        # data download/load on TPU
+        elif self.use_tpu and XLA_AVAILABLE:
+            # all processes wait until data download has happened
+            torch_xla.core.xla_model.rendezvous('pl.TrainerDataLoadingMixin.get_dataloaders')
+
+        return dataloader
+
+    def determine_data_use_amount(self, train_percent_check: float, val_percent_check: float,
+                                  test_percent_check: float, overfit_pct: float) -> None:
+        """Use less data for debugging purposes
         """
         self.train_percent_check = train_percent_check
         self.val_percent_check = val_percent_check
         self.test_percent_check = test_percent_check
         if overfit_pct > 0:
             if overfit_pct > 1:
-                raise ValueError(f"`overfit_pct` must be not greater than 1.0, but got "
-                                 f"{overfit_pct:.3f}.")
+                raise ValueError(
+                    f'`overfit_pct` must be not greater than 1.0, but got {overfit_pct:.3f}.')
 
             self.train_percent_check = overfit_pct
             self.val_percent_check = overfit_pct
diff --git a/pytorch_lightning/trainer/deprecated_api.py b/pytorch_lightning/trainer/deprecated_api.py
new file mode 100644
index 0000000..8c4ca86
--- /dev/null
+++ b/pytorch_lightning/trainer/deprecated_api.py
@@ -0,0 +1,89 @@
+"""Mirroring deprecated API"""
+
+import warnings
+from abc import ABC
+
+
+class TrainerDeprecatedAPITillVer0_8(ABC):
+
+    def __init__(self):
+        super().__init__()  # mixin calls super too
+
+    @property
+    def nb_gpu_nodes(self):
+        """Back compatibility, will be removed in v0.8.0"""
+        warnings.warn("Attribute `nb_gpu_nodes` has renamed to `num_nodes` since v0.5.0"
+                      " and this method will be removed in v0.8.0", DeprecationWarning)
+        return self.num_nodes
+
+    @property
+    def num_gpu_nodes(self):
+        """Back compatibility, will be removed in v0.8.0"""
+        warnings.warn("Attribute `num_gpu_nodes` has renamed to `num_nodes` since v0.5.0"
+                      " and this method will be removed in v0.8.0", DeprecationWarning)
+        return self.num_nodes
+
+    @num_gpu_nodes.setter
+    def num_gpu_nodes(self, num_nodes):
+        """Back compatibility, will be removed in v0.8.0"""
+        warnings.warn("Attribute `num_gpu_nodes` has renamed to `num_nodes` since v0.5.0"
+                      " and this method will be removed in v0.8.0", DeprecationWarning)
+        self.num_nodes = num_nodes
+
+    @property
+    def gradient_clip(self):
+        """Back compatibility, will be removed in v0.8.0"""
+        warnings.warn("Attribute `gradient_clip` has renamed to `gradient_clip_val` since v0.5.0"
+                      " and this method will be removed in v0.8.0", DeprecationWarning)
+        return self.gradient_clip_val
+
+    @gradient_clip.setter
+    def gradient_clip(self, gradient_clip):
+        """Back compatibility, will be removed in v0.8.0"""
+        warnings.warn("Attribute `gradient_clip` has renamed to `gradient_clip_val` since v0.5.0"
+                      " and this method will be removed in v0.8.0", DeprecationWarning)
+        self.gradient_clip_val = gradient_clip
+
+    @property
+    def max_nb_epochs(self):
+        """Back compatibility, will be removed in v0.8.0"""
+        warnings.warn("Attribute `max_nb_epochs` has renamed to `max_epochs` since v0.5.0"
+                      " and this method will be removed in v0.8.0", DeprecationWarning)
+        return self.max_epochs
+
+    @max_nb_epochs.setter
+    def max_nb_epochs(self, max_epochs):
+        """Back compatibility, will be removed in v0.8.0"""
+        warnings.warn("Attribute `max_nb_epochs` has renamed to `max_epochs` since v0.5.0"
+                      " and this method will be removed in v0.8.0", DeprecationWarning)
+        self.max_epochs = max_epochs
+
+    @property
+    def min_nb_epochs(self):
+        """Back compatibility, will be removed in v0.8.0"""
+        warnings.warn("Attribute `min_nb_epochs` has renamed to `min_epochs` since v0.5.0"
+                      " and this method will be removed in v0.8.0", DeprecationWarning)
+        return self.min_epochs
+
+    @min_nb_epochs.setter
+    def min_nb_epochs(self, min_epochs):
+        """Back compatibility, will be removed in v0.8.0"""
+        warnings.warn("Attribute `min_nb_epochs` has renamed to `min_epochs` since v0.5.0"
+                      " and this method will be removed in v0.8.0", DeprecationWarning)
+        self.min_epochs = min_epochs
+
+    @property
+    def nb_sanity_val_steps(self):
+        """Back compatibility, will be removed in v0.8.0"""
+        warnings.warn("Attribute `nb_sanity_val_steps` has renamed to "
+                      "`num_sanity_val_steps` since v0.5.0"
+                      " and this method will be removed in v0.8.0", DeprecationWarning)
+        return self.num_sanity_val_steps
+
+    @nb_sanity_val_steps.setter
+    def nb_sanity_val_steps(self, nb):
+        """Back compatibility, will be removed in v0.8.0"""
+        warnings.warn("Attribute `nb_sanity_val_steps` has renamed to "
+                      "`num_sanity_val_steps` since v0.5.0"
+                      " and this method will be removed in v0.8.0", DeprecationWarning)
+        self.num_sanity_val_steps = nb
diff --git a/pytorch_lightning/trainer/distrib_data_parallel.py b/pytorch_lightning/trainer/distrib_data_parallel.py
index 01bcdb1..7da8906 100644
--- a/pytorch_lightning/trainer/distrib_data_parallel.py
+++ b/pytorch_lightning/trainer/distrib_data_parallel.py
@@ -118,48 +118,51 @@ import os
 import re
 import warnings
 from abc import ABC, abstractmethod
+from typing import Union
 
 import torch
 
+from pytorch_lightning.loggers import LightningLoggerBase
 from pytorch_lightning.utilities.debugging import MisconfigurationException
 
 try:
     from apex import amp
-
-    APEX_AVAILABLE = True
 except ImportError:
     APEX_AVAILABLE = False
+else:
+    APEX_AVAILABLE = True
 
 
 class TrainerDDPMixin(ABC):
 
-    def __init__(self):
-        # this is just a summary on variables used in this abstract class,
-        #  the proper values/initialisation should be done in child class
-        self.num_gpus = None
-        self.on_gpu = None
-        self.num_gpu_nodes = None
-        self.logger = None
-        self.data_parallel_device_ids = None
-        self.distributed_backend = None
-        self.use_amp = None
-        self.amp_level = None
-        self.use_tpu = None
+    # this is just a summary on variables used in this abstract class,
+    #  the proper values/initialisation should be done in child class
+    on_gpu: bool
+    num_gpu_nodes: int
+    logger: Union[LightningLoggerBase, bool]
+    data_parallel_device_ids: ...
+    distributed_backend: str
+    use_amp: bool
+    amp_level: str
+    use_tpu: bool
+    default_save_path: str
+
+    @property
+    @abstractmethod
+    def num_gpus(self) -> int:
+        """Warning: this is just empty shell for code implemented in other class."""
 
     @abstractmethod
-    def copy_trainer_model_properties(self, model):
-        # this is just empty shell for code from other class
-        pass
+    def copy_trainer_model_properties(self, *args):
+        """Warning: this is just empty shell for code implemented in other class."""
 
     @abstractmethod
-    def run_pretrain_routine(self, model):
-        # this is just empty shell for code from other class
-        pass
+    def run_pretrain_routine(self, *args):
+        """Warning: this is just empty shell for code implemented in other class."""
 
     @abstractmethod
-    def init_optimizers(self, optimizers):
-        # this is just empty shell for code from other class
-        pass
+    def init_optimizers(self, *args):
+        """Warning: this is just empty shell for code implemented in other class."""
 
     def init_tpu(self):
         # turn off all the GPU stuff
@@ -338,6 +341,38 @@ class TrainerDDPMixin(ABC):
         # continue training routine
         self.run_pretrain_routine(model)
 
+        # when ddp ends, we save the model
+        self.save_spawn_weights(model)
+
+    def save_spawn_weights(self, model):
+        """
+        Dump a temporary checkpoint after ddp ends to get weights out of the process
+        :param model:
+        :return:
+        """
+        if self.proc_rank == 0:
+            path = os.path.join(self.default_save_path, '__temp_weight_ddp_end.ckpt')
+            self.save_checkpoint(path)
+
+    def load_spawn_weights(self, original_model):
+        """
+        Load the temp weights saved in the process
+        To recover the trained model from the ddp process we load the saved weights
+        :param model:
+        :return:
+        """
+        # load weights saved in ddp
+        path = os.path.join(self.default_save_path, '__temp_weight_ddp_end.ckpt')
+        loaded_model = original_model.__class__.load_from_checkpoint(path)
+
+        # copy loaded weights to old model
+        original_model.load_state_dict(loaded_model.state_dict())
+
+        # remove ddp weights
+        os.remove(path)
+
+        return loaded_model
+
     def resolve_root_node_address(self, root_node):
         if '[' in root_node:
             name = root_node.split('[')[0]
diff --git a/pytorch_lightning/trainer/distrib_parts.py b/pytorch_lightning/trainer/distrib_parts.py
index 29bc817..972c047 100644
--- a/pytorch_lightning/trainer/distrib_parts.py
+++ b/pytorch_lightning/trainer/distrib_parts.py
@@ -269,14 +269,14 @@ Auto-slurm-job-submission
 -------------------------
 
 Instead of manually building SLURM scripts, you can use the
- `SlurmCluster object <https://williamfalcon.github.io/test-tube/hpc/SlurmCluster>`_
- to do this for you. The SlurmCluster can also run a grid search if you pass
- in a `HyperOptArgumentParser
-  <https://williamfalcon.github.io/test-tube/hyperparameter_optimization/HyperOptArgumentParser>`_.
+`SlurmCluster object <https://williamfalcon.github.io/test-tube/hpc/SlurmCluster>`_
+to do this for you. The SlurmCluster can also run a grid search if you pass
+in a `HyperOptArgumentParser
+<https://williamfalcon.github.io/test-tube/hyperparameter_optimization/HyperOptArgumentParser>`_.
 
 Here is an example where you run a grid search of 9 combinations of hyperparams.
- The full examples are `here
- <https://github.com/PyTorchLightning/pytorch-lightning/tree/master/pl_examples/new_project_templates/multi_node_examples>`_.
+The full examples are
+`here <https://git.io/Jv87p>`_.
 
 .. code-block:: python
 
@@ -334,9 +334,9 @@ Here lightning distributes parts of your module across available GPUs to optimiz
 
 """
 
-from abc import ABC, abstractmethod
 import logging as log
 import os
+from abc import ABC, abstractmethod
 
 import torch
 
@@ -348,49 +348,47 @@ from pytorch_lightning.utilities.debugging import MisconfigurationException
 
 try:
     from apex import amp
-
-    APEX_AVAILABLE = True
 except ImportError:
     APEX_AVAILABLE = False
+else:
+    APEX_AVAILABLE = True
 
 try:
     import torch_xla.core.xla_model as xm
-    XLA_AVAILABLE = True
-
 except ImportError:
     XLA_AVAILABLE = False
+else:
+    XLA_AVAILABLE = True
 
 
 class TrainerDPMixin(ABC):
 
-    def __init__(self):
-        # this is just a summary on variables used in this abstract class,
-        #  the proper values/initialisation should be done in child class
-        self.on_gpu = None
-        self.use_dp = None
-        self.use_ddp2 = None
-        self.use_ddp = None
-        self.use_amp = None
-        self.testing = None
-        self.single_gpu = None
-        self.root_gpu = None
-        self.amp_level = None
-        self.precision = None
-        self.current_tpu_idx = None
-        self.proc_rank = None
-        self.tpu_local_core_rank = None
-        self.tpu_global_core_rank = None
-        self.use_tpu = None
+    # this is just a summary on variables used in this abstract class,
+    #  the proper values/initialisation should be done in child class
+    on_gpu: bool
+    use_dp: bool
+    use_ddp2: bool
+    use_ddp: bool
+    use_amp: bool
+    testing: bool
+    single_gpu: bool
+    root_gpu: ...
+    amp_level: str
+    precision: ...
+    current_tpu_idx: ...
+    proc_rank: int
+    tpu_local_core_rank: int
+    tpu_global_core_rank: int
+    use_tpu: bool
+    data_parallel_device_ids: ...
 
     @abstractmethod
-    def run_pretrain_routine(self, model):
-        # this is just empty shell for code from other class
-        pass
+    def run_pretrain_routine(self, *args):
+        """Warning: this is just empty shell for code implemented in other class."""
 
     @abstractmethod
-    def init_optimizers(self, optimizers):
-        # this is just empty shell for code from other class
-        pass
+    def init_optimizers(self, *args):
+        """Warning: this is just empty shell for code implemented in other class."""
 
     def copy_trainer_model_properties(self, model):
         if isinstance(model, LightningDataParallel):
@@ -491,13 +489,17 @@ class TrainerDPMixin(ABC):
 
         # init 16 bit for TPU
         if self.precision == 16:
-            os.environ['XLA_USE_BF16'] = 1
+            os.environ['XLA_USE_BF16'] = str(1)
 
         m = f'INIT TPU local core: {self.tpu_local_core_rank}, ' \
             f'global rank: {self.tpu_global_core_rank}'
         log.info(m)
+
+        # continue training routine
         self.run_pretrain_routine(model)
 
+        self.save_spawn_weights(model)
+
     def dp_train(self, model):
 
         # CHOOSE OPTIMIZER
@@ -509,7 +511,7 @@ class TrainerDPMixin(ABC):
         # check for this bug (amp + dp + !01 doesn't work)
         # https://github.com/NVIDIA/apex/issues/227
         if self.use_dp and self.use_amp:
-            if self.amp_level == 'O2':
+            if self.amp_level == 'O2':  # pragma: no cover
                 m = f"""
                 Amp level {self.amp_level} with DataParallel is not supported.
                 See this note from NVIDIA for more info: https://github.com/NVIDIA/apex/issues/227.
diff --git a/pytorch_lightning/trainer/evaluation_loop.py b/pytorch_lightning/trainer/evaluation_loop.py
index f5d2b93..0bc46b9 100644
--- a/pytorch_lightning/trainer/evaluation_loop.py
+++ b/pytorch_lightning/trainer/evaluation_loop.py
@@ -125,92 +125,103 @@ In this second case, the options you pass to trainer will be used when running
 
 import sys
 from abc import ABC, abstractmethod
+from typing import Callable
 
 import torch
+from torch.utils.data import DataLoader
 from tqdm.auto import tqdm
+import warnings
 
+from pytorch_lightning.core.lightning import LightningModule
 from pytorch_lightning.utilities.debugging import MisconfigurationException
 
 try:
     import torch_xla.distributed.parallel_loader as xla_pl
     import torch_xla.core.xla_model as xm
-
-    XLA_AVAILABLE = True
 except ImportError:
     XLA_AVAILABLE = False
+else:
+    XLA_AVAILABLE = True
 
 
 class TrainerEvaluationLoopMixin(ABC):
 
-    def __init__(self):
-        # this is just a summary on variables used in this abstract class,
-        #  the proper values/initialisation should be done in child class
-        self.test_progress_bar = None
-        self.val_progress_bar = None
-        self.main_progress_bar = None
-        self.use_ddp = None
-        self.use_dp = None
-        self.use_ddp2 = None
-        self.single_gpu = None
-        self.data_parallel_device_ids = None
-        self.model = None
-        self.num_test_batches = None
-        self.num_val_batches = None
-        self.fast_dev_run = None
-        self.process_position = None
-        self.show_progress_bar = None
-        self.process_output = None
-        self.training_tqdm_dict = None
-        self.proc_rank = None
-        self.checkpoint_callback = None
-        self.current_epoch = None
-        self.callback_metrics = None
-        self.get_test_dataloaders = None
-        self.get_val_dataloaders = None
-        self.use_tpu = None
+    # this is just a summary on variables used in this abstract class,
+    #  the proper values/initialisation should be done in child class
+    test_progress_bar: ...
+    val_progress_bar: ...
+    main_progress_bar: ...
+    use_ddp: bool
+    use_dp: bool
+    use_ddp2: bool
+    single_gpu: bool
+    data_parallel_device_ids: ...
+    model: LightningModule
+    num_test_batches: int
+    num_val_batches: int
+    fast_dev_run: ...
+    process_position: ...
+    show_progress_bar: ...
+    process_output: ...
+    training_tqdm_dict: ...
+    proc_rank: int
+    current_epoch: int
+    callback_metrics: ...
+    test_dataloaders: DataLoader
+    val_dataloaders: DataLoader
+    use_tpu: bool
+    reload_dataloaders_every_epoch: ...
+    progress_bar_refresh_rate: ...
+
+    # Callback system
+    on_validation_start: Callable
+    on_validation_end: Callable
+    on_test_start: Callable
+    on_test_end: Callable
 
     @abstractmethod
-    def copy_trainer_model_properties(self, model):
-        # this is just empty shell for code from other class
-        pass
+    def copy_trainer_model_properties(self, *args):
+        """Warning: this is just empty shell for code implemented in other class."""
 
     @abstractmethod
     def get_model(self):
-        # this is just empty shell for code from other class
-        pass
+        """Warning: this is just empty shell for code implemented in other class."""
+
+    @abstractmethod
+    def is_overriden(self, *args):
+        """Warning: this is just empty shell for code implemented in other class."""
 
     @abstractmethod
-    def is_overriden(self, m):
-        # this is just empty shell for code from other class
-        pass
+    def transfer_batch_to_tpu(self, *args):
+        """Warning: this is just empty shell for code implemented in other class."""
 
     @abstractmethod
-    def transfer_batch_to_tpu(self, batch):
-        # this is just empty shell for code from other class
-        pass
+    def transfer_batch_to_gpu(self, *args):
+        """Warning: this is just empty shell for code implemented in other class."""
 
     @abstractmethod
-    def transfer_batch_to_gpu(self, batch, gpu):
-        # this is just empty shell for code from other class
-        pass
+    def add_tqdm_metrics(self, *args):
+        """Warning: this is just empty shell for code implemented in other class."""
 
     @abstractmethod
-    def add_tqdm_metrics(self, metrics):
-        # this is just empty shell for code from other class
-        pass
+    def log_metrics(self, *args):
+        """Warning: this is just empty shell for code implemented in other class."""
 
     @abstractmethod
-    def log_metrics(self, metrics, grad_norm_dic):
-        # this is just empty shell for code from other class
-        pass
+    def reset_test_dataloader(self, *args):
+        """Warning: this is just empty shell for code implemented in other class."""
 
-    def evaluate(self, model, dataloaders, max_batches, test=False):
+    @abstractmethod
+    def reset_val_dataloader(self, *args):
+        """Warning: this is just empty shell for code implemented in other class."""
+
+    def evaluate(self, model, dataloaders, max_batches, test_mode: bool = False):
         """Run evaluation code.
 
         :param model: PT model
         :param dataloaders: list of PT dataloaders
         :param max_batches: Scalar
-        :param test: boolean
+        :param test_mode
         :return:
         """
         # enable eval mode
@@ -237,7 +248,6 @@ class TrainerEvaluationLoopMixin(ABC):
                 dataloader = dataloader.per_device_loader(device)
 
             for batch_idx, batch in enumerate(dataloader):
-
                 if batch is None:  # pragma: no cover
                     continue
 
@@ -248,21 +258,30 @@ class TrainerEvaluationLoopMixin(ABC):
                 # -----------------
                 # RUN EVALUATION STEP
                 # -----------------
-                output = self.evaluation_forward(model,
-                                                 batch,
-                                                 batch_idx,
-                                                 dataloader_idx,
-                                                 test)
+                output = self.evaluation_forward(model, batch, batch_idx, dataloader_idx, test_mode)
+
+                # on dp / ddp2 might still want to do something with the batch parts
+                if test_mode:
+                    if self.is_overriden('test_step_end'):
+                        model_ref = self.get_model()
+                        with self.profiler.profile('test_step_end'):
+                            output = model_ref.test_step_end(output)
+                else:
+                    if self.is_overriden('validation_step_end'):
+                        model_ref = self.get_model()
+                        with self.profiler.profile('validation_step_end'):
+                            output = model_ref.validation_step_end(output)
 
                 # track outputs for collation
                 dl_outputs.append(output)
 
                 # batch done
-                if test:
-                    self.test_progress_bar.update(1)
-                else:
-                    self.val_progress_bar.update(1)
-                    self.main_progress_bar.update(1)
+                if batch_idx % self.progress_bar_refresh_rate == 0:
+                    if test_mode:
+                        self.test_progress_bar.update(self.progress_bar_refresh_rate)
+                    else:
+                        self.val_progress_bar.update(self.progress_bar_refresh_rate)
+                        self.main_progress_bar.update(self.progress_bar_refresh_rate)
             outputs.append(dl_outputs)
 
         eval_results = {}
@@ -273,10 +292,23 @@ class TrainerEvaluationLoopMixin(ABC):
 
         # give model a chance to do something with the outputs (and method defined)
         model = self.get_model()
-        if test and self.is_overriden('test_end'):
+
+        if test_mode and self.is_overriden('test_epoch_end'):
+            eval_results = model.test_epoch_end(outputs)
+        elif self.is_overriden('validation_epoch_end'):
+            eval_results = model.validation_epoch_end(outputs)
+
+        # TODO: remove in v 1.0.0
+        if test_mode and self.is_overriden('test_end'):
             eval_results = model.test_end(outputs)
+            m = 'test_end was deprecated in 0.7.0 and will be removed 1.0.0. ' \
+                'Use test_epoch_end instead.'
+            warnings.warn(m, DeprecationWarning)
         elif self.is_overriden('validation_end'):
             eval_results = model.validation_end(outputs)
+            m = 'validation_end was deprecated in 0.7.0 and will be removed 1.0.0. ' \
+                'Use validation_epoch_end instead.'
+            warnings.warn(m, DeprecationWarning)
 
         # enable train mode again
         model.train()
@@ -286,24 +318,36 @@ class TrainerEvaluationLoopMixin(ABC):
 
         return eval_results
 
-    def run_evaluation(self, test=False):
+    def run_evaluation(self, test_mode: bool = False):
         # when testing make sure user defined a test step
-        if test and not (self.is_overriden('test_step') and self.is_overriden('test_end')):
-            m = '''You called `.test()` without defining model's `.test_step()` or `.test_end()`.
-                    Please define and try again'''
+        if test_mode and not self.is_overriden('test_step'):
+            m = "You called `.test()` without defining model's `.test_step()`." \
+                " Please define and try again"
             raise MisconfigurationException(m)
 
+        # Validation/Test begin callbacks
+        if test_mode:
+            self.on_test_start()
+        else:
+            self.on_validation_start()
+
         # hook
         model = self.get_model()
         model.on_pre_performance_check()
 
         # select dataloaders
-        if test:
-            dataloaders = self.get_test_dataloaders()
+        if test_mode:
+            if self.reload_dataloaders_every_epoch or self.test_dataloaders is None:
+                self.reset_test_dataloader(model)
+
+            dataloaders = self.test_dataloaders
             max_batches = self.num_test_batches
         else:
             # val
-            dataloaders = self.get_val_dataloaders()
+            if self.reload_dataloaders_every_epoch or self.val_dataloaders is None:
+                self.reset_val_dataloader(model)
+
+            dataloaders = self.val_dataloaders
             max_batches = self.num_val_batches
 
         # cap max batches to 1 when using fast_dev_run
@@ -312,24 +356,29 @@ class TrainerEvaluationLoopMixin(ABC):
 
         # init validation or test progress bar
         # main progress bar will already be closed when testing so initial position is free
-        position = 2 * self.process_position + (not test)
-        desc = 'Testing' if test else 'Validating'
-        pbar = tqdm(desc=desc, total=max_batches, leave=test, position=position,
-                    disable=not self.show_progress_bar, dynamic_ncols=True,
-                    file=sys.stdout)
-        setattr(self, f'{"test" if test else "val"}_progress_bar', pbar)
+        position = 2 * self.process_position + (not test_mode)
+        desc = 'Testing' if test_mode else 'Validating'
+        total = max_batches if max_batches != float('inf') else None
+        pbar = tqdm(desc=desc, total=total, leave=test_mode, position=position,
+                    disable=not self.show_progress_bar, dynamic_ncols=True, file=sys.stdout)
+        setattr(self, f'{"test" if test_mode else "val"}_progress_bar', pbar)
 
         # run evaluation
-        eval_results = self.evaluate(self.model,
-                                     dataloaders,
-                                     max_batches,
-                                     test)
+        eval_results = self.evaluate(self.model, dataloaders, max_batches, test_mode)
         _, prog_bar_metrics, log_metrics, callback_metrics, _ = self.process_output(
             eval_results)
 
         # add metrics to prog bar
         self.add_tqdm_metrics(prog_bar_metrics)
 
+        # log results of test
+        if test_mode:
+            if self.proc_rank == 0:
+                print('-' * 100)
+                print('TEST RESULTS')
+                print(prog_bar_metrics)
+                print('-' * 100)
+
         # log metrics
         self.log_metrics(log_metrics, {})
 
@@ -340,27 +389,27 @@ class TrainerEvaluationLoopMixin(ABC):
         model.on_post_performance_check()
 
         # add model specific metrics
-        if not test:
+        if not test_mode:
             self.main_progress_bar.set_postfix(**self.training_tqdm_dict)
 
         # close progress bar
-        if test:
+        if test_mode:
             self.test_progress_bar.close()
         else:
             self.val_progress_bar.close()
 
-        # model checkpointing
-        if self.proc_rank == 0 and self.checkpoint_callback is not None and not test:
-            self.checkpoint_callback.on_validation_end()
+        # Validation/Test end callbacks
+        if test_mode:
+            self.on_test_end()
 
-    def evaluation_forward(self, model, batch, batch_idx, dataloader_idx, test=False):
+    def evaluation_forward(self, model, batch, batch_idx, dataloader_idx, test_mode: bool = False):
         # make dataloader_idx arg in validation_step optional
         args = [batch, batch_idx]
 
-        if test and len(self.get_test_dataloaders()) > 1:
+        if test_mode and len(self.test_dataloaders) > 1:
             args.append(dataloader_idx)
 
-        elif not test and len(self.get_val_dataloaders()) > 1:
+        elif not test_mode and len(self.val_dataloaders) > 1:
             args.append(dataloader_idx)
 
         # handle DP, DDP forward
@@ -368,7 +417,7 @@ class TrainerEvaluationLoopMixin(ABC):
             output = model(*args)
             return output
 
-        # single GPU
+        # single GPU data transfer
         if self.single_gpu:
             # for single GPU put inputs on gpu manually
             root_gpu = 0
@@ -377,13 +426,13 @@ class TrainerEvaluationLoopMixin(ABC):
             batch = self.transfer_batch_to_gpu(batch, root_gpu)
             args[0] = batch
 
-        # TPU
+        # TPU data  transfer
         if self.use_tpu:
             batch = self.transfer_batch_to_tpu(batch)
             args[0] = batch
 
-        # CPU
-        if test:
+        # CPU, TPU or gpu step
+        if test_mode:
             output = model.test_step(*args)
         else:
             output = model.validation_step(*args)
diff --git a/pytorch_lightning/trainer/logging.py b/pytorch_lightning/trainer/logging.py
index 34b1c11..313eed5 100644
--- a/pytorch_lightning/trainer/logging.py
+++ b/pytorch_lightning/trainer/logging.py
@@ -1,26 +1,28 @@
 from abc import ABC
+from typing import Union, Iterable
 
 import torch
 
 from pytorch_lightning.core import memory
-from pytorch_lightning.loggers import TensorBoardLogger
+from pytorch_lightning.loggers import TensorBoardLogger, LightningLoggerBase, LoggerCollection
 
 
 class TrainerLoggingMixin(ABC):
 
-    def __init__(self):
-        # this is just a summary on variables used in this abstract class,
-        #  the proper values/initialisation should be done in child class
-        self.current_epoch = None
-        self.on_gpu = None
-        self.log_gpu_memory = None
-        self.logger = None
-        self.tqdm_metrics = None
-        self.global_step = None
-        self.proc_rank = None
-        self.use_dp = None
-        self.use_ddp2 = None
-        self.num_gpus = None
+    # this is just a summary on variables used in this abstract class,
+    #  the proper values/initialisation should be done in child class
+    current_epoch: int
+    on_gpu: bool
+    log_gpu_memory: ...
+    logger: Union[LightningLoggerBase, bool]
+    tqdm_metrics: ...
+    global_step: int
+    proc_rank: int
+    use_dp: bool
+    use_ddp2: bool
+    default_save_path: str
+    slurm_job_id: int
+    num_gpus: int
 
     def configure_logger(self, logger):
         if logger is True:
@@ -34,16 +36,21 @@ class TrainerLoggingMixin(ABC):
         elif logger is False:
             self.logger = None
         else:
-            self.logger = logger
+            if isinstance(logger, Iterable):
+                self.logger = LoggerCollection(logger)
+            else:
+                self.logger = logger
             self.logger.rank = 0
 
     def log_metrics(self, metrics, grad_norm_dic, step=None):
         """Logs the metric dict passed in.
         If `step` parameter is None and `step` key is presented is metrics,
         uses metrics["step"] as a step
-        :param metrics (dict): Metric values
-        :param grad_norm_dic (dict): Gradient norms
-        :param step (int): Step for which metrics should be logged. Default value corresponds to `self.global_step`
+
+        Args:
+            metrics (dict): Metric values
+            grad_norm_dic (dict): Gradient norms
+            step (int): Step for which metrics should be logged. Default value corresponds to `self.global_step`
         """
         # add gpu memory
         if self.on_gpu and self.log_gpu_memory:
@@ -91,8 +98,6 @@ class TrainerLoggingMixin(ABC):
         """Reduces output according to the training mode.
 
         Separates loss from logging and tqdm metrics
-        :param output:
-        :return:
         """
         # ---------------
         # EXTRACT CALLBACK KEYS
diff --git a/pytorch_lightning/trainer/model_hooks.py b/pytorch_lightning/trainer/model_hooks.py
index e5afc90..2894cc6 100644
--- a/pytorch_lightning/trainer/model_hooks.py
+++ b/pytorch_lightning/trainer/model_hooks.py
@@ -11,8 +11,9 @@ class TrainerModelHooksMixin(ABC):
         f_op = getattr(model, f_name, None)
         return callable(f_op)
 
-    def is_overriden(self, f_name):
-        model = self.get_model()
+    def is_overriden(self, f_name, model=None):
+        if model is None:
+            model = self.get_model()
         super_object = LightningModule
 
         # when code pointers are different, it was overriden
@@ -26,5 +27,4 @@ class TrainerModelHooksMixin(ABC):
 
     @abstractmethod
     def get_model(self):
-        # this is just empty shell for code from other class
-        pass
+        """Warning: this is just empty shell for code implemented in other class."""
diff --git a/pytorch_lightning/trainer/trainer.py b/pytorch_lightning/trainer/trainer.py
index 4d204bd..7668a1f 100644
--- a/pytorch_lightning/trainer/trainer.py
+++ b/pytorch_lightning/trainer/trainer.py
@@ -1,18 +1,22 @@
+import logging as log
 import os
 import sys
 import warnings
-import logging as log
-from typing import Union, Optional, List, Dict, Tuple
+from argparse import ArgumentParser
+from typing import Union, Optional, List, Dict, Tuple, Iterable
 
 import torch
+from torch import optim
 import torch.distributed as dist
 import torch.multiprocessing as mp
+from torch.optim.optimizer import Optimizer
 from torch.utils.data import DataLoader
 from tqdm.auto import tqdm
-from torch.optim.optimizer import Optimizer
 
+from pytorch_lightning.callbacks import Callback
 from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping
 from pytorch_lightning.loggers import LightningLoggerBase
+from pytorch_lightning.profiler import Profiler, PassThroughProfiler
 from pytorch_lightning.profiler.profiler import BaseProfiler
 from pytorch_lightning.trainer.auto_mix_precision import TrainerAMPMixin
 from pytorch_lightning.trainer.callback_config import TrainerCallbackConfigMixin
@@ -24,6 +28,8 @@ from pytorch_lightning.trainer.distrib_parts import (
     determine_root_gpu_device
 )
 from pytorch_lightning.core.lightning import LightningModule
+from pytorch_lightning.trainer.callback_hook import TrainerCallbackHookMixin
+from pytorch_lightning.trainer.deprecated_api import TrainerDeprecatedAPITillVer0_8
 from pytorch_lightning.trainer.evaluation_loop import TrainerEvaluationLoopMixin
 from pytorch_lightning.trainer.logging import TrainerLoggingMixin
 from pytorch_lightning.trainer.model_hooks import TrainerModelHooksMixin
@@ -31,44 +37,46 @@ from pytorch_lightning.trainer.training_io import TrainerIOMixin
 from pytorch_lightning.trainer.training_loop import TrainerTrainLoopMixin
 from pytorch_lightning.trainer.training_tricks import TrainerTrainingTricksMixin
 from pytorch_lightning.utilities.debugging import MisconfigurationException
-from pytorch_lightning.profiler import Profiler, PassThroughProfiler
-
 
 try:
     from apex import amp
-
-    APEX_AVAILABLE = True
 except ImportError:
     APEX_AVAILABLE = False
+else:
+    APEX_AVAILABLE = True
 
 try:
     import torch_xla
     import torch_xla.core.xla_model as xm
     import torch_xla.distributed.xla_multiprocessing as xmp
-
-    XLA_AVAILABLE = True
 except ImportError:
     XLA_AVAILABLE = False
+else:
+    XLA_AVAILABLE = True
 
 
-class Trainer(TrainerIOMixin,
-              TrainerDPMixin,
-              TrainerDDPMixin,
-              TrainerLoggingMixin,
-              TrainerModelHooksMixin,
-              TrainerTrainingTricksMixin,
-              TrainerDataLoadingMixin,
-              TrainerAMPMixin,
-              TrainerEvaluationLoopMixin,
-              TrainerTrainLoopMixin,
-              TrainerCallbackConfigMixin,
-              ):
+class Trainer(
+    TrainerIOMixin,
+    TrainerDPMixin,
+    TrainerDDPMixin,
+    TrainerLoggingMixin,
+    TrainerModelHooksMixin,
+    TrainerTrainingTricksMixin,
+    TrainerDataLoadingMixin,
+    TrainerAMPMixin,
+    TrainerEvaluationLoopMixin,
+    TrainerTrainLoopMixin,
+    TrainerCallbackConfigMixin,
+    TrainerCallbackHookMixin,
+    TrainerDeprecatedAPITillVer0_8,
+):
 
     def __init__(
             self,
-            logger: Union[LightningLoggerBase, bool] = True,
+            logger: Union[LightningLoggerBase, Iterable[LightningLoggerBase], bool] = True,
             checkpoint_callback: Union[ModelCheckpoint, bool] = True,
-            early_stop_callback: Optional[Union[EarlyStopping, bool]] = None,
+            early_stop_callback: Optional[Union[EarlyStopping, bool]] = False,
+            callbacks: List[Callback] = [],
             default_save_path: Optional[str] = None,
             gradient_clip_val: float = 0,
             gradient_clip=None,  # backward compatible, todo: remove in v0.8.0
@@ -79,11 +87,12 @@ class Trainer(TrainerIOMixin,
             num_tpu_cores: Optional[int] = None,
             log_gpu_memory: Optional[str] = None,
             show_progress_bar: bool = True,
+            progress_bar_refresh_rate: int = 1,
             overfit_pct: float = 0.0,
             track_grad_norm: int = -1,
             check_val_every_n_epoch: int = 1,
             fast_dev_run: bool = False,
-            accumulate_grad_batches: Union[int, Dict[int, int]] = 1,
+            accumulate_grad_batches: Union[int, Dict[int, int], List[list]] = 1,
             max_nb_epochs=None,  # backward compatible, todo: remove in v0.8.0
             min_nb_epochs=None,  # backward compatible, todo: remove in v0.8.0
             max_epochs: int = 1000,
@@ -93,12 +102,12 @@ class Trainer(TrainerIOMixin,
             train_percent_check: float = 1.0,
             val_percent_check: float = 1.0,
             test_percent_check: float = 1.0,
-            val_check_interval: Union[float] = 1.0,
+            val_check_interval: float = 1.0,
             log_save_interval: int = 100,
             row_log_interval: int = 10,
             add_row_log_interval=None,  # backward compatible, todo: remove in v0.8.0
             distributed_backend: Optional[str] = None,
-            use_amp=False,  # backward compatible, todo: remove in v0.8.0
+            use_amp=False,  # backward compatible, todo: remove in v0.9.0
             precision: int = 32,
             print_nan_grads: bool = False,
             weights_summary: str = 'full',
@@ -109,500 +118,148 @@ class Trainer(TrainerIOMixin,
             truncated_bptt_steps: Optional[int] = None,
             resume_from_checkpoint: Optional[str] = None,
             profiler: Optional[BaseProfiler] = None,
+            benchmark: bool = False,
+            reload_dataloaders_every_epoch: bool = False,
+            **kwargs
     ):
         r"""
 
         Customize every aspect of training via flags
 
         Args:
-            logger: Logger for experiment tracking.
-                Example::
+            logger: Logger (or iterable collection of loggers) for experiment tracking.
 
-                    from pytorch_lightning.loggers import TensorBoardLogger
-
-                    # default logger used by trainer
-                    logger = TensorBoardLogger(
-                        save_dir=os.getcwd(),
-                        version=self.slurm_job_id,
-                        name='lightning_logs'
-                    )
+            checkpoint_callback: Callback for checkpointing.
 
-                    Trainer(logger=logger)
+            early_stop_callback (:class:`pytorch_lightning.callbacks.EarlyStopping`):
 
-            checkpoint_callback: Callback for checkpointing.
-                Example::
-
-                    from pytorch_lightning.callbacks import ModelCheckpoint
-
-                    # default used by the Trainer
-                    checkpoint_callback = ModelCheckpoint(
-                        filepath=os.getcwd(),
-                        save_best_only=True,
-                        verbose=True,
-                        monitor='val_loss',
-                        mode='min',
-                        prefix=''
-                    )
-
-                    trainer = Trainer(checkpoint_callback=checkpoint_callback)
-
-            early_stop_callback: Callback for early stopping. If
-                set to ``True``, then the default callback monitoring ``'val_loss'`` is created.
-                Will raise an error if ``'val_loss'`` is not found.
-                If set to ``False``, then early stopping will be disabled.
-                If set to ``None``, then the default callback monitoring ``'val_loss'`` is created.
-                If ``'val_loss'`` is not found will work as if early stopping is disabled.
-                Default: ``None``.
-                Example::
-
-                    from pytorch_lightning.callbacks import EarlyStopping
-
-                    # default used by the Trainer
-                    early_stop_callback = EarlyStopping(
-                        monitor='val_loss',
-                        patience=3,
-                        strict=False,
-                        verbose=False,
-                        mode='min'
-                    )
-
-                    trainer = Trainer(early_stop_callback=early_stop_callback)
+            callbacks: Add a list of callbacks.
 
             default_save_path: Default path for logs and weights when no logger/ckpt_callback passed
-                Example::
-
-                    # default used by the Trainer
-                    trainer = Trainer(default_save_path=os.getcwd())
 
             gradient_clip_val: 0 means don't clip.
-                Example::
-
-                    # default used by the Trainer
-                    trainer = Trainer(gradient_clip_val=0.0)
 
             gradient_clip:
-                .. warning: .. deprecated:: 0.5.0
-                    Use `gradient_clip_val` instead. Will remove 0.8.0.
+                .. warning:: deprecated 0.7.0 Use `gradient_clip_val` instead. Will remove 0.9.0.
 
             process_position: orders the tqdm bar when running multiple models on same machine.
-                Example::
-
-                    # default used by the Trainer
-                    trainer = Trainer(process_position=0)
 
             num_nodes: number of GPU nodes for distributed training.
-                Example::
-
-                    # default used by the Trainer
-                    trainer = Trainer(num_nodes=1)
-
-                    # to train on 8 nodes
-                    trainer = Trainer(num_nodes=8)
 
             nb_gpu_nodes:
-                ..warning:: .. deprecated:: 0.5.0
-                    Use `num_nodes` instead. Will remove 0.8.0.
+                .. warning:: .. deprecated:: 0.7.0
+                    Use `num_nodes` instead. Will remove 0.9.0.
 
             gpus: Which GPUs to train on.
-                Example::
-
-                    # default used by the Trainer (ie: train on CPU)
-                    trainer = Trainer(gpus=None)
-
-                    # int: train on 2 gpus
-                    trainer = Trainer(gpus=2)
-
-                    # list: train on GPUs 1, 4 (by bus ordering)
-                    trainer = Trainer(gpus=[1, 4])
-                    trainer = Trainer(gpus='1, 4') # equivalent
-
-                    # -1: train on all gpus
-                    trainer = Trainer(gpus=-1)
-                    trainer = Trainer(gpus='-1') # equivalent
-
-                    # combine with num_nodes to train on multiple GPUs across nodes
-                    trainer = Trainer(gpus=2, num_nodes=4) # uses 8 gpus in total
 
             num_tpu_cores: How many TPU cores to train on (1 or 8).
-                A single TPU v2 or v3 has 8 cores. A TPU pod has
-                up to 2048 cores. A slice of a POD means you get as many cores
-                as you request.
-
-                You MUST use DistributedDataSampler with your dataloader for this
-                to work. Your effective batch size is batch_size * total tpu cores.
-
-                This parameter can be either 1 or 8.
-
-                Example::
-
-                    # your_trainer_file.py
-
-                    # default used by the Trainer (ie: train on CPU)
-                    trainer = Trainer(num_tpu_cores=None)
-
-                    # int: train on a single core
-                    trainer = Trainer(num_tpu_cores=1)
-
-                    # int: train on all cores few cores
-                    trainer = Trainer(num_tpu_cores=8)
-
-                    # for 8+ cores must submit via xla script with
-                    # a max of 8 cores specified. The XLA script
-                    # will duplicate script onto each TPU in the POD
-                    trainer = Trainer(num_tpu_cores=8)
-
-                    # -1: train on all available TPUs
-                    trainer = Trainer(num_tpu_cores=-1)
-
-            To train on more than 8 cores (ie: a POD),
-            submit this script using the xla_dist script.
-
-            Example::
-
-                $ python -m torch_xla.distributed.xla_dist
-                --tpu=$TPU_POD_NAME
-                --conda-env=torch-xla-nightly
-                --env=XLA_USE_BF16=1
-                -- python your_trainer_file.py
 
             log_gpu_memory: None, 'min_max', 'all'. Might slow performance
-                because it uses the output of nvidia-smi.
-                Example::
-
-                    # default used by the Trainer
-                    trainer = Trainer(log_gpu_memory=None)
-
-                    # log all the GPUs (on master node only)
-                    trainer = Trainer(log_gpu_memory='all')
-
-                    # log only the min and max memory on the master node
-                    trainer = Trainer(log_gpu_memory='min_max')
 
             show_progress_bar: If true shows tqdm progress bar
-                Example::
-
-                    # default used by the Trainer
-                    trainer = Trainer(show_progress_bar=True)
-
-            overfit_pct: uses this much data of all datasets.
-                Example::
 
-                    # default used by the Trainer
-                    trainer = Trainer(overfit_pct=0.0)
-
-                    # use only 1% of the train, test, val datasets
-                    trainer = Trainer(overfit_pct=0.01)
+            progress_bar_refresh_rate: How often to refresh progress bar (in steps)
 
             track_grad_norm: -1 no tracking. Otherwise tracks that norm
-                Example::
-
-                    # default used by the Trainer
-                    trainer = Trainer(track_grad_norm=-1)
-
-                    # track the 2-norm
-                    trainer = Trainer(track_grad_norm=2)
 
             check_val_every_n_epoch: Check val every n train epochs.
-                Example::
-
-                    # default used by the Trainer
-                    trainer = Trainer(check_val_every_n_epoch=1)
-
-                    # run val loop every 10 training epochs
-                    trainer = Trainer(check_val_every_n_epoch=10)
 
             fast_dev_run: runs 1 batch of train, test  and val to find any bugs (ie: a sort of unit test).
-                Example::
-
-                    # default used by the Trainer
-                    trainer = Trainer(fast_dev_run=False)
-
-                    # runs 1 train, val, test  batch and program ends
-                    trainer = Trainer(fast_dev_run=True)
 
             accumulate_grad_batches: Accumulates grads every k batches or as set up in the dict.
-                Example::
-
-                    # default used by the Trainer (no accumulation)
-                    trainer = Trainer(accumulate_grad_batches=1)
-
-                    # accumulate every 4 batches (effective batch size is batch*4)
-                    trainer = Trainer(accumulate_grad_batches=4)
-
-                    # no accumulation for epochs 1-4. accumulate 3 for epochs 5-10. accumulate 20 after that
-                    trainer = Trainer(accumulate_grad_batches={5: 3, 10: 20})
 
             max_epochs: Stop training once this number of epochs is reached.
-                Example::
-
-                    # default used by the Trainer
-                    trainer = Trainer(max_epochs=1000)
 
             max_nb_epochs:
-                .. warning:: .. deprecated:: 0.5.0
-                    Use `max_epochs` instead. Will remove 0.8.0.
+                .. warning:: .. deprecated:: 0.7.0
+                    Use `max_epochs` instead. Will remove 0.9.0.
 
             min_epochs: Force training for at least these many epochs
-                Example::
-
-                    # default used by the Trainer
-                    trainer = Trainer(min_epochs=1)
 
             min_nb_epochs:
-                .. warning:: .. deprecated:: 0.5.0
-                    Use `min_nb_epochs` instead. Will remove 0.8.0.
+                .. warning:: .. deprecated:: 0.7.0
+                    Use `min_epochs` instead. Will remove 0.9.0.
 
             max_steps: Stop training after this number of steps. Disabled by default (None).
-                Training will stop if max_steps or max_epochs have reached (earliest).
-                Example::
-
-                    # Stop after 100 steps
-                    trainer = Trainer(max_steps=100)
 
             min_steps: Force training for at least these number of steps. Disabled by default (None).
-                Trainer will train model for at least min_steps or min_epochs (latest).
-                Example::
-
-                    # Run at least for 100 steps (disable min_epochs)
-                    trainer = Trainer(min_steps=100, min_epochs=0)
 
             train_percent_check: How much of training dataset to check.
-                Useful when debugging or testing something that happens at the end of an epoch.
-                Example::
-
-                    # default used by the Trainer
-                    trainer = Trainer(train_percent_check=1.0)
-
-                    # run through only 25% of the training set each epoch
-                    trainer = Trainer(train_percent_check=0.25)
 
             val_percent_check: How much of validation dataset to check.
-                Useful when debugging or testing something that happens at the end of an epoch.
-                Example::
-
-                    # default used by the Trainer
-                    trainer = Trainer(val_percent_check=1.0)
-
-                    # run through only 25% of the validation set each epoch
-                    trainer = Trainer(val_percent_check=0.25)
 
             test_percent_check: How much of test dataset to check.
-                Useful when debugging or testing something that happens at the end of an epoch.
-                Example::
-
-                    # default used by the Trainer
-                    trainer = Trainer(test_percent_check=1.0)
-
-                    # run through only 25% of the test set each epoch
-                    trainer = Trainer(test_percent_check=0.25)
 
             val_check_interval: How often within one training epoch to check the validation set
-                If float, % of tng epoch. If int, check every n batch
-                Example::
-
-                    # default used by the Trainer
-                    trainer = Trainer(val_check_interval=1.0)
-
-                    # check validation set 4 times during a training epoch
-                    trainer = Trainer(val_check_interval=0.25)
-
-                    # check validation set every 1000 training batches
-                    # use this when using iterableDataset and your dataset has no length
-                    # (ie: production cases with streaming data)
-                    trainer = Trainer(val_check_interval=1000)
 
             log_save_interval: Writes logs to disk this often
-                Example::
-
-                    # default used by the Trainer
-                    trainer = Trainer(log_save_interval=100)
 
             row_log_interval: How often to add logging rows (does not write to disk)
-                Example::
-
-                    # default used by the Trainer
-                    trainer = Trainer(row_log_interval=10)
 
             add_row_log_interval:
-                .. warning:: .. deprecated:: 0.5.0
-                    Use `row_log_interval` instead. Will remove 0.8.0.
+                .. warning:: .. deprecated:: 0.7.0
+                    Use `row_log_interval` instead. Will remove 0.9.0.
 
             distributed_backend: The distributed backend to use.
-                Options: 'dp', 'ddp', 'ddp2'.
-                Example::
-
-                    # default used by the Trainer
-                    trainer = Trainer(distributed_backend=None)
-
-                    # dp = DataParallel (split a batch onto k gpus on same machine).
-                    trainer = Trainer(gpus=2, distributed_backend='dp')
-
-                    # ddp = DistributedDataParallel
-                    # Each gpu trains by itself on a subset of the data.
-                    # Gradients sync across all gpus and all machines.
-                    trainer = Trainer(gpus=2, num_nodes=2, distributed_backend='ddp')
-
-                    # ddp2 = DistributedDataParallel + dp
-                    # behaves like dp on every node
-                    # syncs gradients across nodes like ddp
-                    # useful for things like increasing the number of negative samples
-                    trainer = Trainer(gpus=2, num_nodes=2, distributed_backend='ddp2')
 
             use_amp:
-                .. warning:: .. deprecated:: 0.6.1
-                    Use `precision` instead. Will remove 0.8.0.
+                .. warning:: .. deprecated:: 0.7.0
+                    Use `precision` instead. Will remove 0.9.0.
 
             precision: Full precision (32), half precision (16).
-                Can be used on CPU, GPU or TPUs.
-
-                If used on TPU will use torch.bfloat16 but tensor printing
-                will still show torch.float32.
-
-                Example::
-
-                    # default used by the Trainer
-                    trainer = Trainer(precision=32)
-
-                    # 16-bit precision
-                    trainer = Trainer(precision=16)
-
-                    # one day
-                    trainer = Trainer(precision=8|4|2)
 
             print_nan_grads: Prints gradients with nan values
-                Example::
-
-                    # default used by the Trainer
-                    trainer = Trainer(print_nan_grads=False)
 
             weights_summary: Prints a summary of the weights when training begins.
-                Options: 'full', 'top', None.
-                Example::
-
-                    # default used by the Trainer (ie: print all weights)
-                    trainer = Trainer(weights_summary='full')
-
-                    # print only the top level modules
-                    trainer = Trainer(weights_summary='top')
-
-                    # don't print a summary
-                    trainer = Trainer(weights_summary=None)
 
             weights_save_path: Where to save weights if specified.
-                Example::
-
-                    # default used by the Trainer
-                    trainer = Trainer(weights_save_path=os.getcwd())
-
-                    # save to your custom path
-                    trainer = Trainer(weights_save_path='my/path')
-
-                    # if checkpoint callback used, then overrides the weights path
-                    # **NOTE: this saves weights to some/path NOT my/path
-                    checkpoint_callback = ModelCheckpoint(filepath='some/path')
-                    trainer = Trainer(
-                        checkpoint_callback=checkpoint_callback,
-                        weights_save_path='my/path'
-                    )
 
             amp_level: The optimization level to use (O1, O2, etc...).
-                Check nvidia docs for level (https://nvidia.github.io/apex/amp.html#opt-levels)
-                Example::
-
-                    # default used by the Trainer
-                    trainer = Trainer(amp_level='O1')
 
             num_sanity_val_steps: Sanity check runs n batches of val before starting the training routine.
-                This catches any bugs in your validation without having to wait for the first validation check.
-                The Trainer uses 5 steps by default. Turn it off or modify it here.
-                Example::
-
-                    # default used by the Trainer
-                    trainer = Trainer(num_sanity_val_steps=5)
-
-                    # turn it off
-                    trainer = Trainer(num_sanity_val_steps=0)
 
             nb_sanity_val_steps:
-                .. warning:: .. deprecated:: 0.5.0
+                .. warning:: .. deprecated:: 0.7.0
                     Use `num_sanity_val_steps` instead. Will remove 0.8.0.
 
             truncated_bptt_steps: Truncated back prop breaks performs backprop every k steps of
-                a much longer sequence If this is enabled, your batches will automatically get truncated
-                and the trainer will apply Truncated Backprop to it. Make sure your batches have a sequence
-                dimension. (`Williams et al. "An efficient gradient-based algorithm for on-line training of
-                recurrent network trajectories."
-                <http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.56.7941&rep=rep1&type=pdf>`_)
-                Example::
-
-                    # default used by the Trainer (ie: disabled)
-                    trainer = Trainer(truncated_bptt_steps=None)
-
-                    # backprop every 5 steps in a batch
-                    trainer = Trainer(truncated_bptt_steps=5)
-
-
-                Lightning takes care to split your batch along the time-dimension.
-
-                .. note:: If you need to modify how the batch is split,
-                    override :meth:`pytorch_lightning.core.LightningModule.tbptt_split_batch`.
-
-                .. note:: Using this feature requires updating your LightningModule's
-                    :meth:`pytorch_lightning.core.LightningModule.training_step` to include a `hiddens` arg.
 
             resume_from_checkpoint: To resume training from a specific checkpoint pass in the path here.k
-                Example::
 
-                    # default used by the Trainer
-                    trainer = Trainer(resume_from_checkpoint=None)
-
-                    # resume from a specific checkpoint
-                    trainer = Trainer(resume_from_checkpoint='some/path/to/my_checkpoint.ckpt')
             profiler:  To profile individual steps during training and assist in
-                identifying bottlenecks.
-                Example::
-
-                    from pytorch_lightning.profiler import Profiler, AdvancedProfiler
 
-                    # default used by the Trainer
-                    trainer = Trainer(profiler=None)
+            reload_dataloaders_every_epoch: Set to True to reload dataloaders every epoch
 
-                    # to profile standard training events
-                    trainer = Trainer(profiler=True)
-
-                    # equivalent to profiler=True
-                    profiler = Profiler()
-                    trainer = Trainer(profiler=profiler)
-
-                    # advanced profiler for function-level stats
-                    profiler = AdvancedProfiler()
-                    trainer = Trainer(profiler=profiler)
-
-        .. warning:: Following arguments become deprecated and they will be removed in v0.8.0:
+            benchmark: If true enables cudnn.benchmark.
+        """
 
-            - `nb_sanity_val_steps`
+        # Init callbacks
+        self.callbacks = callbacks
+        self.on_init_start()
 
-        """
+        # benchmarking
+        self.benchmark = benchmark
+        if benchmark:
+            torch.backends.cudnn.benchmark = True
 
         # Transfer params
-        # Backward compatibility
+        self.num_nodes = num_nodes
+        # Backward compatibility, TODO: remove in v0.8.0
         if nb_gpu_nodes is not None:
-            warnings.warn("`nb_gpu_nodes` has renamed to `num_nodes` since v0.5.0"
+            warnings.warn("Argument `nb_gpu_nodes` has renamed to `num_nodes` since v0.5.0"
                           " and this method will be removed in v0.8.0", DeprecationWarning)
-            if not num_nodes:  # in case you did not set the proper value
-                num_nodes = nb_gpu_nodes
-        self.num_gpu_nodes = num_nodes
-
+            self.num_gpu_nodes = nb_gpu_nodes
         self.log_gpu_memory = log_gpu_memory
 
-        # Backward compatibility
+        self.gradient_clip_val = gradient_clip_val
+        # Backward compatibility, TODO: remove in v0.8.0
         if gradient_clip is not None:
-            warnings.warn("`gradient_clip` has renamed to `gradient_clip_val` since v0.5.0"
+            warnings.warn("Argument `gradient_clip` has renamed to `gradient_clip_val` since v0.5.0"
                           " and this method will be removed in v0.8.0", DeprecationWarning)
-            if not gradient_clip_val:  # in case you did not set the proper value
-                gradient_clip_val = gradient_clip
-        self.gradient_clip_val = gradient_clip_val
+            self.gradient_clip = gradient_clip
 
+        self.reload_dataloaders_every_epoch = reload_dataloaders_every_epoch
+        self.progress_bar_refresh_rate = progress_bar_refresh_rate
         self.check_val_every_n_epoch = check_val_every_n_epoch
         self.track_grad_norm = track_grad_norm
         self.on_gpu = True if (gpus and torch.cuda.is_available()) else False
@@ -615,33 +272,30 @@ class Trainer(TrainerIOMixin,
         self.process_position = process_position
         self.weights_summary = weights_summary
 
-        # Backward compatibility
+        self.max_epochs = max_epochs
+        # Backward compatibility, TODO: remove in v0.8.0
         if max_nb_epochs is not None:
-            warnings.warn("`max_nb_epochs` has renamed to `max_epochs` since v0.5.0"
+            warnings.warn("Argument `max_nb_epochs` has renamed to `max_epochs` since v0.5.0"
                           " and this method will be removed in v0.8.0", DeprecationWarning)
-            if not max_epochs:  # in case you did not set the proper value
-                max_epochs = max_nb_epochs
-        self.max_epochs = max_epochs
+            self.max_nb_epochs = max_nb_epochs
 
-        # Backward compatibility
+        self.min_epochs = min_epochs
+        # Backward compatibility, TODO: remove in v0.8.0
         if min_nb_epochs is not None:
-            warnings.warn("`min_nb_epochs` has renamed to `min_epochs` since v0.5.0"
+            warnings.warn("Argument `min_nb_epochs` has renamed to `min_epochs` since v0.5.0"
                           " and this method will be removed in v0.8.0", DeprecationWarning)
-            if not min_epochs:  # in case you did not set the proper value
-                min_epochs = min_nb_epochs
-        self.min_epochs = min_epochs
+            self.min_nb_epochs = min_nb_epochs
 
         self.max_steps = max_steps
         self.min_steps = min_steps
 
-        # Backward compatibility
+        self.num_sanity_val_steps = num_sanity_val_steps
+        # Backward compatibility, TODO: remove in v0.8.0
         if nb_sanity_val_steps is not None:
-            warnings.warn("`nb_sanity_val_steps` has renamed to `num_sanity_val_steps` since v0.5.0"
+            warnings.warn("Argument `nb_sanity_val_steps` has renamed to "
+                          "`num_sanity_val_steps` since v0.5.0"
                           " and this method will be removed in v0.8.0", DeprecationWarning)
-            if not num_sanity_val_steps:  # in case you did not set the proper value
-                num_sanity_val_steps = nb_sanity_val_steps
-
-        self.num_sanity_val_steps = num_sanity_val_steps
+            self.nb_sanity_val_steps = nb_sanity_val_steps
         self.print_nan_grads = print_nan_grads
         self.truncated_bptt_steps = truncated_bptt_steps
         self.resume_from_checkpoint = resume_from_checkpoint
@@ -672,10 +326,9 @@ class Trainer(TrainerIOMixin,
         self.num_val_batches = 0
         self.num_training_batches = 0
         self.num_test_batches = 0
-        self.get_train_dataloader = None
-        self.get_test_dataloaders = None
-        self.get_val_dataloaders = None
-        self.is_iterable_train_dataloader = False
+        self.train_dataloader = None
+        self.test_dataloaders = None
+        self.val_dataloaders = None
 
         # training state
         self.model = None
@@ -699,17 +352,17 @@ class Trainer(TrainerIOMixin,
         # creates a default one if none passed in
         self.configure_early_stopping(early_stop_callback)
 
-        self.reduce_lr_on_plateau_scheduler = None
-
         # configure checkpoint callback
         self.checkpoint_callback = checkpoint_callback
         self.weights_save_path = weights_save_path
 
         # accumulated grads
+        self.accumulate_grad_batches = accumulate_grad_batches
         self.configure_accumulated_gradients(accumulate_grad_batches)
 
         # allow int, string and gpu list
-        self.data_parallel_device_ids = parse_gpu_ids(gpus)
+        self.gpus = gpus
+        self.data_parallel_device_ids = parse_gpu_ids(self.gpus)
         self.root_gpu = determine_root_gpu_device(self.data_parallel_device_ids)
 
         # tpu state flags
@@ -723,7 +376,7 @@ class Trainer(TrainerIOMixin,
         self.use_dp = False
         self.single_gpu = False
         self.distributed_backend = distributed_backend
-        self.set_distributed_mode(distributed_backend, num_nodes)
+        self.set_distributed_mode(distributed_backend, self.num_nodes)
 
         # override dist backend when using tpus
         if self.on_tpu:
@@ -734,7 +387,7 @@ class Trainer(TrainerIOMixin,
         self.proc_rank = 0
         self.world_size = 1
         self.node_rank = 0
-        self.configure_slurm_ddp(num_nodes)
+        self.configure_slurm_ddp(self.num_nodes)
 
         # nvidia setup
         self.set_nvidia_flags(self.is_slurm_managing_tasks, self.data_parallel_device_ids)
@@ -756,16 +409,23 @@ class Trainer(TrainerIOMixin,
         self.row_log_interval = row_log_interval
 
         # how much of the data to use
+        self.overfit_pct = overfit_pct
         self.determine_data_use_amount(train_percent_check, val_percent_check,
                                        test_percent_check, overfit_pct)
 
         # 16 bit mixed precision training using apex
         self.amp_level = amp_level
         self.precision = precision
-        if self.precision == 16:
+
+        assert self.precision in (16, 32), 'only 32 or 16 bit precision supported'
+
+        if self.precision == 16 and self.num_tpu_cores is None:
             use_amp = True
         self.init_amp(use_amp)
 
+        # Callback system
+        self.on_init_end()
+
     @property
     def slurm_job_id(self) -> int:
         try:
@@ -775,39 +435,42 @@ class Trainer(TrainerIOMixin,
             job_id = None
         return job_id
 
-    def __parse_gpu_ids(self, gpus):
-        """Parse GPUs id.
+    @classmethod
+    def default_attributes(cls):
+        import inspect
 
-        :param list|str|int gpus: input GPU ids
-        :return list(int):
-        """
-        # if gpus = -1 then use all available devices
-        # otherwise, split the string using commas
-        if gpus is not None:
-            if isinstance(gpus, list):
-                gpus = gpus
-            elif isinstance(gpus, str):
-                if gpus == '-1':
-                    gpus = list(range(0, torch.cuda.device_count()))
-                else:
-                    gpus = [int(x.strip()) for x in gpus.split(',')]
-            elif isinstance(gpus, int):
-                gpus = gpus
-            else:
-                raise ValueError('`gpus` has to be a string, int or list of ints')
+        init_signature = inspect.signature(Trainer)
 
-        return gpus
+        args = {}
+        for param_name in init_signature.parameters:
+            value = init_signature.parameters[param_name].default
+            args[param_name] = value
 
-    def __set_root_gpu(self, gpus):
-        if gpus is None:
-            return None
+        return args
+
+    @classmethod
+    def add_argparse_args(cls, parent_parser: ArgumentParser) -> ArgumentParser:
+        """Extend existing argparse by default `Trainer` attributes."""
+        parser = ArgumentParser(parents=[parent_parser], add_help=False)
+
+        trainer_default_params = Trainer.default_attributes()
+
+        # TODO: get "help" from docstring :)
+        for arg in trainer_default_params:
+            parser.add_argument(
+                f'--{arg}',
+                default=trainer_default_params[arg],
+                dest=arg,
+                help='autogenerated by pl.Trainer'
+            )
 
-        # set root gpu
-        root_gpu = 0
-        if isinstance(gpus, list):
-            root_gpu = gpus[0]
+        return parser
 
-        return root_gpu
+    @classmethod
+    def from_argparse_args(cls, args):
+
+        params = vars(args)
+        return cls(**params)
 
     @property
     def num_gpus(self) -> int:
@@ -849,8 +512,8 @@ class Trainer(TrainerIOMixin,
             self,
             model: LightningModule,
             train_dataloader: Optional[DataLoader] = None,
-            val_dataloader: Optional[DataLoader] = None,
-            test_dataloader: Optional[DataLoader] = None
+            val_dataloaders: Optional[DataLoader] = None,
+            test_dataloaders: Optional[DataLoader] = None
     ):
         r"""
         Runs the full optimization routine.
@@ -862,13 +525,13 @@ class Trainer(TrainerIOMixin,
                 DataLoader with training samples. If the model has
                 a predefined train_dataloader method this will be skipped.
 
-            val_dataloader: Either a single
+            val_dataloaders: Either a single
                 Pytorch Dataloader or a list of them, specifying validation samples.
-                If the model has a predefined val_dataloader method this will be skipped
+                If the model has a predefined val_dataloaders method this will be skipped
 
-            test_dataloader: Either a single
+            test_dataloaders: Either a single
                 Pytorch Dataloader or a list of them, specifying validation samples.
-                If the model has a predefined val_dataloader method this will be skipped
+                If the model has a predefined test_dataloaders method this will be skipped
 
         Example::
 
@@ -894,13 +557,19 @@ class Trainer(TrainerIOMixin,
             # feed to .fit()
 
         """
+        # bind logger and other properties
+        model.logger = self.logger
+        self.copy_trainer_model_properties(model)
+
+        # set up the passed in dataloaders (if needed)
+        self.__attach_dataloaders(model, train_dataloader, val_dataloaders, test_dataloaders)
 
-        # Update the dataloader attributes of the model with the ones supplied here,
-        # if they are not already defined in model
-        _set_dataloader(model, train_dataloader, 'train_dataloader')
-        _set_dataloader(model, val_dataloader, 'val_dataloader')
-        _set_dataloader(model, test_dataloader, 'test_dataloader')
+        # download the data and do whatever transforms we need
+        # do before any spawn calls so that the model can assign properties
+        # only on proc 0 because no spawn has happened yet
+        model.prepare_data()
 
+        # route to appropriate start method
         # when using multi-node or DDP within a node start each module in a separate process
         if self.use_ddp2:
             task = int(os.environ['SLURM_LOCALID'])
@@ -911,8 +580,18 @@ class Trainer(TrainerIOMixin,
                 task = int(os.environ['SLURM_LOCALID'])
                 self.ddp_train(task, model)
             else:
+                self.__set_random_port()
+
+                # track for predict
+                self.model = model
+
+                # train
                 mp.spawn(self.ddp_train, nprocs=self.num_gpus, args=(model,))
 
+                # load weights if not interrupted
+                self.load_spawn_weights(model)
+                self.model = model
+
         # 1 gpu or dp option triggers training using DP module
         # easier to avoid NCCL issues
         elif self.use_dp:
@@ -921,13 +600,22 @@ class Trainer(TrainerIOMixin,
         elif self.single_gpu:
             self.single_gpu_train(model)
 
-        elif self.use_tpu:
+        elif self.use_tpu:  # pragma: no cover
             log.info(f'training on {self.num_tpu_cores} TPU cores')
 
             #  COLAB_GPU is an env var available by default in Colab environments.
             start_method = 'fork' if os.getenv('COLAB_GPU') else 'spawn'
+
+            # track for predict
+            self.model = model
+
+            # train
             xmp.spawn(self.tpu_train, args=(model,), nprocs=self.num_tpu_cores, start_method=start_method)
 
+            # load weights if not interrupted
+            self.load_spawn_weights(model)
+            self.model = model
+
         # ON CPU
         else:
             # run through amp wrapper
@@ -944,31 +632,97 @@ class Trainer(TrainerIOMixin,
         # used for testing or when we need to know that training succeeded
         return 1
 
+    def __set_random_port(self):
+        """
+        When running DDP NOT managed by SLURM, the ports might collide
+        :return:
+        """
+        try:
+            default_port = os.environ['MASTER_PORT']
+        except Exception:
+            import random
+            default_port = random.randint(10000, 19000)
+            os.environ['MASTER_PORT'] = str(default_port)
+
+    def __attach_dataloaders(self, model, train_dataloader, val_dataloaders, test_dataloaders):
+        # when dataloader is passed via fit, patch the train_dataloader
+        # functions to overwrite with these implementations
+        if train_dataloader is not None:
+            if not self.is_overriden('training_step', model):
+                m = 'You called .fit() with a train_dataloader but did not define training_step()'
+                raise MisconfigurationException(m)
+
+            model.train_dataloader = _PatchDataLoader(train_dataloader)
+
+        if val_dataloaders is not None:
+            if not self.is_overriden('validation_step', model):
+                m = 'You called .fit() with a val_dataloaders but did not define validation_step()'
+                raise MisconfigurationException(m)
+
+            model.val_dataloader = _PatchDataLoader(val_dataloaders)
+
+        if test_dataloaders is not None:
+            if not self.is_overriden('test_step', model):
+                m = 'You called .fit() with a test_dataloaders but did not define test_step()'
+                raise MisconfigurationException(m)
+
+            model.test_dataloader = _PatchDataLoader(test_dataloaders)
+
     def init_optimizers(
             self,
             optimizers: Union[Optimizer, Tuple[List, List], List[Optimizer], Tuple[Optimizer]]
     ) -> Tuple[List, List]:
 
-        # single optimizer
+        # single output, single optimizer
         if isinstance(optimizers, Optimizer):
             return [optimizers], []
 
-        # two lists
-        if len(optimizers) == 2 and isinstance(optimizers[0], list):
+        # two lists, optimizer + lr schedulers
+        elif len(optimizers) == 2 and isinstance(optimizers[0], list):
             optimizers, lr_schedulers = optimizers
-            lr_schedulers, self.reduce_lr_on_plateau_scheduler = self.configure_schedulers(lr_schedulers)
+            lr_schedulers = self.configure_schedulers(lr_schedulers)
             return optimizers, lr_schedulers
 
-        # single list or tuple
-        if isinstance(optimizers, (list, tuple)):
+        # single list or tuple, multiple optimizer
+        elif isinstance(optimizers, (list, tuple)):
             return optimizers, []
 
+        # unknown configuration
+        else:
+            raise ValueError('Unknown configuration for model optimizers. Output'
+                             'from model.configure_optimizers() should either be:'
+                             '* single output, single torch.optim.Optimizer'
+                             '* single output, list of torch.optim.Optimizer'
+                             '* two outputs, first being a list of torch.optim.Optimizer',
+                             'second being a list of torch.optim.lr_scheduler')
+
     def configure_schedulers(self, schedulers: list):
-        for i, scheduler in enumerate(schedulers):
-            if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):
-                reduce_lr_on_plateau_scheduler = schedulers.pop(i)
-                return schedulers, reduce_lr_on_plateau_scheduler
-        return schedulers, None
+        # Convert each scheduler into dict sturcture with relevant information
+        lr_schedulers = []
+        default_config = {'interval': 'epoch',  # default every epoch
+                          'frequency': 1,  # default every epoch/batch
+                          'reduce_on_plateau': False,  # most often not ReduceLROnPlateau scheduler
+                          'monitor': 'val_loss'}  # default value to monitor for ReduceLROnPlateau
+        for scheduler in schedulers:
+            if isinstance(scheduler, dict):
+                if 'scheduler' not in scheduler:
+                    raise ValueError(f'Lr scheduler should have key `scheduler`',
+                                     ' with item being a lr scheduler')
+                scheduler['reduce_on_plateau'] = \
+                    isinstance(scheduler, optim.lr_scheduler.ReduceLROnPlateau)
+
+                lr_schedulers.append({**default_config, **scheduler})
+
+            elif isinstance(scheduler, optim.lr_scheduler.ReduceLROnPlateau):
+                lr_schedulers.append({**default_config, 'scheduler': scheduler,
+                                      'reduce_on_plateau': True})
+
+            elif isinstance(scheduler, optim.lr_scheduler._LRScheduler):
+                lr_schedulers.append({**default_config, 'scheduler': scheduler})
+            else:
+                raise ValueError(f'Input {scheduler} to lr schedulers '
+                                 'is a invalid input.')
+        return lr_schedulers
 
     def run_pretrain_routine(self, model: LightningModule):
         """Sanity check a few things before starting actual training.
@@ -986,10 +740,8 @@ class Trainer(TrainerIOMixin,
         # set local properties on the model
         self.copy_trainer_model_properties(ref_model)
 
-        # link up experiment object
+        # log hyper-parameters
         if self.logger is not None:
-            ref_model.logger = self.logger
-
             # save exp to get started
             if hasattr(ref_model, "hparams"):
                 self.logger.log_hyperparams(ref_model.hparams)
@@ -1004,17 +756,12 @@ class Trainer(TrainerIOMixin,
             # wait for all processes to catch up
             torch_xla.core.xla_model.rendezvous("pl.Trainer.run_pretrain_routine")
 
-        # set up checkpoint callback
-        self.configure_checkpoint_callback()
-
         # register auto-resubmit when on SLURM
         self.register_slurm_signal_handlers()
 
-        # transfer data loaders from model
-        self.get_dataloaders(ref_model)
-
         # print model summary
-        if self.proc_rank == 0 and self.weights_summary is not None:
+        # TODO: remove self.testing condition because model.summarize() is wiping out the weights
+        if self.proc_rank == 0 and self.weights_summary is not None and not self.testing:
             if self.weights_summary in ['full', 'top']:
                 ref_model.summarize(mode=self.weights_summary)
             else:
@@ -1025,35 +772,40 @@ class Trainer(TrainerIOMixin,
         # if cluster resets state, the model will update with the saved weights
         self.model = model
 
+        # set up checkpoint callback
+        self.configure_checkpoint_callback()
+
         # restore training and model before hpc call
         self.restore_weights(model)
 
         # when testing requested only run test and return
         if self.testing:
-            self.run_evaluation(test=True)
+            # only load test dataloader for testing
+            # self.reset_test_dataloader(ref_model)
+            self.run_evaluation(test_mode=True)
             return
 
         # check if we should run validation during training
-        self.disable_validation = ((self.num_val_batches == 0 or
-                                    not self.is_overriden('validation_step')) and
-                                   not self.fast_dev_run)
+        self.disable_validation = not self.is_overriden('validation_step') and not self.fast_dev_run
 
         # run tiny validation (if validation defined)
         # to make sure program won't crash during val
         ref_model.on_sanity_check_start()
-        ref_model.on_train_start()
         if not self.disable_validation and self.num_sanity_val_steps > 0:
+            self.reset_val_dataloader(ref_model)
             # init progress bars for validation sanity check
             pbar = tqdm(desc='Validation sanity check',
-                             total=self.num_sanity_val_steps * len(self.get_val_dataloaders()),
-                             leave=False, position=2 * self.process_position,
-                             disable=not self.show_progress_bar, dynamic_ncols=True)
+                        total=self.num_sanity_val_steps * len(self.val_dataloaders),
+                        leave=False, position=2 * self.process_position,
+                        disable=not self.show_progress_bar, dynamic_ncols=True)
             self.main_progress_bar = pbar
             # dummy validation progress bar
             self.val_progress_bar = tqdm(disable=True)
 
-            eval_results = self.evaluate(model, self.get_val_dataloaders(),
-                                         self.num_sanity_val_steps, False)
+            eval_results = self.evaluate(model,
+                                         self.val_dataloaders,
+                                         self.num_sanity_val_steps,
+                                         False)
             _, _, _, callback_metrics, _ = self.process_output(eval_results)
 
             # close progress bars
@@ -1082,7 +834,7 @@ class Trainer(TrainerIOMixin,
         Separates from fit to make sure you never run on your test set until you want to.
 
         Args:
-            model: The model to test.
+            model (:class:`.LightningModule`): The model to test.
 
         Example::
 
@@ -1100,54 +852,35 @@ class Trainer(TrainerIOMixin,
             trainer = Trainer()
             trainer.test(model)
         """
+
         self.testing = True
         if model is not None:
+            self.model = model
             self.fit(model)
+        elif self.use_ddp or self.use_tpu:  # pragma: no cover
+            # attempt to load weights from a spawn
+            path = os.path.join(self.default_save_path, '__temp_weight_ddp_end.ckpt')
+            test_model = self.model
+            if os.path.exists(path):
+                test_model = self.load_spawn_weights(self.model)
+
+            self.fit(test_model)
         else:
-            self.run_evaluation(test=True)
+            self.run_evaluation(test_mode=True)
+
+        self.testing = False
 
 
-def _set_dataloader(model, dataloader, attribute):
+class _PatchDataLoader(object):
     r'''
-    Check dataloaders passed to .fit() method if they are pytorch DataLoader
-    objects and whether or not we should overright the corresponding dataloader
-    in the model
+    Callable object for patching dataloaders passed into trainer.fit().
+    Use this class to override model.*_dataloader() and be pickle-compatible.
 
     Args:
-        model (LightningModule): The model to check
-
-        dataloader: If a pytorch dataloader (or a list of pytorch dataloaders)
-            is passed, it will be incorporate into the model as model.attribute.
-            If attribute alreay exist it will warn the userpass. If not a
-            dataloader will throw an error
-
-        attribute (str): The attribute to save the dataloader under
-
+        dataloader: Dataloader object to return when called.
     '''
-    # Check if attribute comes directly from base class or
-    # derived in user subclass
-    if LightningModule.__qualname__ in getattr(model, attribute).__qualname__:
-        # Val and test should be list of dataloaders
-        dataloader = dataloader if attribute == 'train_dataloader' or \
-            (attribute != 'train_dataloader' and isinstance(dataloader, list)) else [dataloader]
-
-        # Check we are given valid dataloaders
-        is_dataloader = isinstance(dataloader, torch.utils.data.DataLoader)
-        is_dataloader_list = isinstance(dataloader, list)
-        if is_dataloader_list:
-            valid_loaders = all(isinstance(d, torch.utils.data.DataLoader) for d in dataloader)
-        if is_dataloader or is_dataloader_list and valid_loaders:
-
-            # Overwrite abstract methods
-            dl = lambda: dataloader
-            dl.__name__ = attribute
-            setattr(model, attribute, dl)
-
-        elif dataloader and dataloader != [None]:
-            raise ValueError(f'`{attribute}` needs to be an instance of '
-                             '`torch.utils.data.DataLoader` or a list of '
-                             'DataLoaders, instead got %r`' % dataloader)
-
-    elif dataloader:  # if default (None) is passed, do not warn the user
-        warnings.warn(f'Model has predefined `{attribute}`,'
-                      f' will skip `{attribute}={dataloader}` passed to fit method.')
+    def __init__(self, dataloader: Union[List[DataLoader], DataLoader]):
+        self.dataloader = dataloader
+
+    def __call__(self) -> Union[List[DataLoader], DataLoader]:
+        return self.dataloader
diff --git a/pytorch_lightning/trainer/training_io.py b/pytorch_lightning/trainer/training_io.py
index 569c571..25e5644 100644
--- a/pytorch_lightning/trainer/training_io.py
+++ b/pytorch_lightning/trainer/training_io.py
@@ -82,7 +82,7 @@ At a rough level, here's what happens inside Trainer :py:mod:`pytorch_lightning.
     # restore the lr schedulers
     lr_schedulers = checkpoint['lr_schedulers']
     for scheduler, lrs_state in zip(self.lr_schedulers, lr_schedulers):
-        scheduler.load_state_dict(lrs_state)
+        scheduler['scheduler'].load_state_dict(lrs_state)
 
     # uses the model you passed into trainer
     model.load_state_dict(checkpoint['state_dict'])
@@ -95,12 +95,15 @@ import re
 import signal
 import warnings
 from abc import ABC
-from subprocess import call
 from argparse import Namespace
+from subprocess import call
+from typing import Union
 
 import torch
 import torch.distributed as dist
 
+from pytorch_lightning.core.lightning import LightningModule
+from pytorch_lightning.loggers import LightningLoggerBase
 from pytorch_lightning.overrides.data_parallel import (
     LightningDistributedDataParallel,
     LightningDataParallel,
@@ -110,33 +113,32 @@ try:
     import torch_xla
     import torch_xla.core.xla_model as xm
     import torch_xla.distributed.xla_multiprocessing as xmp
-
-    XLA_AVAILABLE = True
 except ImportError:
     XLA_AVAILABLE = False
+else:
+    XLA_AVAILABLE = True
 
 
 class TrainerIOMixin(ABC):
 
-    def __init__(self):
-        # this is just a summary on variables used in this abstract class,
-        #  the proper values/initialisation should be done in child class
-        self.model = None
-        self.on_gpu = None
-        self.root_gpu = None
-        self.resume_from_checkpoint = None
-        self.use_ddp = None
-        self.use_ddp2 = None
-        self.checkpoint_callback = None
-        self.proc_rank = None
-        self.weights_save_path = None
-        self.logger = None
-        self.early_stop_callback = None
-        self.lr_schedulers = None
-        self.optimizers = None
-        self.on_tpu = None
-        self.num_training_batches = None
-        self.accumulate_grad_batches = None
+    # this is just a summary on variables used in this abstract class,
+    #  the proper values/initialisation should be done in child class
+    model: LightningModule
+    on_gpu: bool
+    root_gpu: ...
+    resume_from_checkpoint: ...
+    use_ddp: bool
+    use_ddp2: bool
+    checkpoint_callback: ...
+    proc_rank: int
+    weights_save_path: str
+    logger: Union[LightningLoggerBase, bool]
+    early_stop_callback: ...
+    lr_schedulers: ...
+    optimizers: ...
+    on_tpu: bool
+    num_training_batches: int
+    accumulate_grad_batches: int
 
     def get_model(self):
         is_dp_module = isinstance(self.model, (LightningDistributedDataParallel,
@@ -149,11 +151,11 @@ class TrainerIOMixin(ABC):
     # --------------------
     def restore_weights(self, model):
         """
-        To restore weights we have two cases.
-        First, attempt to restore hpc weights. If successful, don't restore
-        other weights.
+        We attempt to restore weights in this order:
+        1. HPC weights.
+        2. if no HPC weights restore checkpoint_path weights
+        3. otherwise don't restore weights
 
-        Otherwise, try to restore actual weights
         :param model:
         :return:
         """
@@ -171,9 +173,6 @@ class TrainerIOMixin(ABC):
         if not did_restore_hpc_weights:
             if self.resume_from_checkpoint is not None:
                 self.restore(self.resume_from_checkpoint, on_gpu=self.on_gpu)
-            else:
-                # restore weights if same exp version
-                self.restore_state_if_checkpoint_exists(model)
 
         # wait for all models to restore weights
         if self.use_ddp or self.use_ddp2:
@@ -189,42 +188,6 @@ class TrainerIOMixin(ABC):
         if self.on_gpu:
             torch.cuda.empty_cache()
 
-    def restore_state_if_checkpoint_exists(self, model):
-        did_restore = False
-
-        # do nothing if there's not dir or callback
-        no_ckpt_callback = (self.checkpoint_callback is None) or (not self.checkpoint_callback)
-        if no_ckpt_callback or not os.path.exists(self.checkpoint_callback.filepath):
-            return did_restore
-
-        # restore trainer state and model if there is a weight for this experiment
-        last_epoch = -1
-        last_ckpt_name = None
-
-        # find last epoch
-        checkpoints = os.listdir(self.checkpoint_callback.filepath)
-        for name in checkpoints:
-            # ignore hpc ckpts
-            if 'hpc_' in name:
-                continue
-
-            if '.ckpt' in name:
-                epoch = name.split('epoch_')[1]
-                epoch = int(re.sub('[^0-9]', '', epoch))
-
-                if epoch > last_epoch:
-                    last_epoch = epoch
-                    last_ckpt_name = name
-
-        # restore last checkpoint
-        if last_ckpt_name is not None:
-            last_ckpt_path = os.path.join(self.checkpoint_callback.filepath, last_ckpt_name)
-            self.restore(last_ckpt_path, self.on_gpu)
-            log.info(f'Model and Trainer restored from checkpoint: {last_ckpt_path}')
-            did_restore = True
-
-        return did_restore
-
     # --------------------
     # HPC SIGNAL HANDLING
     # --------------------
@@ -243,7 +206,7 @@ class TrainerIOMixin(ABC):
             signal.signal(signal.SIGUSR1, self.sig_handler)
             signal.signal(signal.SIGTERM, self.term_handler)
 
-    def sig_handler(self, signum, frame):
+    def sig_handler(self, signum, frame):  # pragma: no cover
         if self.proc_rank == 0:
             # save weights
             log.info('handling SIGUSR1')
@@ -293,16 +256,29 @@ class TrainerIOMixin(ABC):
     def save_checkpoint(self, filepath):
         checkpoint = self.dump_checkpoint()
 
-        # do the actual save
-        try:
-            self._atomic_save(checkpoint, filepath)
-        except AttributeError:
-            if 'hparams' in checkpoint:
-                del checkpoint['hparams']
+        if self.proc_rank == 0:
+            # do the actual save
+            try:
+                self._atomic_save(checkpoint, filepath)
+            except AttributeError:
+                if 'hparams' in checkpoint:
+                    del checkpoint['hparams']
 
-            self._atomic_save(checkpoint, filepath)
+                self._atomic_save(checkpoint, filepath)
 
     def restore(self, checkpoint_path, on_gpu):
+        """
+        Restore training state from checkpoint.
+        Also restores all training state like:
+        - epoch
+        - callbacks
+        - schedulers
+        - optimizer
+        :param checkpoint_path:
+        :param on_gpu:
+
+        :return:
+        """
 
         # if on_gpu:
         #     checkpoint = torch.load(checkpoint_path)
@@ -343,16 +319,20 @@ class TrainerIOMixin(ABC):
 
         # save lr schedulers
         lr_schedulers = []
-        for i, scheduler in enumerate(self.lr_schedulers):
-            lr_schedulers.append(scheduler.state_dict())
+        for scheduler in self.lr_schedulers:
+            lr_schedulers.append(scheduler['scheduler'].state_dict())
 
         checkpoint['lr_schedulers'] = lr_schedulers
 
         # add the hparams and state_dict from the model
         model = self.get_model()
+
         checkpoint['state_dict'] = model.state_dict()
+
         if hasattr(model, "hparams"):
-            checkpoint['hparams'] = vars(model.hparams)
+            is_namespace = isinstance(model.hparams, Namespace)
+            checkpoint['hparams'] = vars(model.hparams) if is_namespace else model.hparams
+            checkpoint['hparams_type'] = 'namespace' if is_namespace else 'dict'
         else:
             warnings.warn(
                 "Did not find hyperparameters at model.hparams. Saving checkpoint without"
@@ -431,12 +411,12 @@ class TrainerIOMixin(ABC):
         # restore the lr schedulers
         lr_schedulers = checkpoint['lr_schedulers']
         for scheduler, lrs_state in zip(self.lr_schedulers, lr_schedulers):
-            scheduler.load_state_dict(lrs_state)
+            scheduler['scheduler'].load_state_dict(lrs_state)
 
     # ----------------------------------
     # PRIVATE OPS
     # ----------------------------------
-    def hpc_save(self, folderpath, logger):
+    def hpc_save(self, folderpath: str, logger):
         # make sure the checkpoint folder exists
         os.makedirs(folderpath, exist_ok=True)
 
@@ -447,7 +427,7 @@ class TrainerIOMixin(ABC):
 
         if not os.path.exists(folderpath):
             os.makedirs(folderpath, exist_ok=True)
-        filepath = '{}/hpc_ckpt_{}.ckpt'.format(folderpath, ckpt_number)
+        filepath = os.path.join(folderpath, f'hpc_ckpt_{ckpt_number}.ckpt')
 
         # give model a chance to do something on hpc_save
         model = self.get_model()
diff --git a/pytorch_lightning/trainer/training_loop.py b/pytorch_lightning/trainer/training_loop.py
index 6d12d6f..220cdef 100644
--- a/pytorch_lightning/trainer/training_loop.py
+++ b/pytorch_lightning/trainer/training_loop.py
@@ -25,37 +25,6 @@ It can be useful to force training for a minimum number of epochs or limit to a
     # DEFAULT
     trainer = Trainer(min_epochs=1, max_epochs=1000)
 
-Early stopping
---------------
-
-The trainer already sets up default early stopping for you.
-To modify this behavior, pass in your own EarlyStopping callback.
-
-.. code-block:: python
-
-    from pytorch_lightning.callbacks import EarlyStopping
-
-    # DEFAULTS used by Trainer
-    early_stop_callback = EarlyStopping(
-        monitor='val_loss',
-        min_delta=0.00,
-        patience=3,
-        verbose=False,
-        mode='min'
-    )
-
-    # without passing anything in, uses the default callback above
-    trainer = Trainer()
-
-    # pass in your own to override the default callback
-    trainer = Trainer(early_stop_callback=early_stop_callback)
-
-    # pass in min_epochs to enable the callback after min_epochs have run
-    trainer = Trainer(early_stop_callback=early_stop_callback, min_epochs=5)
-
-    # pass in None to disable it
-    trainer = Trainer(early_stop_callback=None)
-
 Force disable early stop
 ------------------------
 
@@ -114,7 +83,7 @@ Packed sequences as inputs
 
 When using PackedSequence, do 2 things:
 1. return either a padded tensor in dataset or a list of variable length tensors
- in the dataloader collate_fn (example above shows the list implementation).
+in the dataloader collate_fn (example above shows the list implementation).
 2. Pack the sequence in forward or training and validation steps depending on use case.
 
 .. code-block:: python
@@ -153,173 +122,182 @@ When this flag is enabled each batch is split into sequences of size truncated_b
 """
 
 import copy
+import logging as log
 import warnings
 from abc import ABC, abstractmethod
-import logging as log
+from typing import Callable
+from typing import Union, List
 
 import numpy as np
+from torch.utils.data import DataLoader
 
+from pytorch_lightning.callbacks.base import Callback
+from pytorch_lightning.core.lightning import LightningModule
+from pytorch_lightning.loggers import LightningLoggerBase
 from pytorch_lightning.utilities.debugging import MisconfigurationException
 
 try:
     from apex import amp
-
-    APEX_AVAILABLE = True
 except ImportError:
     APEX_AVAILABLE = False
+else:
+    APEX_AVAILABLE = True
 
 try:
+    import torch_xla.distributed.parallel_loader as xla_pl
     import torch_xla.core.xla_model as xm
-
-    XLA_AVAILABLE = True
 except ImportError:
     XLA_AVAILABLE = False
-
-try:
-    import torch_xla.distributed.parallel_loader as xla_pl
-
+else:
     XLA_AVAILABLE = True
 
-except ImportError:
-    XLA_AVAILABLE = False
-
 
 class TrainerTrainLoopMixin(ABC):
 
-    def __init__(self):
-        # this is just a summary on variables used in this abstract class,
-        #  the proper values/initialisation should be done in child class
-        self.max_epochs = None
-        self.min_epochs = None
-        self.use_ddp = None
-        self.use_dp = None
-        self.use_ddp2 = None
-        self.single_gpu = None
-        self.use_tpu = None
-        self.data_parallel_device_ids = None
-        self.check_val_every_n_epoch = None
-        self.num_training_batches = None
-        self.val_check_batch = None
-        self.num_val_batches = None
-        self.disable_validation = None
-        self.fast_dev_run = None
-        self.is_iterable_train_dataloader = None
-        self.main_progress_bar = None
-        self.accumulation_scheduler = None
-        self.lr_schedulers = None
-        self.enable_early_stop = None
-        self.early_stop_callback = None
-        self.callback_metrics = None
-        self.logger = None
-        self.global_step = None
-        self.testing = None
-        self.log_save_interval = None
-        self.proc_rank = None
-        self.row_log_interval = None
-        self.total_batches = None
-        self.truncated_bptt_steps = None
-        self.optimizers = None
-        self.accumulate_grad_batches = None
-        self.use_amp = None
-        self.print_nan_grads = None
-        self.track_grad_norm = None
-        self.model = None
-        self.running_loss = None
-        self.training_tqdm_dict = None
-        self.get_train_dataloader = None
-        self.reduce_lr_on_plateau_scheduler = None
-        self.profiler = None
-        self.batch_idx = None
-        self.precision = None
-
-    @property
-    def max_nb_epochs(self):
-        """
-        .. warning:: `max_nb_epochs` is deprecated and will be removed in v0.8.0, use `max_epochs` instead.
-        """
-        warnings.warn("`max_nb_epochs` is deprecated and will be removed in "
-                      "v0.8.0, use `max_epochs` instead.", DeprecationWarning)
-        return self.max_epochs
-
-    @property
-    def min_nb_epochs(self):
-        """
-        .. warning:: `min_nb_epochs` is deprecated and will be removed in v0.8.0, use `min_epochs` instead.
-        """
-        warnings.warn("`min_nb_epochs` is deprecated and will be removed in "
-                      "v0.8.0, use `min_epochs` instead.", DeprecationWarning)
-        return self.min_epochs
+    # this is just a summary on variables used in this abstract class,
+    #  the proper values/initialisation should be done in child class
+    max_epochs: int
+    min_epochs: int
+    use_ddp: bool
+    use_dp: bool
+    use_ddp2: bool
+    single_gpu: bool
+    use_tpu: bool
+    data_parallel_device_ids: ...
+    check_val_every_n_epoch: ...
+    num_training_batches: int
+    val_check_batch: ...
+    num_val_batches: int
+    disable_validation: bool
+    fast_dev_run: ...
+    main_progress_bar: ...
+    accumulation_scheduler: ...
+    lr_schedulers: ...
+    enable_early_stop: ...
+    early_stop_callback: ...
+    callback_metrics: ...
+    logger: Union[LightningLoggerBase, bool]
+    global_step: int
+    testing: bool
+    log_save_interval: float
+    proc_rank: int
+    row_log_interval: float
+    total_batches: int
+    truncated_bptt_steps: ...
+    optimizers: ...
+    accumulate_grad_batches: int
+    use_amp: bool
+    print_nan_grads: ...
+    track_grad_norm: ...
+    model: LightningModule
+    running_loss: ...
+    training_tqdm_dict: ...
+    reduce_lr_on_plateau_scheduler: ...
+    profiler: ...
+    batch_idx: int
+    precision: ...
+    train_dataloader: DataLoader
+    reload_dataloaders_every_epoch: bool
+    progress_bar_refresh_rate: ...
+    max_steps: int
+    max_steps: int
+    total_batch_idx: int
+    checkpoint_callback: ...
+
+    # Callback system
+    callbacks: List[Callback]
+    on_train_start: Callable
+    on_train_end: Callable
+    on_batch_start: Callable
+    on_batch_end: Callable
+    on_epoch_start: Callable
+    on_epoch_end: Callable
+    on_validation_end: Callable
 
     @abstractmethod
     def get_model(self):
-        # this is just empty shell for code from other class
-        pass
+        """Warning: this is just empty shell for code implemented in other class."""
 
     @abstractmethod
-    def is_function_implemented(self, m):
-        # this is just empty shell for code from other class
-        pass
+    def is_function_implemented(self, *args):
+        """Warning: this is just empty shell for code implemented in other class."""
 
     @abstractmethod
-    def run_evaluation(self, test):
-        # this is just empty shell for code from other class
-        pass
+    def run_evaluation(self, *args):
+        """Warning: this is just empty shell for code implemented in other class."""
 
     @abstractmethod
-    def transfer_batch_to_gpu(self, batch, gpu):
-        # this is just empty shell for code from other class
-        pass
+    def transfer_batch_to_gpu(self, *args):
+        """Warning: this is just empty shell for code implemented in other class."""
 
     @abstractmethod
-    def transfer_batch_to_tpu(self, batch):
-        # this is just empty shell for code from other class
-        pass
+    def transfer_batch_to_tpu(self, *args):
+        """Warning: this is just empty shell for code implemented in other class."""
 
     @abstractmethod
     def clip_gradients(self):
-        # this is just empty shell for code from other class
-        pass
+        """Warning: this is just empty shell for code implemented in other class."""
 
     @abstractmethod
     def print_nan_gradients(self):
-        # this is just empty shell for code from other class
-        pass
+        """Warning: this is just empty shell for code implemented in other class."""
+
+    @abstractmethod
+    def is_overriden(self, *args):
+        """Warning: this is just empty shell for code implemented in other class."""
+
+    @abstractmethod
+    def add_tqdm_metrics(self, *args):
+        """Warning: this is just empty shell for code implemented in other class."""
+
+    @abstractmethod
+    def log_metrics(self, *args):
+        """Warning: this is just empty shell for code implemented in other class."""
 
     @abstractmethod
-    def is_overriden(self, m):
-        # this is just empty shell for code from other class
-        pass
+    def process_output(self, *args):
+        """Warning: this is just empty shell for code implemented in other class."""
 
     @abstractmethod
-    def add_tqdm_metrics(self, metrics):
-        # this is just empty shell for code from other class
-        pass
+    def reset_train_dataloader(self, *args):
+        """Warning: this is just empty shell for code implemented in other class."""
 
     @abstractmethod
-    def log_metrics(self, metrics, grad_norm_dic):
-        # this is just empty shell for code from other class
-        pass
+    def reset_val_dataloader(self, model):
+        """Warning: this is just empty shell for code implemented in other class."""
 
     @abstractmethod
-    def process_output(self, output, train):
-        # this is just empty shell for code from other class
-        pass
+    def has_arg(self, *args):
+        """Warning: this is just empty shell for code implemented in other class."""
 
     def train(self):
         warnings.warn('Displayed epoch numbers in the progress bar start from "1" until v0.6.x,'
                       ' but will start from "0" in v0.8.0.', DeprecationWarning)
+
         # get model
         model = self.get_model()
+
+        # load data
+        self.reset_train_dataloader(model)
+        self.reset_val_dataloader(model)
+
+        # Train start events
+        with self.profiler.profile('on_train_start'):
+            # callbacks
+            self.on_train_start()
+            # initialize early stop callback
+            if self.early_stop_callback is not None:
+                self.early_stop_callback.on_train_start(self, self.get_model())
+            # model hooks
+            model.on_train_start()
+
         try:
             # run all epochs
             for epoch in range(self.current_epoch, self.max_epochs):
                 # set seed for distributed sampler (enables shuffling for each epoch)
-                if (self.use_ddp or self.use_tpu) \
-                        and hasattr(self.get_train_dataloader().sampler, 'set_epoch'):
-                    self.get_train_dataloader().sampler.set_epoch(epoch)
-
-                # get model
-                model = self.get_model()
+                if self.use_ddp \
+                        and hasattr(self.train_dataloader.sampler, 'set_epoch'):
+                    self.train_dataloader.sampler.set_epoch(epoch)
 
                 # update training progress in trainer and model
                 model.current_epoch = epoch
@@ -327,7 +305,7 @@ class TrainerTrainLoopMixin(ABC):
 
                 total_val_batches = 0
                 is_val_epoch = False
-                if not self.disable_validation:
+                if not self.disable_validation and self.num_training_batches != float('inf'):
                     # val can be checked multiple times in epoch
                     is_val_epoch = (self.current_epoch + 1) % self.check_val_every_n_epoch == 0
                     val_checks_per_epoch = self.num_training_batches // self.val_check_batch
@@ -341,8 +319,8 @@ class TrainerTrainLoopMixin(ABC):
                 if self.fast_dev_run:
                     # limit the number of batches to 2 (1 train and 1 val) in fast_dev_run
                     num_iterations = 2
-                elif self.is_iterable_train_dataloader:
-                    # for iterable train loader, the progress bar never ends
+                elif self.total_batches == float('inf'):
+                    # for infinite train or val loader, the progress bar never ends
                     num_iterations = None
                 else:
                     num_iterations = self.total_batches
@@ -351,62 +329,59 @@ class TrainerTrainLoopMixin(ABC):
                 # .reset() doesn't work on disabled progress bar so we should check
                 if not self.main_progress_bar.disable:
                     self.main_progress_bar.reset(num_iterations)
-                desc = f'Epoch {epoch + 1}' if not self.is_iterable_train_dataloader else ''
+                desc = f'Epoch {epoch + 1}'
                 self.main_progress_bar.set_description(desc)
 
-                # changing gradient according accumulation_scheduler
-                self.accumulation_scheduler.on_epoch_begin()
-
                 # -----------------
                 # RUN TNG EPOCH
                 # -----------------
                 self.run_training_epoch()
 
                 # update LR schedulers
-                if self.lr_schedulers is not None:
-                    for lr_scheduler in self.lr_schedulers:
-                        lr_scheduler.step()
-                if self.reduce_lr_on_plateau_scheduler is not None:
-                    val_loss = self.callback_metrics.get('val_loss')
-                    if val_loss is None:
-                        avail_metrics = ','.join(list(self.callback_metrics.keys()))
-                        m = f'ReduceLROnPlateau conditioned on metric val_loss ' \
-                            f'which is not available. Available metrics are: {avail_metrics}'
-                        raise MisconfigurationException(m)
-                    self.reduce_lr_on_plateau_scheduler.step(val_loss)
+                self.update_learning_rates(interval='epoch')
 
                 if self.max_steps and self.max_steps == self.global_step:
-                    self.main_progress_bar.close()
-                    model.on_train_end()
+                    self.run_training_teardown()
                     return
 
                 # early stopping
                 met_min_epochs = epoch >= self.min_epochs - 1
                 met_min_steps = self.global_step >= self.min_steps if self.min_steps else True
 
-                if (self.enable_early_stop and not self.disable_validation and is_val_epoch and
-                        ((met_min_epochs and met_min_steps) or self.fast_dev_run)):
-                    should_stop = self.early_stop_callback.on_epoch_end()
-                    # stop training
-                    stop = should_stop and met_min_epochs
-                    if stop:
-                        self.run_training_teardown()
-                        return
+                # TODO wrap this logic into the callback
+                if self.enable_early_stop and not self.disable_validation and is_val_epoch:
+                    if ((met_min_epochs and met_min_steps) or self.fast_dev_run):
+                        should_stop = self.early_stop_callback.on_epoch_end(self, self.get_model())
+                        # stop training
+                        stop = should_stop and met_min_epochs
+                        if stop:
+                            self.run_training_teardown()
+                            return
 
             self.run_training_teardown()
+
         except KeyboardInterrupt:
             log.info('Detected KeyboardInterrupt, attempting graceful shutdown...')
             self.run_training_teardown()
 
     def run_training_epoch(self):
-        # before epoch hook
-        if self.is_function_implemented('on_epoch_start'):
-            model = self.get_model()
-            with self.profiler.profile('on_epoch_start'):
-                model.on_epoch_start()
 
-        # request the dataloader
-        train_dataloader = self.get_train_dataloader()
+        # Epoch start events
+        with self.profiler.profile('on_epoch_start'):
+            # callbacks
+            self.on_epoch_start()
+            # changing gradient according accumulation_scheduler
+            self.accumulation_scheduler.on_epoch_start(self, self.get_model())
+            # model hooks
+            if self.is_function_implemented('on_epoch_start'):
+                self.get_model().on_epoch_start()
+
+        # reset train dataloader
+        if self.reload_dataloaders_every_epoch:
+            self.reset_train_dataloader(self.get_model())
+
+        # track local dataloader so TPU can wrap each epoch
+        train_dataloader = self.train_dataloader
 
         # on TPU we have to wrap it under the ParallelLoader
         if self.use_tpu:
@@ -436,20 +411,20 @@ class TrainerTrainLoopMixin(ABC):
             # when returning -1 from train_step, we end epoch early
             early_stop_epoch = batch_result == -1
 
+            # update lr
+            self.update_learning_rates(interval='step')
+
             # ---------------
             # RUN VAL STEP
             # ---------------
             is_val_check_batch = (batch_idx + 1) % self.val_check_batch == 0
             can_check_epoch = (self.current_epoch + 1) % self.check_val_every_n_epoch == 0
-            should_check_val = (not self.disable_validation and can_check_epoch and
-                                (is_val_check_batch or early_stop_epoch))
+            should_check_val = not self.disable_validation and can_check_epoch
+            should_check_val = should_check_val and (is_val_check_batch or early_stop_epoch)
 
             # fast_dev_run always forces val checking after train batch
             if self.fast_dev_run or should_check_val:
-                self.run_evaluation(test=self.testing)
-
-                if self.enable_early_stop:
-                    self.early_stop_callback.check_metrics(self.callback_metrics)
+                self.run_evaluation(test_mode=self.testing)
 
             # when logs should be saved
             should_save_log = (batch_idx + 1) % self.log_save_interval == 0 or early_stop_epoch
@@ -463,6 +438,17 @@ class TrainerTrainLoopMixin(ABC):
                 # logs user requested information to logger
                 self.log_metrics(batch_step_metrics, grad_norm_dic)
 
+            # ---------------
+            # CHECKPOINTING, EARLY STOPPING
+            # ---------------
+            # save checkpoint even when no test or val step are defined
+            train_step_only = not self.is_overriden('validation_step')
+            if self.fast_dev_run or should_check_val or train_step_only:
+                self.call_checkpoint_callback()
+
+                if self.enable_early_stop:
+                    self.early_stop_callback.check_metrics(self.callback_metrics)
+
             # progress global step according to grads progress
             if (self.batch_idx + 1) % self.accumulate_grad_batches == 0:
                 self.global_step += 1
@@ -478,11 +464,13 @@ class TrainerTrainLoopMixin(ABC):
             if early_stop_epoch or self.fast_dev_run:
                 break
 
-        # epoch end hook
-        if self.is_function_implemented('on_epoch_end'):
-            model = self.get_model()
-            with self.profiler.profile('on_epoch_end'):
-                model.on_epoch_end()
+        # Epoch end events
+        with self.profiler.profile('on_epoch_end'):
+            # callbacks
+            self.on_epoch_end()
+            # model hooks
+            if self.is_function_implemented('on_epoch_end'):
+                self.get_model().on_epoch_end()
 
     def run_training_batch(self, batch, batch_idx):
         # track grad norms
@@ -497,14 +485,15 @@ class TrainerTrainLoopMixin(ABC):
         if batch is None:
             return 0, grad_norm_dic, {}
 
-        # hook
-        if self.is_function_implemented('on_batch_start'):
-            model_ref = self.get_model()
-            with self.profiler.profile('on_batch_start'):
-                response = model_ref.on_batch_start(batch)
-
-            if response == -1:
-                return -1, grad_norm_dic, {}
+        # Batch start events
+        with self.profiler.profile('on_batch_start'):
+            # callbacks
+            self.on_batch_start()
+            # hooks
+            if self.is_function_implemented('on_batch_start'):
+                response = self.get_model().on_batch_start(batch)
+                if response == -1:
+                    return -1, grad_norm_dic, {}
 
         splits = [batch]
         if self.truncated_bptt_steps is not None:
@@ -591,26 +580,26 @@ class TrainerTrainLoopMixin(ABC):
                     # override function to modify this behavior
                     model = self.get_model()
                     with self.profiler.profile('optimizer_step'):
-                        if self.use_tpu:
-                            xm.optimizer_step(optimizer)
-                        else:
-                            model.optimizer_step(self.current_epoch, batch_idx,
-                                                 optimizer, opt_idx, optimizer_closure)
+                        model.optimizer_step(self.current_epoch, batch_idx,
+                                             optimizer, opt_idx, optimizer_closure)
 
                     # calculate running loss for display
                     self.running_loss.append(self.batch_loss_value)
                     self.batch_loss_value = 0
                     self.avg_loss = np.mean(self.running_loss[-100:])
 
-        # activate batch end hook
-        if self.is_function_implemented('on_batch_end'):
-            model = self.get_model()
-            with self.profiler.profile('on_batch_end'):
-                model.on_batch_end()
+        # Batch end events
+        with self.profiler.profile('on_batch_end'):
+            # callbacks
+            self.on_batch_end()
+            # model hooks
+            if self.is_function_implemented('on_batch_end'):
+                self.get_model().on_batch_end()
 
         # update progress bar
-        self.main_progress_bar.update(1)
-        self.main_progress_bar.set_postfix(**self.training_tqdm_dict)
+        if batch_idx % self.progress_bar_refresh_rate == 0:
+            self.main_progress_bar.update(self.progress_bar_refresh_rate)
+            self.main_progress_bar.set_postfix(**self.training_tqdm_dict)
 
         # collapse all metrics into one dict
         all_log_metrics = {k: v for d in all_log_metrics for k, v in d.items()}
@@ -621,12 +610,15 @@ class TrainerTrainLoopMixin(ABC):
         return 0, grad_norm_dic, all_log_metrics
 
     def run_training_teardown(self):
-        model = self.get_model()
-
         self.main_progress_bar.close()
 
+        # Train end events
         with self.profiler.profile('on_train_end'):
-            model.on_train_end()
+            # callbacks
+            self.on_train_end()
+            # model hooks
+            if self.is_function_implemented('on_train_end'):
+                self.get_model().on_train_end()
 
         if self.logger is not None:
             self.logger.finalize("success")
@@ -651,8 +643,9 @@ class TrainerTrainLoopMixin(ABC):
             if self.has_arg('training_step', 'optimizer_idx'):
                 args.append(opt_idx)
             else:
+                num_opts = len(self.optimizers)
                 raise ValueError(
-                    f'Your LightningModule defines {len(self.optimizers)} optimizers but '
+                    f'Your LightningModule defines {num_opts} optimizers but '
                     f'training_step is missing the "optimizer_idx" argument.'
                 )
 
@@ -683,13 +676,58 @@ class TrainerTrainLoopMixin(ABC):
         else:
             output = self.model.training_step(*args)
 
+        # allow any mode to define training_step_end
+        # do something will all the dp outputs (like softmax)
+        if self.is_overriden('training_step_end'):
+            model_ref = self.get_model()
+            with self.profiler.profile('training_step_end'):
+                output = model_ref.training_step_end(output)
+
         # allow any mode to define training_end
+        # TODO: remove in 1.0.0
         if self.is_overriden('training_end'):
             model_ref = self.get_model()
             with self.profiler.profile('training_end'):
                 output = model_ref.training_end(output)
 
+            m = 'training_end was deprecated in 0.7.0 and will be removed 1.0.0. ' \
+                'Use training_epoch_end instead'
+            warnings.warn(m, DeprecationWarning)
+
         # format and reduce outputs accordingly
         output = self.process_output(output, train=True)
 
         return output
+
+    def update_learning_rates(self, interval):
+        ''' Update learning rates
+        Args:
+            interval (str): either 'epoch' or 'step'.
+        '''
+        if not self.lr_schedulers:
+            return
+
+        for lr_scheduler in self.lr_schedulers:
+            current_idx = self.batch_idx if interval == 'step' else self.current_epoch
+            current_idx += 1  # account for both batch and epoch starts from 0
+            # Take step if call to update_learning_rates matches the interval key and
+            # the current step modulo the schedulers frequency is zero
+            if lr_scheduler['interval'] == interval and current_idx % lr_scheduler['frequency'] == 0:
+                # If instance of ReduceLROnPlateau, we need to pass validation loss
+                if lr_scheduler['reduce_on_plateau']:
+                    monitor_key = lr_scheduler['monitor']
+                    monitor_val = self.callback_metrics.get(monitor_key)
+                    if monitor_val is None:
+                        avail_metrics = ','.join(list(self.callback_metrics.keys()))
+                        m = f'ReduceLROnPlateau conditioned on metric {monitor_key} ' \
+                            f'which is not available. Available metrics are: {avail_metrics}. ' \
+                            'Condition can be set using `monitor` key in lr scheduler dict'
+                        raise MisconfigurationException(m)
+                    lr_scheduler['scheduler'].step(monitor_val)
+                else:
+                    lr_scheduler['scheduler'].step()
+
+    def call_checkpoint_callback(self):
+        if self.checkpoint_callback is not None:
+            self.checkpoint_callback.on_validation_end(self, self.get_model())
+        self.on_validation_end()
diff --git a/pytorch_lightning/trainer/training_tricks.py b/pytorch_lightning/trainer/training_tricks.py
index c62c6f3..304e720 100644
--- a/pytorch_lightning/trainer/training_tricks.py
+++ b/pytorch_lightning/trainer/training_tricks.py
@@ -1,27 +1,49 @@
 import logging as log
+import math
 from abc import ABC, abstractmethod
 
 import torch
 
 from pytorch_lightning.callbacks import GradientAccumulationScheduler
 
+EPSILON = 1e-6
+EPSILON_FP16 = 1e-5
+
 
 class TrainerTrainingTricksMixin(ABC):
 
-    def __init__(self):
-        # this is just a summary on variables used in this abstract class,
-        #  the proper values/initialisation should be done in child class
-        self.gradient_clip_val = None
+    # this is just a summary on variables used in this abstract class,
+    #  the proper values/initialisation should be done in child class
+    gradient_clip_val: ...
 
     @abstractmethod
     def get_model(self):
-        # this is just empty shell for code from other class
-        pass
+        """Warning: this is just empty shell for code implemented in other class."""
 
     def clip_gradients(self):
+        # this code is a modification of torch.nn.utils.clip_grad_norm_
+        # with TPU support based on https://github.com/pytorch/xla/blob/master/TROUBLESHOOTING.md
         if self.gradient_clip_val > 0:
             model = self.get_model()
-            torch.nn.utils.clip_grad_norm_(model.parameters(), self.gradient_clip_val)
+            parameters = model.parameters()
+            max_norm = float(self.gradient_clip_val)
+            norm_type = float(2.0)
+            if isinstance(parameters, torch.Tensor):
+                parameters = [parameters]
+            parameters = list(filter(lambda p: p.grad is not None, parameters))
+            if norm_type == math.inf:
+                total_norm = max(p.grad.data.abs().max() for p in parameters)
+            else:
+                device = parameters[0].device
+                total_norm = torch.zeros([], device=device if parameters else None)
+                for p in parameters:
+                    param_norm = p.grad.data.norm(norm_type) ** norm_type
+                total_norm.add_(param_norm)
+                total_norm = (total_norm ** (1. / norm_type))
+            eps = EPSILON_FP16 if self.precision == 16 else EPSILON
+            clip_coef = torch.tensor(max_norm, device=device) / (total_norm + eps)
+            for p in parameters:
+                p.grad.data.mul_(torch.where(clip_coef < 1, clip_coef, torch.tensor(1., device=device)))
 
     def print_nan_gradients(self):
         model = self.get_model()
@@ -30,8 +52,6 @@ class TrainerTrainingTricksMixin(ABC):
                 log.info(param, param.grad)
 
     def configure_accumulated_gradients(self, accumulate_grad_batches):
-        self.accumulate_grad_batches = None
-
         if isinstance(accumulate_grad_batches, dict):
             self.accumulation_scheduler = GradientAccumulationScheduler(accumulate_grad_batches)
         elif isinstance(accumulate_grad_batches, int):
@@ -39,5 +59,3 @@ class TrainerTrainingTricksMixin(ABC):
             self.accumulation_scheduler = GradientAccumulationScheduler(schedule)
         else:
             raise TypeError("Gradient accumulation supports only int and dict types")
-
-        self.accumulation_scheduler.set_trainer(self)
diff --git a/tests/README.md b/tests/README.md
index 183e9c2..8835ab9 100644
--- a/tests/README.md
+++ b/tests/README.md
@@ -17,7 +17,7 @@ cd pytorch-lightning
 pip install -e .
 
 # install dev deps
-pip install -r requirements.txt
+pip install -r tests/requirements.txt
 
 # run tests
 py.test -v
@@ -35,7 +35,7 @@ Make sure to run coverage on a GPU machine with at least 2 GPUs and NVIDIA apex
 ```bash
 cd pytorch-lightning
 
-# generate coverage 
+# generate coverage (coverage is also installed as part of dev dependencies under tests/requirements.txt)
 pip install coverage
 coverage run --source pytorch_lightning -m py.test pytorch_lightning tests examples -v --doctest-modules
 
diff --git a/tests/loggers/__init__.py b/tests/loggers/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/tests/loggers/test_base.py b/tests/loggers/test_base.py
new file mode 100644
index 0000000..4e4ba58
--- /dev/null
+++ b/tests/loggers/test_base.py
@@ -0,0 +1,151 @@
+import pickle
+from unittest.mock import MagicMock
+
+import tests.models.utils as tutils
+from pytorch_lightning import Trainer
+from pytorch_lightning.loggers import LightningLoggerBase, rank_zero_only, LoggerCollection
+from tests.models import LightningTestModel
+
+
+def test_logger_collection():
+    mock1 = MagicMock()
+    mock2 = MagicMock()
+
+    logger = LoggerCollection([mock1, mock2])
+
+    assert logger[0] == mock1
+    assert logger[1] == mock2
+
+    assert logger.experiment[0] == mock1.experiment
+    assert logger.experiment[1] == mock2.experiment
+
+    logger.close()
+    mock1.close.assert_called_once()
+    mock2.close.assert_called_once()
+
+
+class CustomLogger(LightningLoggerBase):
+    def __init__(self):
+        super().__init__()
+        self.hparams_logged = None
+        self.metrics_logged = None
+        self.finalized = False
+
+    @property
+    def experiment(self):
+        return 'test'
+
+    @rank_zero_only
+    def log_hyperparams(self, params):
+        self.hparams_logged = params
+
+    @rank_zero_only
+    def log_metrics(self, metrics, step):
+        self.metrics_logged = metrics
+
+    @rank_zero_only
+    def finalize(self, status):
+        self.finalized_status = status
+
+    @property
+    def name(self):
+        return "name"
+
+    @property
+    def version(self):
+        return "1"
+
+
+def test_custom_logger(tmpdir):
+    hparams = tutils.get_hparams()
+    model = LightningTestModel(hparams)
+
+    logger = CustomLogger()
+
+    trainer_options = dict(
+        max_epochs=1,
+        train_percent_check=0.05,
+        logger=logger,
+        default_save_path=tmpdir
+    )
+
+    trainer = Trainer(**trainer_options)
+    result = trainer.fit(model)
+    assert result == 1, "Training failed"
+    assert logger.hparams_logged == hparams
+    assert logger.metrics_logged != {}
+    assert logger.finalized_status == "success"
+
+
+def test_multiple_loggers(tmpdir):
+    hparams = tutils.get_hparams()
+    model = LightningTestModel(hparams)
+
+    logger1 = CustomLogger()
+    logger2 = CustomLogger()
+
+    trainer_options = dict(
+        max_epochs=1,
+        train_percent_check=0.05,
+        logger=[logger1, logger2],
+        default_save_path=tmpdir
+    )
+
+    trainer = Trainer(**trainer_options)
+    result = trainer.fit(model)
+    assert result == 1, "Training failed"
+
+    assert logger1.hparams_logged == hparams
+    assert logger1.metrics_logged != {}
+    assert logger1.finalized_status == "success"
+
+    assert logger2.hparams_logged == hparams
+    assert logger2.metrics_logged != {}
+    assert logger2.finalized_status == "success"
+
+
+def test_multiple_loggers_pickle(tmpdir):
+    """Verify that pickling trainer with multiple loggers works."""
+
+    logger1 = CustomLogger()
+    logger2 = CustomLogger()
+
+    trainer_options = dict(max_epochs=1, logger=[logger1, logger2])
+
+    trainer = Trainer(**trainer_options)
+    pkl_bytes = pickle.dumps(trainer)
+    trainer2 = pickle.loads(pkl_bytes)
+    trainer2.logger.log_metrics({"acc": 1.0}, 0)
+
+    assert logger1.metrics_logged != {}
+    assert logger2.metrics_logged != {}
+
+
+def test_adding_step_key(tmpdir):
+    logged_step = 0
+
+    def _validation_end(outputs):
+        nonlocal logged_step
+        logged_step += 1
+        return {"log": {"step": logged_step, "val_acc": logged_step / 10}}
+
+    def _log_metrics_decorator(log_metrics_fn):
+        def decorated(metrics, step):
+            if "val_acc" in metrics:
+                assert step == logged_step
+            return log_metrics_fn(metrics, step)
+
+        return decorated
+
+    model, hparams = tutils.get_model()
+    model.validation_end = _validation_end
+    trainer_options = dict(
+        max_epochs=4,
+        default_save_path=tmpdir,
+        train_percent_check=0.001,
+        val_percent_check=0.01,
+        num_sanity_val_steps=0
+    )
+    trainer = Trainer(**trainer_options)
+    trainer.logger.log_metrics = _log_metrics_decorator(trainer.logger.log_metrics)
+    trainer.fit(model)
diff --git a/tests/loggers/test_comet.py b/tests/loggers/test_comet.py
new file mode 100644
index 0000000..69f434c
--- /dev/null
+++ b/tests/loggers/test_comet.py
@@ -0,0 +1,156 @@
+import os
+import pickle
+from unittest.mock import patch
+
+import pytest
+import torch
+
+import tests.models.utils as tutils
+from pytorch_lightning import Trainer
+from pytorch_lightning.loggers import CometLogger
+from pytorch_lightning.utilities.debugging import MisconfigurationException
+from tests.models import LightningTestModel
+
+
+def test_comet_logger(tmpdir, monkeypatch):
+    """Verify that basic functionality of Comet.ml logger works."""
+
+    # prevent comet logger from trying to print at exit, since
+    # pytest's stdout/stderr redirection breaks it
+    import atexit
+    monkeypatch.setattr(atexit, 'register', lambda _: None)
+
+    tutils.reset_seed()
+
+    hparams = tutils.get_hparams()
+    model = LightningTestModel(hparams)
+
+    comet_dir = os.path.join(tmpdir, 'cometruns')
+
+    # We test CometLogger in offline mode with local saves
+    logger = CometLogger(
+        save_dir=comet_dir,
+        project_name='general',
+        workspace='dummy-test',
+    )
+
+    trainer_options = dict(
+        default_save_path=tmpdir,
+        max_epochs=1,
+        train_percent_check=0.05,
+        logger=logger
+    )
+
+    trainer = Trainer(**trainer_options)
+    result = trainer.fit(model)
+    trainer.logger.log_metrics({'acc': torch.ones(1)})
+
+    assert result == 1, 'Training failed'
+
+
+def test_comet_logger_online():
+    """Test comet online with mocks."""
+    # Test api_key given
+    with patch('pytorch_lightning.loggers.comet.CometExperiment') as comet:
+        logger = CometLogger(
+            api_key='key',
+            workspace='dummy-test',
+            project_name='general'
+        )
+
+        _ = logger.experiment
+
+        comet.assert_called_once_with(
+            api_key='key',
+            workspace='dummy-test',
+            project_name='general'
+        )
+
+    # Test both given
+    with patch('pytorch_lightning.loggers.comet.CometExperiment') as comet:
+        logger = CometLogger(
+            save_dir='test',
+            api_key='key',
+            workspace='dummy-test',
+            project_name='general'
+        )
+
+        _ = logger.experiment
+
+        comet.assert_called_once_with(
+            api_key='key',
+            workspace='dummy-test',
+            project_name='general'
+        )
+
+    # Test neither given
+    with pytest.raises(MisconfigurationException):
+        CometLogger(
+            workspace='dummy-test',
+            project_name='general'
+        )
+
+    # Test already exists
+    with patch('pytorch_lightning.loggers.comet.CometExistingExperiment') as comet_existing:
+        logger = CometLogger(
+            experiment_key='test',
+            experiment_name='experiment',
+            api_key='key',
+            workspace='dummy-test',
+            project_name='general'
+        )
+
+        _ = logger.experiment
+
+        comet_existing.assert_called_once_with(
+            api_key='key',
+            workspace='dummy-test',
+            project_name='general',
+            previous_experiment='test'
+        )
+
+        comet_existing().set_name.assert_called_once_with('experiment')
+
+    with patch('pytorch_lightning.loggers.comet.API') as api:
+        CometLogger(
+            api_key='key',
+            workspace='dummy-test',
+            project_name='general',
+            rest_api_key='rest'
+        )
+
+        api.assert_called_once_with('rest')
+
+
+def test_comet_pickle(tmpdir, monkeypatch):
+    """Verify that pickling trainer with comet logger works."""
+
+    # prevent comet logger from trying to print at exit, since
+    # pytest's stdout/stderr redirection breaks it
+    import atexit
+    monkeypatch.setattr(atexit, 'register', lambda _: None)
+
+    tutils.reset_seed()
+
+    # hparams = tutils.get_hparams()
+    # model = LightningTestModel(hparams)
+
+    comet_dir = os.path.join(tmpdir, 'cometruns')
+
+    # We test CometLogger in offline mode with local saves
+    logger = CometLogger(
+        save_dir=comet_dir,
+        project_name='general',
+        workspace='dummy-test',
+    )
+
+    trainer_options = dict(
+        default_save_path=tmpdir,
+        max_epochs=1,
+        logger=logger
+    )
+
+    trainer = Trainer(**trainer_options)
+    pkl_bytes = pickle.dumps(trainer)
+    trainer2 = pickle.loads(pkl_bytes)
+    trainer2.logger.log_metrics({'acc': 1.0})
diff --git a/tests/loggers/test_mlflow.py b/tests/loggers/test_mlflow.py
new file mode 100644
index 0000000..6e49a9f
--- /dev/null
+++ b/tests/loggers/test_mlflow.py
@@ -0,0 +1,54 @@
+import os
+import pickle
+
+import tests.models.utils as tutils
+from pytorch_lightning import Trainer
+from pytorch_lightning.loggers import MLFlowLogger
+from tests.models import LightningTestModel
+
+
+def test_mlflow_logger(tmpdir):
+    """Verify that basic functionality of mlflow logger works."""
+    tutils.reset_seed()
+
+    hparams = tutils.get_hparams()
+    model = LightningTestModel(hparams)
+
+    mlflow_dir = os.path.join(tmpdir, 'mlruns')
+    logger = MLFlowLogger('test', tracking_uri=f'file:{os.sep * 2}{mlflow_dir}')
+
+    # Test already exists
+    logger2 = MLFlowLogger('test', tracking_uri=f'file:{os.sep * 2}{mlflow_dir}')
+    _ = logger2.run_id
+
+    # Try logging string
+    logger.log_metrics({'acc': 'test'})
+
+    trainer_options = dict(
+        default_save_path=tmpdir,
+        max_epochs=1,
+        train_percent_check=0.05,
+        logger=logger
+    )
+    trainer = Trainer(**trainer_options)
+    result = trainer.fit(model)
+
+    assert result == 1, 'Training failed'
+
+
+def test_mlflow_pickle(tmpdir):
+    """Verify that pickling trainer with mlflow logger works."""
+    tutils.reset_seed()
+
+    mlflow_dir = os.path.join(tmpdir, 'mlruns')
+    logger = MLFlowLogger('test', tracking_uri=f'file:{os.sep * 2}{mlflow_dir}')
+    trainer_options = dict(
+        default_save_path=tmpdir,
+        max_epochs=1,
+        logger=logger
+    )
+
+    trainer = Trainer(**trainer_options)
+    pkl_bytes = pickle.dumps(trainer)
+    trainer2 = pickle.loads(pkl_bytes)
+    trainer2.logger.log_metrics({'acc': 1.0})
diff --git a/tests/loggers/test_neptune.py b/tests/loggers/test_neptune.py
new file mode 100644
index 0000000..6130bfb
--- /dev/null
+++ b/tests/loggers/test_neptune.py
@@ -0,0 +1,98 @@
+import pickle
+from unittest.mock import patch
+
+import torch
+
+import tests.models.utils as tutils
+from pytorch_lightning import Trainer
+from pytorch_lightning.loggers import NeptuneLogger
+from tests.models import LightningTestModel
+
+
+def test_neptune_logger(tmpdir):
+    """Verify that basic functionality of neptune logger works."""
+    tutils.reset_seed()
+
+    hparams = tutils.get_hparams()
+    model = LightningTestModel(hparams)
+    logger = NeptuneLogger(offline_mode=True)
+
+    trainer_options = dict(
+        default_save_path=tmpdir,
+        max_epochs=1,
+        train_percent_check=0.05,
+        logger=logger
+    )
+    trainer = Trainer(**trainer_options)
+    result = trainer.fit(model)
+
+    assert result == 1, 'Training failed'
+
+
+@patch('pytorch_lightning.loggers.neptune.neptune')
+def test_neptune_online(neptune):
+    logger = NeptuneLogger(api_key='test', project_name='project')
+    neptune.init.assert_called_once_with(api_token='test', project_qualified_name='project')
+
+    assert logger.name == neptune.create_experiment().name
+    assert logger.version == neptune.create_experiment().id
+
+
+@patch('pytorch_lightning.loggers.neptune.neptune')
+def test_neptune_additional_methods(neptune):
+    logger = NeptuneLogger(offline_mode=True)
+
+    logger.log_metric('test', torch.ones(1))
+    neptune.create_experiment().log_metric.assert_called_once_with('test', torch.ones(1))
+    neptune.create_experiment().log_metric.reset_mock()
+
+    logger.log_metric('test', 1.0)
+    neptune.create_experiment().log_metric.assert_called_once_with('test', 1.0)
+    neptune.create_experiment().log_metric.reset_mock()
+
+    logger.log_metric('test', 1.0, step=2)
+    neptune.create_experiment().log_metric.assert_called_once_with('test', x=2, y=1.0)
+    neptune.create_experiment().log_metric.reset_mock()
+
+    logger.log_text('test', 'text')
+    neptune.create_experiment().log_metric.assert_called_once_with('test', 'text')
+    neptune.create_experiment().log_metric.reset_mock()
+
+    logger.log_image('test', 'image file')
+    neptune.create_experiment().log_image.assert_called_once_with('test', 'image file')
+    neptune.create_experiment().log_image.reset_mock()
+
+    logger.log_image('test', 'image file', step=2)
+    neptune.create_experiment().log_image.assert_called_once_with('test', x=2, y='image file')
+    neptune.create_experiment().log_image.reset_mock()
+
+    logger.log_artifact('file')
+    neptune.create_experiment().log_artifact.assert_called_once_with('file', None)
+
+    logger.set_property('property', 10)
+    neptune.create_experiment().set_property.assert_called_once_with('property', 10)
+
+    logger.append_tags('one tag')
+    neptune.create_experiment().append_tags.assert_called_once_with('one tag')
+    neptune.create_experiment().append_tags.reset_mock()
+
+    logger.append_tags(['two', 'tags'])
+    neptune.create_experiment().append_tags.assert_called_once_with('two', 'tags')
+
+
+def test_neptune_pickle(tmpdir):
+    """Verify that pickling trainer with neptune logger works."""
+    tutils.reset_seed()
+
+    logger = NeptuneLogger(offline_mode=True)
+
+    trainer_options = dict(
+        default_save_path=tmpdir,
+        max_epochs=1,
+        logger=logger
+    )
+
+    trainer = Trainer(**trainer_options)
+    pkl_bytes = pickle.dumps(trainer)
+    trainer2 = pickle.loads(pkl_bytes)
+    trainer2.logger.log_metrics({'acc': 1.0})
diff --git a/tests/loggers/test_tensorboard.py b/tests/loggers/test_tensorboard.py
new file mode 100644
index 0000000..c532e46
--- /dev/null
+++ b/tests/loggers/test_tensorboard.py
@@ -0,0 +1,114 @@
+import pickle
+
+import pytest
+import torch
+
+import tests.models.utils as tutils
+from pytorch_lightning import Trainer
+from pytorch_lightning.loggers import (
+    TensorBoardLogger
+)
+from tests.models import LightningTestModel
+
+
+def test_tensorboard_logger(tmpdir):
+    """Verify that basic functionality of Tensorboard logger works."""
+
+    hparams = tutils.get_hparams()
+    model = LightningTestModel(hparams)
+
+    logger = TensorBoardLogger(save_dir=tmpdir, name="tensorboard_logger_test")
+
+    trainer_options = dict(max_epochs=1, train_percent_check=0.01, logger=logger)
+
+    trainer = Trainer(**trainer_options)
+    result = trainer.fit(model)
+
+    print("result finished")
+    assert result == 1, "Training failed"
+
+
+def test_tensorboard_pickle(tmpdir):
+    """Verify that pickling trainer with Tensorboard logger works."""
+
+    logger = TensorBoardLogger(save_dir=tmpdir, name="tensorboard_pickle_test")
+
+    trainer_options = dict(max_epochs=1, logger=logger)
+
+    trainer = Trainer(**trainer_options)
+    pkl_bytes = pickle.dumps(trainer)
+    trainer2 = pickle.loads(pkl_bytes)
+    trainer2.logger.log_metrics({"acc": 1.0})
+
+
+def test_tensorboard_automatic_versioning(tmpdir):
+    """Verify that automatic versioning works"""
+
+    root_dir = tmpdir.mkdir("tb_versioning")
+    root_dir.mkdir("version_0")
+    root_dir.mkdir("version_1")
+
+    logger = TensorBoardLogger(save_dir=tmpdir, name="tb_versioning")
+
+    assert logger.version == 2
+
+
+def test_tensorboard_manual_versioning(tmpdir):
+    """Verify that manual versioning works"""
+
+    root_dir = tmpdir.mkdir("tb_versioning")
+    root_dir.mkdir("version_0")
+    root_dir.mkdir("version_1")
+    root_dir.mkdir("version_2")
+
+    logger = TensorBoardLogger(save_dir=tmpdir, name="tb_versioning", version=1)
+
+    assert logger.version == 1
+
+
+def test_tensorboard_named_version(tmpdir):
+    """Verify that manual versioning works for string versions, e.g. '2020-02-05-162402' """
+
+    tmpdir.mkdir("tb_versioning")
+    expected_version = "2020-02-05-162402"
+
+    logger = TensorBoardLogger(save_dir=tmpdir, name="tb_versioning", version=expected_version)
+    logger.log_hyperparams({"a": 1, "b": 2})  # Force data to be written
+
+    assert logger.version == expected_version
+    # Could also test existence of the directory but this fails
+    # in the "minimum requirements" test setup
+
+
+def test_tensorboard_no_name(tmpdir):
+    """Verify that None or empty name works"""
+
+    logger = TensorBoardLogger(save_dir=tmpdir, name="")
+    assert logger.root_dir == tmpdir
+
+    logger = TensorBoardLogger(save_dir=tmpdir, name=None)
+    assert logger.root_dir == tmpdir
+
+
+@pytest.mark.parametrize("step_idx", [10, None])
+def test_tensorboard_log_metrics(tmpdir, step_idx):
+    logger = TensorBoardLogger(tmpdir)
+    metrics = {
+        "float": 0.3,
+        "int": 1,
+        "FloatTensor": torch.tensor(0.1),
+        "IntTensor": torch.tensor(1)
+    }
+    logger.log_metrics(metrics, step_idx)
+
+
+def test_tensorboard_log_hyperparams(tmpdir):
+    logger = TensorBoardLogger(tmpdir)
+    hparams = {
+        "float": 0.3,
+        "int": 1,
+        "string": "abc",
+        "bool": True,
+        "dict": {'a': {'b': 'c'}}
+    }
+    logger.log_hyperparams(hparams)
diff --git a/tests/loggers/test_test_tube.py b/tests/loggers/test_test_tube.py
new file mode 100644
index 0000000..0788e0c
--- /dev/null
+++ b/tests/loggers/test_test_tube.py
@@ -0,0 +1,51 @@
+import pickle
+
+import tests.models.utils as tutils
+from pytorch_lightning import Trainer
+from tests.models import LightningTestModel
+
+
+def test_testtube_logger(tmpdir):
+    """Verify that basic functionality of test tube logger works."""
+    tutils.reset_seed()
+    hparams = tutils.get_hparams()
+    model = LightningTestModel(hparams)
+
+    logger = tutils.get_test_tube_logger(tmpdir, False)
+
+    assert logger.name == 'lightning_logs'
+
+    trainer_options = dict(
+        default_save_path=tmpdir,
+        max_epochs=1,
+        train_percent_check=0.05,
+        logger=logger
+    )
+
+    trainer = Trainer(**trainer_options)
+    result = trainer.fit(model)
+
+    assert result == 1, 'Training failed'
+
+
+def test_testtube_pickle(tmpdir):
+    """Verify that pickling a trainer containing a test tube logger works."""
+    tutils.reset_seed()
+
+    hparams = tutils.get_hparams()
+
+    logger = tutils.get_test_tube_logger(tmpdir, False)
+    logger.log_hyperparams(hparams)
+    logger.save()
+
+    trainer_options = dict(
+        default_save_path=tmpdir,
+        max_epochs=1,
+        train_percent_check=0.05,
+        logger=logger
+    )
+
+    trainer = Trainer(**trainer_options)
+    pkl_bytes = pickle.dumps(trainer)
+    trainer2 = pickle.loads(pkl_bytes)
+    trainer2.logger.log_metrics({'acc': 1.0})
diff --git a/tests/loggers/test_wandb.py b/tests/loggers/test_wandb.py
new file mode 100644
index 0000000..abb4954
--- /dev/null
+++ b/tests/loggers/test_wandb.py
@@ -0,0 +1,78 @@
+import os
+import pickle
+from unittest.mock import patch
+
+import pytest
+
+import tests.models.utils as tutils
+from pytorch_lightning import Trainer
+from pytorch_lightning.loggers import WandbLogger
+
+
+@patch('pytorch_lightning.loggers.wandb.wandb')
+def test_wandb_logger(wandb):
+    """Verify that basic functionality of wandb logger works.
+    Wandb doesn't work well with pytest so we have to mock it out here."""
+    tutils.reset_seed()
+
+    logger = WandbLogger(anonymous=True, offline=True)
+
+    logger.log_metrics({'acc': 1.0})
+    wandb.init().log.assert_called_once_with({'acc': 1.0})
+
+    wandb.init().log.reset_mock()
+    logger.log_metrics({'acc': 1.0}, step=3)
+    wandb.init().log.assert_called_once_with({'global_step': 3, 'acc': 1.0})
+
+    logger.log_hyperparams({'test': None})
+    wandb.init().config.update.assert_called_once_with({'test': None})
+
+    logger.watch('model', 'log', 10)
+    wandb.watch.assert_called_once_with('model', log='log', log_freq=10)
+
+    logger.finalize('fail')
+    wandb.join.assert_called_once_with(1)
+
+    wandb.join.reset_mock()
+    logger.finalize('success')
+    wandb.join.assert_called_once_with(0)
+
+    wandb.join.reset_mock()
+    wandb.join.side_effect = TypeError
+    with pytest.raises(TypeError):
+        logger.finalize('any')
+
+    wandb.join.assert_called()
+
+    assert logger.name == wandb.init().project_name()
+    assert logger.version == wandb.init().id
+
+
+@patch('pytorch_lightning.loggers.wandb.wandb')
+def test_wandb_pickle(wandb):
+    """Verify that pickling trainer with wandb logger works.
+    Wandb doesn't work well with pytest so we have to mock it out here."""
+    tutils.reset_seed()
+
+    class Experiment:
+        id = 'the_id'
+
+    wandb.init.return_value = Experiment()
+
+    logger = WandbLogger(id='the_id', offline=True)
+
+    trainer_options = dict(max_epochs=1, logger=logger)
+
+    trainer = Trainer(**trainer_options)
+    pkl_bytes = pickle.dumps(trainer)
+    trainer2 = pickle.loads(pkl_bytes)
+
+    assert os.environ['WANDB_MODE'] == 'dryrun'
+    assert trainer2.logger.__class__.__name__ == WandbLogger.__name__
+    _ = trainer2.logger.experiment
+
+    wandb.init.assert_called()
+    assert 'id' in wandb.init.call_args[1]
+    assert wandb.init.call_args[1]['id'] == 'the_id'
+
+    del os.environ['WANDB_MODE']
diff --git a/tests/models/__init__.py b/tests/models/__init__.py
index 3e6424b..4992e70 100644
--- a/tests/models/__init__.py
+++ b/tests/models/__init__.py
@@ -2,23 +2,55 @@
 
 import torch
 
-from .base import LightningTestModelBase, LightningTestModelBaseWithoutDataloader
+from .base import TestModelBase, DictHparamsModel
 from .mixins import (
-    LightningValidationStepMixin,
-    LightningValidationMixin,
-    LightningValidationStepMultipleDataloadersMixin,
-    LightningValidationMultipleDataloadersMixin,
-    LightningTestStepMixin,
-    LightningTestMixin,
-    LightningTestStepMultipleDataloadersMixin,
-    LightningTestMultipleDataloadersMixin,
+    LightEmptyTestStep,
+    LightValidationStepMixin,
+    LightValidationMixin,
+    LightValidationStepMultipleDataloadersMixin,
+    LightValidationMultipleDataloadersMixin,
+    LightTestStepMixin,
+    LightTestMixin,
+    LightTestStepMultipleDataloadersMixin,
+    LightTestMultipleDataloadersMixin,
+    LightTestFitSingleTestDataloadersMixin,
+    LightTestFitMultipleTestDataloadersMixin,
+    LightValStepFitSingleDataloaderMixin,
+    LightValStepFitMultipleDataloadersMixin,
+    LightTrainDataloader,
+    LightTestDataloader,
+    LightInfTrainDataloader,
+    LightInfValDataloader,
+    LightInfTestDataloader,
+    LightTestOptimizerWithSchedulingMixin,
+    LightTestMultipleOptimizersWithSchedulingMixin,
+    LightTestOptimizersWithMixedSchedulingMixin
 )
 
 
-class LightningTestModel(LightningValidationMixin, LightningTestMixin, LightningTestModelBase):
-    """
-    Most common test case. Validation and test dataloaders.
-    """
+class LightningTestModel(LightTrainDataloader,
+                         LightValidationMixin,
+                         LightTestMixin,
+                         TestModelBase):
+    """Most common test case. Validation and test dataloaders."""
 
     def on_training_metrics(self, logs):
         logs['some_tensor_to_test'] = torch.rand(1)
+
+
+class LightningTestModelWithoutHyperparametersArg(LightningTestModel):
+    """ without hparams argument in constructor """
+
+    def __init__(self):
+        import tests.models.utils as tutils
+
+        # the user loads the hparams in some other way
+        hparams = tutils.get_hparams()
+        super().__init__(hparams)
+
+
+class LightningTestModelWithUnusedHyperparametersArg(LightningTestModelWithoutHyperparametersArg):
+    """ has hparams argument in constructor but is not used """
+
+    def __init__(self, hparams):
+        super().__init__()
diff --git a/tests/models/base.py b/tests/models/base.py
index d33f011..8f7f549 100644
--- a/tests/models/base.py
+++ b/tests/models/base.py
@@ -6,9 +6,9 @@ import torch.nn as nn
 import torch.nn.functional as F
 from torch import optim
 from torch.utils.data import DataLoader
-from torch.utils.data.distributed import DistributedSampler
 from torchvision import transforms
 from torchvision.datasets import MNIST
+from typing import Dict
 
 try:
     from test_tube import HyperOptArgumentParser
@@ -16,15 +16,21 @@ except ImportError:
     # TODO: this should be discussed and moved out of this package
     raise ImportError('Missing test-tube package.')
 
-from pytorch_lightning.core.decorators import data_loader
 from pytorch_lightning.core.lightning import LightningModule
 
+# TODO: remove after getting own MNIST
+# TEMPORAL FIX, https://github.com/pytorch/vision/issues/1938
+import urllib.request
+opener = urllib.request.build_opener()
+opener.addheaders = [('User-agent', 'Mozilla/5.0')]
+urllib.request.install_opener(opener)
+
 
 class TestingMNIST(MNIST):
 
     def __init__(self, root, train=True, transform=None, target_transform=None,
                  download=False, num_samples=8000):
-        super(TestingMNIST, self).__init__(
+        super().__init__(
             root,
             train=train,
             transform=transform,
@@ -36,6 +42,29 @@ class TestingMNIST(MNIST):
         self.targets = self.targets[:num_samples]
 
 
+class DictHparamsModel(LightningModule):
+
+    def __init__(self, hparams: Dict):
+        super(DictHparamsModel, self).__init__()
+        self.hparams = hparams
+        self.l1 = torch.nn.Linear(hparams.get('in_features'), hparams['out_features'])
+
+    def forward(self, x):
+        return torch.relu(self.l1(x.view(x.size(0), -1)))
+
+    def training_step(self, batch, batch_idx):
+        x, y = batch
+        y_hat = self.forward(x)
+        return {'loss': F.cross_entropy(y_hat, y)}
+
+    def configure_optimizers(self):
+        return torch.optim.Adam(self.parameters(), lr=0.02)
+
+    def train_dataloader(self):
+        return DataLoader(TestingMNIST(os.getcwd(), train=True, download=True,
+                                       transform=transforms.ToTensor()), batch_size=32)
+
+
 class TestModelBase(LightningModule):
     """
     Base LightningModule for testing. Implements only the required
@@ -48,7 +77,7 @@ class TestModelBase(LightningModule):
         :param hparams:
         """
         # init superclass
-        super(TestModelBase, self).__init__()
+        super().__init__()
         self.hparams = hparams
 
         self.batch_size = hparams.batch_size
@@ -87,7 +116,6 @@ class TestModelBase(LightningModule):
         :param x:
         :return:
         """
-
         x = self.c_d1(x)
         x = torch.tanh(x)
         x = self.c_d1_bn(x)
@@ -102,7 +130,7 @@ class TestModelBase(LightningModule):
         nll = F.nll_loss(logits, labels)
         return nll
 
-    def training_step(self, batch, batch_idx):
+    def training_step(self, batch, batch_idx, optimizer_idx=None):
         """
         Lightning calls this inside the training loop
         :param batch:
@@ -150,30 +178,26 @@ class TestModelBase(LightningModule):
         # test returning only 1 list instead of 2
         return optimizer
 
+    def prepare_data(self):
+        transform = transforms.Compose([transforms.ToTensor(),
+                                        transforms.Normalize((0.5,), (1.0,))])
+        _ = TestingMNIST(root=self.hparams.data_root, train=True,
+                         transform=transform, download=True, num_samples=2000)
+
     def _dataloader(self, train):
         # init data generators
         transform = transforms.Compose([transforms.ToTensor(),
                                         transforms.Normalize((0.5,), (1.0,))])
         dataset = TestingMNIST(root=self.hparams.data_root, train=train,
-                               transform=transform, download=True, num_samples=2000)
+                               transform=transform, download=False, num_samples=2000)
 
         # when using multi-node we need to add the datasampler
-        train_sampler = None
         batch_size = self.hparams.batch_size
 
-        try:
-            if self.use_ddp and not self.force_remove_distributed_sampler:
-                train_sampler = DistributedSampler(dataset, rank=self.trainer.proc_rank)
-                batch_size = batch_size // self.trainer.world_size  # scale batch size
-        except Exception:
-            pass
-
-        should_shuffle = train_sampler is None
         loader = DataLoader(
             dataset=dataset,
             batch_size=batch_size,
-            shuffle=should_shuffle,
-            sampler=train_sampler
+            shuffle=True
         )
 
         return loader
@@ -197,32 +221,17 @@ class TestModelBase(LightningModule):
         parser.add_argument('--out_features', default=10, type=int)
         # use 500 for CPU, 50000 for GPU to see speed difference
         parser.add_argument('--hidden_dim', default=50000, type=int)
-
         # data
         parser.add_argument('--data_root', default=os.path.join(root_dir, 'mnist'), type=str)
-
         # training params (opt)
         parser.opt_list('--learning_rate', default=0.001 * 8, type=float,
                         options=[0.0001, 0.0005, 0.001, 0.005],
                         tunable=False)
         parser.opt_list('--optimizer_name', default='adam', type=str,
                         options=['adam'], tunable=False)
-
         # if using 2 nodes with 4 gpus each the batch size here
         #  (256) will be 256 / (2*8) = 16 per gpu
         parser.opt_list('--batch_size', default=256 * 8, type=int,
                         options=[32, 64, 128, 256], tunable=False,
-                        help='batch size will be divided over all gpus being used across all nodes')
+                        help='batch size will be divided over all GPUs being used across all nodes')
         return parser
-
-
-class LightningTestModelBase(TestModelBase):
-    """ with pre-defined train dataloader """
-    @data_loader
-    def train_dataloader(self):
-        return self._dataloader(train=True)
-
-
-class LightningTestModelBaseWithoutDataloader(TestModelBase):
-    """ without pre-defined train dataloader """
-    pass
diff --git a/tests/models/debug.py b/tests/models/debug.py
index aa0614a..3c200a5 100644
--- a/tests/models/debug.py
+++ b/tests/models/debug.py
@@ -34,21 +34,18 @@ class CoolModel(pl.LightningModule):
         y_hat = self.forward(x)
         return {'val_loss': self.my_loss(y_hat, y)}
 
-    def validation_end(self, outputs):
+    def validation_epoch_end(self, outputs):
         avg_loss = torch.stack([x for x in outputs['val_loss']]).mean()
         return avg_loss
 
     def configure_optimizers(self):
         return [torch.optim.Adam(self.parameters(), lr=0.02)]
 
-    @pl.data_loader
     def train_dataloader(self):
         return DataLoader(MNIST('path/to/save', train=True), batch_size=32)
 
-    @pl.data_loader
     def val_dataloader(self):
         return DataLoader(MNIST('path/to/save', train=False), batch_size=32)
 
-    @pl.data_loader
     def test_dataloader(self):
         return DataLoader(MNIST('path/to/save', train=False), batch_size=32)
diff --git a/tests/models/mixins.py b/tests/models/mixins.py
index 03da85d..fd3f0dd 100644
--- a/tests/models/mixins.py
+++ b/tests/models/mixins.py
@@ -1,21 +1,19 @@
 from collections import OrderedDict
 
 import torch
+from torch import optim
 
-from pytorch_lightning.core.decorators import data_loader
 
-
-class LightningValidationStepMixin:
+class LightValidationStepMixin:
     """
     Add val_dataloader and validation_step methods for the case
     when val_dataloader returns a single dataloader
     """
 
-    @data_loader
     def val_dataloader(self):
         return self._dataloader(train=False)
 
-    def validation_step(self, batch, batch_idx):
+    def validation_step(self, batch, batch_idx, *args, **kwargs):
         """
         Lightning calls this inside the validation loop
         :param batch:
@@ -59,13 +57,13 @@ class LightningValidationStepMixin:
             return output
 
 
-class LightningValidationMixin(LightningValidationStepMixin):
+class LightValidationMixin(LightValidationStepMixin):
     """
     Add val_dataloader, validation_step, and validation_end methods for the case
     when val_dataloader returns a single dataloader
     """
 
-    def validation_end(self, outputs):
+    def validation_epoch_end(self, outputs):
         """
         Called at the end of validation to aggregate outputs
         :param outputs: list of individual outputs of each validation step
@@ -77,7 +75,7 @@ class LightningValidationMixin(LightningValidationStepMixin):
         val_loss_mean = 0
         val_acc_mean = 0
         for output in outputs:
-            val_loss = output['val_loss']
+            val_loss = _get_output_metric(output, 'val_loss')
 
             # reduce manually when using dp
             if self.trainer.use_dp or self.trainer.use_ddp2:
@@ -85,7 +83,7 @@ class LightningValidationMixin(LightningValidationStepMixin):
             val_loss_mean += val_loss
 
             # reduce manually when using dp
-            val_acc = output['val_acc']
+            val_acc = _get_output_metric(output, 'val_acc')
             if self.trainer.use_dp or self.trainer.use_ddp2:
                 val_acc = torch.mean(val_acc)
 
@@ -99,17 +97,16 @@ class LightningValidationMixin(LightningValidationStepMixin):
         return results
 
 
-class LightningValidationStepMultipleDataloadersMixin:
+class LightValidationStepMultipleDataloadersMixin:
     """
     Add val_dataloader and validation_step methods for the case
     when val_dataloader returns multiple dataloaders
     """
 
-    @data_loader
     def val_dataloader(self):
         return [self._dataloader(train=False), self._dataloader(train=False)]
 
-    def validation_step(self, batch, batch_idx, dataloader_idx):
+    def validation_step(self, batch, batch_idx, dataloader_idx, **kwargs):
         """
         Lightning calls this inside the validation loop
         :param batch:
@@ -159,13 +156,13 @@ class LightningValidationStepMultipleDataloadersMixin:
             return output
 
 
-class LightningValidationMultipleDataloadersMixin(LightningValidationStepMultipleDataloadersMixin):
+class LightValidationMultipleDataloadersMixin(LightValidationStepMultipleDataloadersMixin):
     """
     Add val_dataloader, validation_step, and validation_end methods for the case
     when val_dataloader returns multiple dataloaders
     """
 
-    def validation_end(self, outputs):
+    def validation_epoch_end(self, outputs):
         """
         Called at the end of validation to aggregate outputs
         :param outputs: list of individual outputs of each validation step
@@ -202,13 +199,73 @@ class LightningValidationMultipleDataloadersMixin(LightningValidationStepMultipl
         return result
 
 
-class LightningTestStepMixin:
+class LightTrainDataloader:
+    """Simple train dataloader."""
+
+    def train_dataloader(self):
+        return self._dataloader(train=True)
+
+
+class LightTestDataloader:
+    """Simple test dataloader."""
 
-    @data_loader
     def test_dataloader(self):
         return self._dataloader(train=False)
 
-    def test_step(self, batch, batch_idx):
+
+class CustomInfDataloader:
+    def __init__(self, dataloader):
+        self.dataloader = dataloader
+        self.iter = iter(dataloader)
+        self.count = 0
+
+    def __iter__(self):
+        self.count = 0
+        return self
+
+    def __next__(self):
+        if self.count >= 50:
+            raise StopIteration
+        self.count = self.count + 1
+        try:
+            return next(self.iter)
+        except StopIteration:
+            self.iter = iter(self.dataloader)
+            return next(self.iter)
+
+
+class LightInfTrainDataloader:
+    """Simple test dataloader."""
+
+    def train_dataloader(self):
+        return CustomInfDataloader(self._dataloader(train=True))
+
+
+class LightInfValDataloader:
+    """Simple test dataloader."""
+
+    def val_dataloader(self):
+        return CustomInfDataloader(self._dataloader(train=False))
+
+
+class LightInfTestDataloader:
+    """Simple test dataloader."""
+
+    def test_dataloader(self):
+        return CustomInfDataloader(self._dataloader(train=False))
+
+
+class LightEmptyTestStep:
+    """Empty test step."""
+
+    def test_step(self, *args, **kwargs):
+        return dict()
+
+
+class LightTestStepMixin(LightTestDataloader):
+    """Test step mixin."""
+
+    def test_step(self, batch, batch_idx, *args, **kwargs):
         """
         Lightning calls this inside the validation loop
         :param batch:
@@ -252,8 +309,10 @@ class LightningTestStepMixin:
             return output
 
 
-class LightningTestMixin(LightningTestStepMixin):
-    def test_end(self, outputs):
+class LightTestMixin(LightTestStepMixin):
+    """Ritch test mixin."""
+
+    def test_epoch_end(self, outputs):
         """
         Called at the end of validation to aggregate outputs
         :param outputs: list of individual outputs of each validation step
@@ -265,7 +324,7 @@ class LightningTestMixin(LightningTestStepMixin):
         test_loss_mean = 0
         test_acc_mean = 0
         for output in outputs:
-            test_loss = output['test_loss']
+            test_loss = _get_output_metric(output, 'test_loss')
 
             # reduce manually when using dp
             if self.trainer.use_dp:
@@ -273,7 +332,7 @@ class LightningTestMixin(LightningTestStepMixin):
             test_loss_mean += test_loss
 
             # reduce manually when using dp
-            test_acc = output['test_acc']
+            test_acc = _get_output_metric(output, 'test_acc')
             if self.trainer.use_dp:
                 test_acc = torch.mean(test_acc)
 
@@ -287,13 +346,113 @@ class LightningTestMixin(LightningTestStepMixin):
         return result
 
 
-class LightningTestStepMultipleDataloadersMixin:
+class LightTestStepMultipleDataloadersMixin:
+    """Test step multiple dataloaders mixin."""
 
-    @data_loader
     def test_dataloader(self):
         return [self._dataloader(train=False), self._dataloader(train=False)]
 
-    def test_step(self, batch, batch_idx, dataloader_idx):
+    def test_step(self, batch, batch_idx, dataloader_idx, **kwargs):
+        """
+        Lightning calls this inside the validation loop
+        :param batch:
+        :return:
+        """
+        x, y = batch
+        x = x.view(x.size(0), -1)
+        y_hat = self.forward(x)
+
+        loss_test = self.loss(y, y_hat)
+
+        # acc
+        labels_hat = torch.argmax(y_hat, dim=1)
+        test_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0)
+        test_acc = torch.tensor(test_acc)
+
+        if self.on_gpu:
+            test_acc = test_acc.cuda(loss_test.device.index)
+
+        # in DP mode (default) make sure if result is scalar, there's another dim in the beginning
+        if self.trainer.use_dp:
+            loss_test = loss_test.unsqueeze(0)
+            test_acc = test_acc.unsqueeze(0)
+
+        # alternate possible outputs to test
+        if batch_idx % 1 == 0:
+            output = OrderedDict({
+                'test_loss': loss_test,
+                'test_acc': test_acc,
+            })
+            return output
+        if batch_idx % 2 == 0:
+            return test_acc
+
+        if batch_idx % 3 == 0:
+            output = OrderedDict({
+                'test_loss': loss_test,
+                'test_acc': test_acc,
+                'test_dic': {'test_loss_a': loss_test}
+            })
+            return output
+        if batch_idx % 5 == 0:
+            output = OrderedDict({
+                f'test_loss_{dataloader_idx}': loss_test,
+                f'test_acc_{dataloader_idx}': test_acc,
+            })
+            return output
+
+
+class LightTestFitSingleTestDataloadersMixin:
+    """Test fit single test dataloaders mixin."""
+
+    def test_step(self, batch, batch_idx, *args, **kwargs):
+        """
+        Lightning calls this inside the validation loop
+        :param batch:
+        :return:
+        """
+        x, y = batch
+        x = x.view(x.size(0), -1)
+        y_hat = self.forward(x)
+
+        loss_test = self.loss(y, y_hat)
+
+        # acc
+        labels_hat = torch.argmax(y_hat, dim=1)
+        test_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0)
+        test_acc = torch.tensor(test_acc)
+
+        if self.on_gpu:
+            test_acc = test_acc.cuda(loss_test.device.index)
+
+        # in DP mode (default) make sure if result is scalar, there's another dim in the beginning
+        if self.trainer.use_dp:
+            loss_test = loss_test.unsqueeze(0)
+            test_acc = test_acc.unsqueeze(0)
+
+        # alternate possible outputs to test
+        if batch_idx % 1 == 0:
+            output = OrderedDict({
+                'test_loss': loss_test,
+                'test_acc': test_acc,
+            })
+            return output
+        if batch_idx % 2 == 0:
+            return test_acc
+
+        if batch_idx % 3 == 0:
+            output = OrderedDict({
+                'test_loss': loss_test,
+                'test_acc': test_acc,
+                'test_dic': {'test_loss_a': loss_test}
+            })
+            return output
+
+
+class LightTestFitMultipleTestDataloadersMixin:
+    """Test fit multiple test dataloaders mixin."""
+
+    def test_step(self, batch, batch_idx, dataloader_idx, **kwargs):
         """
         Lightning calls this inside the validation loop
         :param batch:
@@ -343,8 +502,107 @@ class LightningTestStepMultipleDataloadersMixin:
             return output
 
 
-class LightningTestMultipleDataloadersMixin(LightningTestStepMultipleDataloadersMixin):
-    def test_end(self, outputs):
+class LightValStepFitSingleDataloaderMixin:
+
+    def validation_step(self, batch, batch_idx, *args, **kwargs):
+        """
+        Lightning calls this inside the validation loop
+        :param batch:
+        :return:
+        """
+        x, y = batch
+        x = x.view(x.size(0), -1)
+        y_hat = self.forward(x)
+
+        loss_val = self.loss(y, y_hat)
+
+        # acc
+        labels_hat = torch.argmax(y_hat, dim=1)
+        val_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0)
+        val_acc = torch.tensor(val_acc)
+
+        if self.on_gpu:
+            val_acc = val_acc.cuda(loss_val.device.index)
+
+        # in DP mode (default) make sure if result is scalar, there's another dim in the beginning
+        if self.trainer.use_dp:
+            loss_val = loss_val.unsqueeze(0)
+            val_acc = val_acc.unsqueeze(0)
+
+        # alternate possible outputs to test
+        if batch_idx % 1 == 0:
+            output = OrderedDict({
+                'val_loss': loss_val,
+                'val_acc': val_acc,
+            })
+            return output
+        if batch_idx % 2 == 0:
+            return val_acc
+
+        if batch_idx % 3 == 0:
+            output = OrderedDict({
+                'val_loss': loss_val,
+                'val_acc': val_acc,
+                'test_dic': {'val_loss_a': loss_val}
+            })
+            return output
+
+
+class LightValStepFitMultipleDataloadersMixin:
+
+    def validation_step(self, batch, batch_idx, dataloader_idx, **kwargs):
+        """
+        Lightning calls this inside the validation loop
+        :param batch:
+        :return:
+        """
+        x, y = batch
+        x = x.view(x.size(0), -1)
+        y_hat = self.forward(x)
+
+        loss_val = self.loss(y, y_hat)
+
+        # acc
+        labels_hat = torch.argmax(y_hat, dim=1)
+        val_acc = torch.sum(y == labels_hat).item() / (len(y) * 1.0)
+        val_acc = torch.tensor(val_acc)
+
+        if self.on_gpu:
+            val_acc = val_acc.cuda(loss_val.device.index)
+
+        # in DP mode (default) make sure if result is scalar, there's another dim in the beginning
+        if self.trainer.use_dp:
+            loss_val = loss_val.unsqueeze(0)
+            val_acc = val_acc.unsqueeze(0)
+
+        # alternate possible outputs to test
+        if batch_idx % 1 == 0:
+            output = OrderedDict({
+                'val_loss': loss_val,
+                'val_acc': val_acc,
+            })
+            return output
+        if batch_idx % 2 == 0:
+            return val_acc
+
+        if batch_idx % 3 == 0:
+            output = OrderedDict({
+                'val_loss': loss_val,
+                'val_acc': val_acc,
+                'test_dic': {'val_loss_a': loss_val}
+            })
+            return output
+        if batch_idx % 5 == 0:
+            output = OrderedDict({
+                f'val_loss_{dataloader_idx}': loss_val,
+                f'val_acc_{dataloader_idx}': val_acc,
+            })
+            return output
+
+
+class LightTestMultipleDataloadersMixin(LightTestStepMultipleDataloadersMixin):
+
+    def test_epoch_end(self, outputs):
         """
         Called at the end of validation to aggregate outputs
         :param outputs: list of individual outputs of each validation step
@@ -379,3 +637,50 @@ class LightningTestMultipleDataloadersMixin(LightningTestStepMultipleDataloaders
         tqdm_dict = {'test_loss': test_loss_mean.item(), 'test_acc': test_acc_mean.item()}
         result = {'progress_bar': tqdm_dict}
         return result
+
+
+class LightTestOptimizerWithSchedulingMixin:
+    def configure_optimizers(self):
+        if self.hparams.optimizer_name == 'lbfgs':
+            optimizer = optim.LBFGS(self.parameters(), lr=self.hparams.learning_rate)
+        else:
+            optimizer = optim.Adam(self.parameters(), lr=self.hparams.learning_rate)
+        lr_scheduler = optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.1)
+        return [optimizer], [lr_scheduler]
+
+
+class LightTestMultipleOptimizersWithSchedulingMixin:
+    def configure_optimizers(self):
+        if self.hparams.optimizer_name == 'lbfgs':
+            optimizer1 = optim.LBFGS(self.parameters(), lr=self.hparams.learning_rate)
+            optimizer2 = optim.LBFGS(self.parameters(), lr=self.hparams.learning_rate)
+        else:
+            optimizer1 = optim.Adam(self.parameters(), lr=self.hparams.learning_rate)
+            optimizer2 = optim.Adam(self.parameters(), lr=self.hparams.learning_rate)
+        lr_scheduler1 = optim.lr_scheduler.StepLR(optimizer1, 1, gamma=0.1)
+        lr_scheduler2 = optim.lr_scheduler.StepLR(optimizer2, 1, gamma=0.1)
+
+        return [optimizer1, optimizer2], [lr_scheduler1, lr_scheduler2]
+
+
+class LightTestOptimizersWithMixedSchedulingMixin:
+    def configure_optimizers(self):
+        if self.hparams.optimizer_name == 'lbfgs':
+            optimizer1 = optim.LBFGS(self.parameters(), lr=self.hparams.learning_rate)
+            optimizer2 = optim.LBFGS(self.parameters(), lr=self.hparams.learning_rate)
+        else:
+            optimizer1 = optim.Adam(self.parameters(), lr=self.hparams.learning_rate)
+            optimizer2 = optim.Adam(self.parameters(), lr=self.hparams.learning_rate)
+        lr_scheduler1 = optim.lr_scheduler.StepLR(optimizer1, 4, gamma=0.1)
+        lr_scheduler2 = optim.lr_scheduler.StepLR(optimizer2, 1, gamma=0.1)
+
+        return [optimizer1, optimizer2], \
+            [{'scheduler': lr_scheduler1, 'interval': 'step'}, lr_scheduler2]
+
+
+def _get_output_metric(output, name):
+    if isinstance(output, dict):
+        val = output[name]
+    else:  # if it is 2level deep -> per dataloader and per batch
+        val = sum(out[name] for out in output) / len(output)
+    return val
diff --git a/tests/models/utils.py b/tests/models/utils.py
index 7a641b5..2f97116 100644
--- a/tests/models/utils.py
+++ b/tests/models/utils.py
@@ -32,11 +32,15 @@ def run_model_test_no_loggers(trainer_options, model, min_acc=0.50):
 
     # test model loading
     pretrained_model = load_model(trainer.logger,
-                                  trainer.checkpoint_callback.filepath,
+                                  trainer.checkpoint_callback.dirpath,
                                   path_expt=trainer_options.get('default_save_path'))
 
     # test new model accuracy
-    for dataloader in model.test_dataloader():
+    test_loaders = model.test_dataloader()
+    if not isinstance(test_loaders, list):
+        test_loaders = [test_loaders]
+
+    for dataloader in test_loaders:
         run_prediction(dataloader, pretrained_model, min_acc=min_acc)
 
     if trainer.use_ddp:
@@ -66,15 +70,19 @@ def run_model_test(trainer_options, model, on_gpu=True):
     assert result == 1, 'amp + ddp model failed to complete'
 
     # test model loading
-    pretrained_model = load_model(logger, trainer.checkpoint_callback.filepath)
+    pretrained_model = load_model(logger, trainer.checkpoint_callback.dirpath)
 
     # test new model accuracy
-    [run_prediction(dataloader, pretrained_model) for dataloader in model.test_dataloader()]
+    test_loaders = model.test_dataloader()
+    if not isinstance(test_loaders, list):
+        test_loaders = [test_loaders]
+
+    [run_prediction(dataloader, pretrained_model) for dataloader in test_loaders]
 
     if trainer.use_ddp or trainer.use_ddp2:
         # on hpc this would work fine... but need to hack it for the purpose of the test
         trainer.model = pretrained_model
-        trainer.optimizers, trainer.lr_schedulers = pretrained_model.configure_optimizers()
+        trainer.optimizers, trainer.lr_schedulers = trainer.init_optimizers(pretrained_model.configure_optimizers())
 
     # test HPC loading / saving
     trainer.hpc_save(save_dir, logger)
@@ -82,7 +90,7 @@ def run_model_test(trainer_options, model, on_gpu=True):
 
 
 def get_hparams(continue_training=False, hpc_exp_number=0):
-    root_dir = os.path.dirname(os.path.realpath(__file__))
+    tests_dir = os.path.dirname(os.path.dirname(os.path.realpath(__file__)))
 
     args = {
         'drop_prob': 0.2,
@@ -90,7 +98,7 @@ def get_hparams(continue_training=False, hpc_exp_number=0):
         'in_features': 28 * 28,
         'learning_rate': 0.001 * 8,
         'optimizer_name': 'adam',
-        'data_root': os.path.join(root_dir, 'mnist'),
+        'data_root': os.path.join(tests_dir, 'datasets'),
         'out_features': 10,
         'hidden_dim': 1000,
     }
@@ -150,15 +158,31 @@ def load_model(exp, root_weights_dir, module_class=LightningTemplateModel, path_
     checkpoints = [x for x in os.listdir(root_weights_dir) if '.ckpt' in x]
     weights_dir = os.path.join(root_weights_dir, checkpoints[0])
 
-    trained_model = module_class.load_from_metrics(weights_path=weights_dir,
-                                                   tags_csv=tags_path)
+    trained_model = module_class.load_from_checkpoint(
+        checkpoint_path=weights_dir,
+        tags_csv=tags_path
+    )
+
+    assert trained_model is not None, 'loading model failed'
+
+    return trained_model
+
+
+def load_model_from_checkpoint(root_weights_dir, module_class=LightningTemplateModel):
+    # load trained model
+    checkpoints = [x for x in os.listdir(root_weights_dir) if '.ckpt' in x]
+    weights_dir = os.path.join(root_weights_dir, checkpoints[0])
+
+    trained_model = module_class.load_from_checkpoint(
+        checkpoint_path=weights_dir,
+    )
 
     assert trained_model is not None, 'loading model failed'
 
     return trained_model
 
 
-def run_prediction(dataloader, trained_model, dp=False, min_acc=0.50):
+def run_prediction(dataloader, trained_model, dp=False, min_acc=0.45):
     # run prediction on 1 batch
     for batch in dataloader:
         break
@@ -180,13 +204,13 @@ def run_prediction(dataloader, trained_model, dp=False, min_acc=0.50):
         acc = torch.tensor(acc)
         acc = acc.item()
 
-    assert acc > min_acc, f'this model is expected to get > {min_acc} in test set (it got {acc})'
+    assert acc >= min_acc, f"This model is expected to get > {min_acc} in test set (it got {acc})"
 
 
 def assert_ok_model_acc(trainer, key='test_acc', thr=0.4):
     # this model should get 0.80+ acc
     acc = trainer.training_tqdm_dict[key]
-    assert acc > thr, f'Model failed to get expected {thr} accuracy. {key} = {acc}'
+    assert acc > thr, f"Model failed to get expected {thr} accuracy. {key} = {acc}"
 
 
 def can_run_gpu_test():
@@ -215,5 +239,6 @@ def set_random_master_port():
 def init_checkpoint_callback(logger, path_dir=None):
     exp_path = get_data_path(logger, path_dir=path_dir)
     ckpt_dir = os.path.join(exp_path, 'checkpoints')
+    os.mkdir(ckpt_dir)
     checkpoint = ModelCheckpoint(ckpt_dir)
     return checkpoint
diff --git a/tests/test_amp.py b/tests/test_amp.py
index 5a34906..832c7ba 100644
--- a/tests/test_amp.py
+++ b/tests/test_amp.py
@@ -4,10 +4,10 @@ import pytest
 
 import tests.models.utils as tutils
 from pytorch_lightning import Trainer
+from pytorch_lightning.utilities.debugging import MisconfigurationException
 from tests.models import (
     LightningTestModel,
 )
-from pytorch_lightning.utilities.debugging import MisconfigurationException
 
 
 def test_amp_single_gpu(tmpdir):
diff --git a/tests/test_cpu_models.py b/tests/test_cpu_models.py
index 37daf58..1d0b1d1 100644
--- a/tests/test_cpu_models.py
+++ b/tests/test_cpu_models.py
@@ -3,14 +3,15 @@ import warnings
 import torch
 
 import tests.models.utils as tutils
-from pytorch_lightning import Trainer, data_loader
+from pytorch_lightning import Trainer
 from pytorch_lightning.callbacks import (
     EarlyStopping,
 )
 from tests.models import (
+    TestModelBase,
+    LightTrainDataloader,
     LightningTestModel,
-    LightningTestModelBase,
-    LightningTestMixin,
+    LightTestMixin,
 )
 
 
@@ -46,7 +47,7 @@ def test_lbfgs_cpu_model(tmpdir):
 
     trainer_options = dict(
         default_save_path=tmpdir,
-        max_epochs=1,
+        max_epochs=2,
         print_nan_grads=True,
         show_progress_bar=False,
         weights_summary='top',
@@ -121,7 +122,7 @@ def test_running_test_without_val(tmpdir):
     """Verify `test()` works on a model with no `val_loader`."""
     tutils.reset_seed()
 
-    class CurrentTestModel(LightningTestMixin, LightningTestModelBase):
+    class CurrentTestModel(LightTrainDataloader, LightTestMixin, TestModelBase):
         pass
 
     hparams = tutils.get_hparams()
@@ -281,7 +282,7 @@ def test_tbptt_cpu_model(tmpdir):
         def __len__(self):
             return 1
 
-    class BpttTestModel(LightningTestModelBase):
+    class BpttTestModel(LightTrainDataloader, TestModelBase):
         def __init__(self, hparams):
             super().__init__(hparams)
             self.test_hidden = None
@@ -304,7 +305,6 @@ def test_tbptt_cpu_model(tmpdir):
                 'hiddens': self.test_hidden,
             }
 
-        @data_loader
         def train_dataloader(self):
             return torch.utils.data.DataLoader(
                 dataset=MockSeq2SeqDataset(),
diff --git a/tests/test_deprecated.py b/tests/test_deprecated.py
new file mode 100644
index 0000000..b014c5a
--- /dev/null
+++ b/tests/test_deprecated.py
@@ -0,0 +1,55 @@
+"""Test deprecated functionality which will be removed in vX.Y.Z"""
+
+from pytorch_lightning import Trainer
+
+
+def test_to_be_removed_in_v0_8_0_module_imports():
+    from pytorch_lightning.logging.comet_logger import CometLogger  # noqa: F811
+    from pytorch_lightning.logging.mlflow_logger import MLFlowLogger  # noqa: F811
+    from pytorch_lightning.logging.test_tube_logger import TestTubeLogger  # noqa: F811
+
+    from pytorch_lightning.pt_overrides.override_data_parallel import (  # noqa: F811
+        LightningDataParallel, LightningDistributedDataParallel)
+    from pytorch_lightning.overrides.override_data_parallel import (  # noqa: F811
+        LightningDataParallel, LightningDistributedDataParallel)
+
+    from pytorch_lightning.core.model_saving import ModelIO  # noqa: F811
+    from pytorch_lightning.core.root_module import LightningModule  # noqa: F811
+
+    from pytorch_lightning.root_module.decorators import data_loader  # noqa: F811
+    from pytorch_lightning.root_module.grads import GradInformation  # noqa: F811
+    from pytorch_lightning.root_module.hooks import ModelHooks  # noqa: F811
+    from pytorch_lightning.root_module.memory import ModelSummary  # noqa: F811
+    from pytorch_lightning.root_module.model_saving import ModelIO  # noqa: F811
+    from pytorch_lightning.root_module.root_module import LightningModule  # noqa: F811
+
+
+def test_to_be_removed_in_v0_8_0_trainer():
+    mapping_old_new = {
+        'gradient_clip': 'gradient_clip_val',
+        'nb_gpu_nodes': 'num_nodes',
+        'max_nb_epochs': 'max_epochs',
+        'min_nb_epochs': 'min_epochs',
+        'nb_sanity_val_steps': 'num_sanity_val_steps',
+    }
+    # skip 0 since it may be interested as False
+    kwargs = {k: (i + 1) for i, k in enumerate(mapping_old_new)}
+
+    trainer = Trainer(**kwargs)
+
+    for attr_old in mapping_old_new:
+        attr_new = mapping_old_new[attr_old]
+        assert kwargs[attr_old] == getattr(trainer, attr_old), \
+            'Missing deprecated attribute "%s"' % attr_old
+        assert kwargs[attr_old] == getattr(trainer, attr_new), \
+            'Wrongly passed deprecated argument "%s" to attribute "%s"' % (attr_old, attr_new)
+
+
+def test_to_be_removed_in_v0_9_0_module_imports():
+    from pytorch_lightning.core.decorators import data_loader  # noqa: F811
+
+    from pytorch_lightning.logging.comet import CometLogger  # noqa: F402
+    from pytorch_lightning.logging.mlflow import MLFlowLogger  # noqa: F402
+    from pytorch_lightning.logging.neptune import NeptuneLogger  # noqa: F402
+    from pytorch_lightning.logging.test_tube import TestTubeLogger  # noqa: F402
+    from pytorch_lightning.logging.wandb import WandbLogger  # noqa: F402
diff --git a/tests/test_gpu_models.py b/tests/test_gpu_models.py
index e982d2f..a95e4d4 100644
--- a/tests/test_gpu_models.py
+++ b/tests/test_gpu_models.py
@@ -9,14 +9,14 @@ from pytorch_lightning.callbacks import (
     ModelCheckpoint,
 )
 from pytorch_lightning.core import memory
-from tests.models import (
-    LightningTestModel,
-)
 from pytorch_lightning.trainer.distrib_parts import (
     parse_gpu_ids,
     determine_root_gpu_device,
 )
 from pytorch_lightning.utilities.debugging import MisconfigurationException
+from tests.models import (
+    LightningTestModel,
+)
 
 PRETEND_N_OF_GPUS = 16
 
@@ -66,6 +66,31 @@ def test_multi_gpu_model_ddp(tmpdir):
     tutils.run_model_test(trainer_options, model)
 
 
+def test_ddp_all_dataloaders_passed_to_fit(tmpdir):
+    """Make sure DDP works with dataloaders passed to fit()"""
+    if not tutils.can_run_gpu_test():
+        return
+
+    tutils.reset_seed()
+    tutils.set_random_master_port()
+
+    model, hparams = tutils.get_model()
+    trainer_options = dict(default_save_path=tmpdir,
+                           show_progress_bar=False,
+                           max_epochs=1,
+                           train_percent_check=0.4,
+                           val_percent_check=0.2,
+                           gpus=[0, 1],
+                           distributed_backend='ddp')
+
+    fit_options = dict(train_dataloader=model.train_dataloader(),
+                       val_dataloaders=model.val_dataloader())
+
+    trainer = Trainer(**trainer_options)
+    result = trainer.fit(model, **fit_options)
+    assert result == 1, "DDP doesn't work with dataloaders passed to fit()."
+
+
 def test_optimizer_return_options():
     tutils.reset_seed()
 
@@ -91,10 +116,14 @@ def test_optimizer_return_options():
     assert len(lr_sched) == 0
 
     # opt tuple of lists
-    opts = ([opt_a], ['lr_scheduler'])
+    scheduler = torch.optim.lr_scheduler.StepLR(opt_a, 10)
+    opts = ([opt_a], [scheduler])
     optim, lr_sched = trainer.init_optimizers(opts)
     assert len(optim) == 1 and len(lr_sched) == 1
-    assert optim[0] == opts[0][0] and lr_sched[0] == 'lr_scheduler'
+    assert optim[0] == opts[0][0] and \
+        lr_sched[0] == dict(scheduler=scheduler, interval='epoch',
+                            frequency=1, reduce_on_plateau=False,
+                            monitor='val_loss')
 
 
 def test_cpu_slurm_save_load(tmpdir):
@@ -124,7 +153,11 @@ def test_cpu_slurm_save_load(tmpdir):
 
     # predict with trained model before saving
     # make a prediction
-    for dataloader in model.test_dataloader():
+    dataloaders = model.test_dataloader()
+    if not isinstance(dataloaders, list):
+        dataloaders = [dataloaders]
+
+    for dataloader in dataloaders:
         for batch in dataloader:
             break
 
@@ -211,32 +244,6 @@ def test_multi_gpu_model_dp(tmpdir):
     memory.get_memory_profile('min_max')
 
 
-def test_ddp_sampler_error(tmpdir):
-    """Make sure DDP + AMP work."""
-    if not tutils.can_run_gpu_test():
-        return
-
-    tutils.reset_seed()
-    tutils.set_random_master_port()
-
-    hparams = tutils.get_hparams()
-    model = LightningTestModel(hparams, force_remove_distributed_sampler=True)
-
-    logger = tutils.get_test_tube_logger(tmpdir, True)
-
-    trainer = Trainer(
-        logger=logger,
-        show_progress_bar=False,
-        max_epochs=1,
-        gpus=[0, 1],
-        distributed_backend='ddp',
-        precision=16
-    )
-
-    with pytest.warns(UserWarning):
-        trainer.get_dataloaders(model)
-
-
 @pytest.fixture
 def mocked_device_count(monkeypatch):
     def device_count():
@@ -253,66 +260,57 @@ def mocked_device_count_0(monkeypatch):
     monkeypatch.setattr(torch.cuda, 'device_count', device_count)
 
 
-test_num_gpus_data = [
+@pytest.mark.gpus_param_tests
+@pytest.mark.parametrize(["gpus", "expected_num_gpus", "distributed_backend"], [
     pytest.param(None, 0, None, id="None - expect 0 gpu to use."),
     pytest.param(0, 0, None, id="Oth gpu, expect 1 gpu to use."),
     pytest.param(1, 1, None, id="1st gpu, expect 1 gpu to use."),
     pytest.param(-1, PRETEND_N_OF_GPUS, "ddp", id="-1 - use all gpus"),
     pytest.param('-1', PRETEND_N_OF_GPUS, "ddp", id="'-1' - use all gpus"),
     pytest.param(3, 3, "ddp", id="3rd gpu - 1 gpu to use (backend:ddp)")
-]
-
-
-@pytest.mark.gpus_param_tests
-@pytest.mark.parametrize(["gpus", "expected_num_gpus", "distributed_backend"], test_num_gpus_data)
+])
 def test_trainer_gpu_parse(mocked_device_count, gpus, expected_num_gpus, distributed_backend):
     assert Trainer(gpus=gpus, distributed_backend=distributed_backend).num_gpus == expected_num_gpus
 
 
-test_num_gpus_data_0 = [
+@pytest.mark.gpus_param_tests
+@pytest.mark.parametrize(["gpus", "expected_num_gpus", "distributed_backend"], [
     pytest.param(None, 0, None, id="None - expect 0 gpu to use."),
     pytest.param(None, 0, "ddp", id="None - expect 0 gpu to use."),
-]
-
-
-@pytest.mark.gpus_param_tests
-@pytest.mark.parametrize(["gpus", "expected_num_gpus", "distributed_backend"], test_num_gpus_data_0)
+])
 def test_trainer_num_gpu_0(mocked_device_count_0, gpus, expected_num_gpus, distributed_backend):
     assert Trainer(gpus=gpus, distributed_backend=distributed_backend).num_gpus == expected_num_gpus
 
 
-test_root_gpu_data = [
+@pytest.mark.gpus_param_tests
+@pytest.mark.parametrize(['gpus', 'expected_root_gpu', "distributed_backend"], [
     pytest.param(None, None, "ddp", id="None is None"),
     pytest.param(0, None, "ddp", id="O gpus, expect gpu root device to be None."),
     pytest.param(1, 0, "ddp", id="1 gpu, expect gpu root device to be 0."),
     pytest.param(-1, 0, "ddp", id="-1 - use all gpus, expect gpu root device to be 0."),
     pytest.param('-1', 0, "ddp", id="'-1' - use all gpus, expect gpu root device to be 0."),
-    pytest.param(3, 0, "ddp", id="3 gpus, expect gpu root device to be 0.(backend:ddp)")]
-
-
-@pytest.mark.gpus_param_tests
-@pytest.mark.parametrize(['gpus', 'expected_root_gpu', "distributed_backend"], test_root_gpu_data)
+    pytest.param(3, 0, "ddp", id="3 gpus, expect gpu root device to be 0.(backend:ddp)")
+])
 def test_root_gpu_property(mocked_device_count, gpus, expected_root_gpu, distributed_backend):
     assert Trainer(gpus=gpus, distributed_backend=distributed_backend).root_gpu == expected_root_gpu
 
 
-test_root_gpu_data_for_0_devices_passing = [
+@pytest.mark.gpus_param_tests
+@pytest.mark.parametrize([
+    'gpus', 'expected_root_gpu', "distributed_backend"], [
     pytest.param(None, None, None, id="None is None"),
     pytest.param(None, None, "ddp", id="None is None"),
     pytest.param(0, None, "ddp", id="None is None"),
-]
-
-
-@pytest.mark.gpus_param_tests
-@pytest.mark.parametrize([
-    'gpus', 'expected_root_gpu', "distributed_backend"], test_root_gpu_data_for_0_devices_passing)
+])
 def test_root_gpu_property_0_passing(
         mocked_device_count_0, gpus, expected_root_gpu, distributed_backend):
     assert Trainer(gpus=gpus, distributed_backend=distributed_backend).root_gpu == expected_root_gpu
 
 
 # Asking for a gpu when non are available will result in a MisconfigurationException
-test_root_gpu_data_for_0_devices_raising = [
+@pytest.mark.gpus_param_tests
+@pytest.mark.parametrize([
+    'gpus', 'expected_root_gpu', "distributed_backend"], [
     pytest.param(1, None, "ddp"),
     pytest.param(3, None, "ddp"),
     pytest.param(3, None, "ddp"),
@@ -320,34 +318,27 @@ test_root_gpu_data_for_0_devices_raising = [
     pytest.param([0, 1], None, "ddp"),
     pytest.param(-1, None, "ddp"),
     pytest.param('-1', None, "ddp")
-]
-
-
-@pytest.mark.gpus_param_tests
-@pytest.mark.parametrize([
-    'gpus', 'expected_root_gpu', "distributed_backend"], test_root_gpu_data_for_0_devices_raising)
+])
 def test_root_gpu_property_0_raising(
         mocked_device_count_0, gpus, expected_root_gpu, distributed_backend):
     with pytest.raises(MisconfigurationException):
         Trainer(gpus=gpus, distributed_backend=distributed_backend).root_gpu
 
 
-test_determine_root_gpu_device_data = [
+@pytest.mark.gpus_param_tests
+@pytest.mark.parametrize(['gpus', 'expected_root_gpu'], [
     pytest.param(None, None, id="No gpus, expect gpu root device to be None"),
     pytest.param([0], 0, id="Oth gpu, expect gpu root device to be 0."),
     pytest.param([1], 1, id="1st gpu, expect gpu root device to be 1."),
     pytest.param([3], 3, id="3rd gpu, expect gpu root device to be 3."),
     pytest.param([1, 2], 1, id="[1, 2] gpus, expect gpu root device to be 1."),
-]
-
-
-@pytest.mark.gpus_param_tests
-@pytest.mark.parametrize(['gpus', 'expected_root_gpu'], test_determine_root_gpu_device_data)
+])
 def test_determine_root_gpu_device(gpus, expected_root_gpu):
     assert determine_root_gpu_device(gpus) == expected_root_gpu
 
 
-test_parse_gpu_ids_data = [
+@pytest.mark.gpus_param_tests
+@pytest.mark.parametrize(['gpus', 'expected_gpu_ids'], [
     pytest.param(None, None),
     pytest.param(0, None),
     pytest.param(1, [0]),
@@ -359,16 +350,13 @@ test_parse_gpu_ids_data = [
     pytest.param('3', [3]),
     pytest.param('1, 3', [1, 3]),
     pytest.param('-1', list(range(PRETEND_N_OF_GPUS)), id="'-1' - use all gpus"),
-]
-
-
-@pytest.mark.gpus_param_tests
-@pytest.mark.parametrize(['gpus', 'expected_gpu_ids'], test_parse_gpu_ids_data)
+])
 def test_parse_gpu_ids(mocked_device_count, gpus, expected_gpu_ids):
     assert parse_gpu_ids(gpus) == expected_gpu_ids
 
 
-test_parse_gpu_invalid_inputs_data = [
+@pytest.mark.gpus_param_tests
+@pytest.mark.parametrize(['gpus'], [
     pytest.param(0.1),
     pytest.param(-2),
     pytest.param(False),
@@ -377,11 +365,7 @@ test_parse_gpu_invalid_inputs_data = [
     pytest.param([None]),
     pytest.param(['0']),
     pytest.param((0, 1)),
-]
-
-
-@pytest.mark.gpus_param_tests
-@pytest.mark.parametrize(['gpus'], test_parse_gpu_invalid_inputs_data)
+])
 def test_parse_gpu_fail_on_unsupported_inputs(mocked_device_count, gpus):
     with pytest.raises(MisconfigurationException):
         parse_gpu_ids(gpus)
diff --git a/tests/test_logging.py b/tests/test_logging.py
deleted file mode 100644
index 93f0b46..0000000
--- a/tests/test_logging.py
+++ /dev/null
@@ -1,408 +0,0 @@
-import os
-import pickle
-
-import pytest
-import torch
-
-import tests.models.utils as tutils
-from pytorch_lightning import Trainer
-from pytorch_lightning.loggers import (
-    LightningLoggerBase,
-    rank_zero_only,
-    TensorBoardLogger,
-    MLFlowLogger,
-    CometLogger,
-    WandbLogger,
-    NeptuneLogger
-)
-from tests.models import LightningTestModel
-
-
-def test_testtube_logger(tmpdir):
-    """Verify that basic functionality of test tube logger works."""
-    tutils.reset_seed()
-    hparams = tutils.get_hparams()
-    model = LightningTestModel(hparams)
-
-    logger = tutils.get_test_tube_logger(tmpdir, False)
-
-    trainer_options = dict(
-        default_save_path=tmpdir,
-        max_epochs=1,
-        train_percent_check=0.05,
-        logger=logger
-    )
-
-    trainer = Trainer(**trainer_options)
-    result = trainer.fit(model)
-
-    assert result == 1, "Training failed"
-
-
-def test_testtube_pickle(tmpdir):
-    """Verify that pickling a trainer containing a test tube logger works."""
-    tutils.reset_seed()
-
-    hparams = tutils.get_hparams()
-    model = LightningTestModel(hparams)
-
-    logger = tutils.get_test_tube_logger(tmpdir, False)
-    logger.log_hyperparams(hparams)
-    logger.save()
-
-    trainer_options = dict(
-        default_save_path=tmpdir,
-        max_epochs=1,
-        train_percent_check=0.05,
-        logger=logger
-    )
-
-    trainer = Trainer(**trainer_options)
-    pkl_bytes = pickle.dumps(trainer)
-    trainer2 = pickle.loads(pkl_bytes)
-    trainer2.logger.log_metrics({"acc": 1.0})
-
-
-def test_mlflow_logger(tmpdir):
-    """Verify that basic functionality of mlflow logger works."""
-    tutils.reset_seed()
-
-    hparams = tutils.get_hparams()
-    model = LightningTestModel(hparams)
-
-    mlflow_dir = os.path.join(tmpdir, "mlruns")
-    logger = MLFlowLogger("test", tracking_uri=f"file:{os.sep * 2}{mlflow_dir}")
-
-    trainer_options = dict(
-        default_save_path=tmpdir,
-        max_epochs=1,
-        train_percent_check=0.05,
-        logger=logger
-    )
-    trainer = Trainer(**trainer_options)
-    result = trainer.fit(model)
-
-    print('result finished')
-    assert result == 1, "Training failed"
-
-
-def test_mlflow_pickle(tmpdir):
-    """Verify that pickling trainer with mlflow logger works."""
-    tutils.reset_seed()
-
-    # hparams = tutils.get_hparams()
-    # model = LightningTestModel(hparams)
-
-    mlflow_dir = os.path.join(tmpdir, "mlruns")
-    logger = MLFlowLogger("test", tracking_uri=f"file:{os.sep * 2}{mlflow_dir}")
-    trainer_options = dict(
-        default_save_path=tmpdir,
-        max_epochs=1,
-        logger=logger
-    )
-
-    trainer = Trainer(**trainer_options)
-    pkl_bytes = pickle.dumps(trainer)
-    trainer2 = pickle.loads(pkl_bytes)
-    trainer2.logger.log_metrics({"acc": 1.0})
-
-
-def test_comet_logger(tmpdir, monkeypatch):
-    """Verify that basic functionality of Comet.ml logger works."""
-
-    # prevent comet logger from trying to print at exit, since
-    # pytest's stdout/stderr redirection breaks it
-    import atexit
-    monkeypatch.setattr(atexit, "register", lambda _: None)
-
-    tutils.reset_seed()
-
-    hparams = tutils.get_hparams()
-    model = LightningTestModel(hparams)
-
-    comet_dir = os.path.join(tmpdir, "cometruns")
-
-    # We test CometLogger in offline mode with local saves
-    logger = CometLogger(
-        save_dir=comet_dir,
-        project_name="general",
-        workspace="dummy-test",
-    )
-
-    trainer_options = dict(
-        default_save_path=tmpdir,
-        max_epochs=1,
-        train_percent_check=0.05,
-        logger=logger
-    )
-
-    trainer = Trainer(**trainer_options)
-    result = trainer.fit(model)
-
-    print('result finished')
-    assert result == 1, "Training failed"
-
-
-def test_comet_pickle(tmpdir, monkeypatch):
-    """Verify that pickling trainer with comet logger works."""
-
-    # prevent comet logger from trying to print at exit, since
-    # pytest's stdout/stderr redirection breaks it
-    import atexit
-    monkeypatch.setattr(atexit, "register", lambda _: None)
-
-    tutils.reset_seed()
-
-    # hparams = tutils.get_hparams()
-    # model = LightningTestModel(hparams)
-
-    comet_dir = os.path.join(tmpdir, "cometruns")
-
-    # We test CometLogger in offline mode with local saves
-    logger = CometLogger(
-        save_dir=comet_dir,
-        project_name="general",
-        workspace="dummy-test",
-    )
-
-    trainer_options = dict(
-        default_save_path=tmpdir,
-        max_epochs=1,
-        logger=logger
-    )
-
-    trainer = Trainer(**trainer_options)
-    pkl_bytes = pickle.dumps(trainer)
-    trainer2 = pickle.loads(pkl_bytes)
-    trainer2.logger.log_metrics({"acc": 1.0})
-
-
-def test_wandb_logger(tmpdir):
-    """Verify that basic functionality of wandb logger works."""
-    tutils.reset_seed()
-
-    wandb_dir = os.path.join(tmpdir, "wandb")
-    _ = WandbLogger(save_dir=wandb_dir, anonymous=True, offline=True)
-
-
-def test_wandb_pickle(tmpdir):
-    """Verify that pickling trainer with wandb logger works."""
-    tutils.reset_seed()
-
-    wandb_dir = str(tmpdir)
-    logger = WandbLogger(save_dir=wandb_dir, anonymous=True, offline=True)
-    assert logger is not None
-
-
-def test_neptune_logger(tmpdir):
-    """Verify that basic functionality of neptune logger works."""
-    tutils.reset_seed()
-
-    hparams = tutils.get_hparams()
-    model = LightningTestModel(hparams)
-    logger = NeptuneLogger(offline_mode=True)
-
-    trainer_options = dict(
-        default_save_path=tmpdir,
-        max_epochs=1,
-        train_percent_check=0.05,
-        logger=logger
-    )
-    trainer = Trainer(**trainer_options)
-    result = trainer.fit(model)
-
-    print('result finished')
-    assert result == 1, "Training failed"
-
-
-def test_neptune_pickle(tmpdir):
-    """Verify that pickling trainer with neptune logger works."""
-    tutils.reset_seed()
-
-    # hparams = tutils.get_hparams()
-    # model = LightningTestModel(hparams)
-
-    logger = NeptuneLogger(offline_mode=True)
-
-    trainer_options = dict(
-        default_save_path=tmpdir,
-        max_epochs=1,
-        logger=logger
-    )
-
-    trainer = Trainer(**trainer_options)
-    pkl_bytes = pickle.dumps(trainer)
-    trainer2 = pickle.loads(pkl_bytes)
-    trainer2.logger.log_metrics({"acc": 1.0})
-
-
-def test_tensorboard_logger(tmpdir):
-    """Verify that basic functionality of Tensorboard logger works."""
-
-    hparams = tutils.get_hparams()
-    model = LightningTestModel(hparams)
-
-    logger = TensorBoardLogger(save_dir=tmpdir, name="tensorboard_logger_test")
-
-    trainer_options = dict(max_epochs=1, train_percent_check=0.01, logger=logger)
-
-    trainer = Trainer(**trainer_options)
-    result = trainer.fit(model)
-
-    print("result finished")
-    assert result == 1, "Training failed"
-
-
-def test_tensorboard_pickle(tmpdir):
-    """Verify that pickling trainer with Tensorboard logger works."""
-
-    # hparams = tutils.get_hparams()
-    # model = LightningTestModel(hparams)
-
-    logger = TensorBoardLogger(save_dir=tmpdir, name="tensorboard_pickle_test")
-
-    trainer_options = dict(max_epochs=1, logger=logger)
-
-    trainer = Trainer(**trainer_options)
-    pkl_bytes = pickle.dumps(trainer)
-    trainer2 = pickle.loads(pkl_bytes)
-    trainer2.logger.log_metrics({"acc": 1.0})
-
-
-def test_tensorboard_automatic_versioning(tmpdir):
-    """Verify that automatic versioning works"""
-
-    root_dir = tmpdir.mkdir("tb_versioning")
-    root_dir.mkdir("version_0")
-    root_dir.mkdir("version_1")
-
-    logger = TensorBoardLogger(save_dir=tmpdir, name="tb_versioning")
-
-    assert logger.version == 2
-
-
-def test_tensorboard_manual_versioning(tmpdir):
-    """Verify that manual versioning works"""
-
-    root_dir = tmpdir.mkdir("tb_versioning")
-    root_dir.mkdir("version_0")
-    root_dir.mkdir("version_1")
-    root_dir.mkdir("version_2")
-
-    logger = TensorBoardLogger(save_dir=tmpdir, name="tb_versioning", version=1)
-
-    assert logger.version == 1
-
-
-def test_tensorboard_named_version(tmpdir):
-    """Verify that manual versioning works for string versions, e.g. '2020-02-05-162402' """
-
-    tmpdir.mkdir("tb_versioning")
-    expected_version = "2020-02-05-162402"
-
-    logger = TensorBoardLogger(save_dir=tmpdir, name="tb_versioning", version=expected_version)
-    logger.log_hyperparams({"a": 1, "b": 2})  # Force data to be written
-
-    assert logger.version == expected_version
-    # Could also test existence of the directory but this fails in the "minimum requirements" test setup
-
-
-@pytest.mark.parametrize("step_idx", [10, None])
-def test_tensorboard_log_metrics(tmpdir, step_idx):
-    logger = TensorBoardLogger(tmpdir)
-    metrics = {
-        "float": 0.3,
-        "int": 1,
-        "FloatTensor": torch.tensor(0.1),
-        "IntTensor": torch.tensor(1)
-    }
-    logger.log_metrics(metrics, step_idx)
-
-
-def test_tensorboard_log_hyperparams(tmpdir):
-    logger = TensorBoardLogger(tmpdir)
-    hparams = {
-        "float": 0.3,
-        "int": 1,
-        "string": "abc",
-        "bool": True
-    }
-    logger.log_hyperparams(hparams)
-
-
-def test_custom_logger(tmpdir):
-    class CustomLogger(LightningLoggerBase):
-        def __init__(self):
-            super().__init__()
-            self.hparams_logged = None
-            self.metrics_logged = None
-            self.finalized = False
-
-        @rank_zero_only
-        def log_hyperparams(self, params):
-            self.hparams_logged = params
-
-        @rank_zero_only
-        def log_metrics(self, metrics, step):
-            self.metrics_logged = metrics
-
-        @rank_zero_only
-        def finalize(self, status):
-            self.finalized_status = status
-
-        @property
-        def name(self):
-            return "name"
-
-        @property
-        def version(self):
-            return "1"
-
-    hparams = tutils.get_hparams()
-    model = LightningTestModel(hparams)
-
-    logger = CustomLogger()
-
-    trainer_options = dict(
-        max_epochs=1,
-        train_percent_check=0.05,
-        logger=logger,
-        default_save_path=tmpdir
-    )
-
-    trainer = Trainer(**trainer_options)
-    result = trainer.fit(model)
-    assert result == 1, "Training failed"
-    assert logger.hparams_logged == hparams
-    assert logger.metrics_logged != {}
-    assert logger.finalized_status == "success"
-
-
-def test_adding_step_key(tmpdir):
-    logged_step = 0
-
-    def _validation_end(outputs):
-        nonlocal logged_step
-        logged_step += 1
-        return {"log": {"step": logged_step, "val_acc": logged_step / 10}}
-
-    def _log_metrics_decorator(log_metrics_fn):
-        def decorated(metrics, step):
-            if "val_acc" in metrics:
-                assert step == logged_step
-            return log_metrics_fn(metrics, step)
-
-        return decorated
-
-    model, hparams = tutils.get_model()
-    model.validation_end = _validation_end
-    trainer_options = dict(
-        max_epochs=4,
-        default_save_path=tmpdir,
-        train_percent_check=0.001,
-        val_percent_check=0.01,
-        num_sanity_val_steps=0
-    )
-    trainer = Trainer(**trainer_options)
-    trainer.logger.log_metrics = _log_metrics_decorator(trainer.logger.log_metrics)
-    trainer.fit(model)
diff --git a/tests/test_profiler.py b/tests/test_profiler.py
index 5fae874..d2bc1eb 100644
--- a/tests/test_profiler.py
+++ b/tests/test_profiler.py
@@ -1,22 +1,21 @@
 import time
+
 import numpy as np
 import pytest
 
 from pytorch_lightning.profiler import Profiler, AdvancedProfiler
 
-PROFILER_OVERHEAD_MAX_TOLERANCE = 0.001
+PROFILER_OVERHEAD_MAX_TOLERANCE = 0.0001
 
 
 @pytest.fixture
 def simple_profiler():
-    """Creates a new profiler for every test with `simple_profiler` as an arg."""
     profiler = Profiler()
     return profiler
 
 
 @pytest.fixture
 def advanced_profiler():
-    """Creates a new profiler for every test with `advanced_profiler` as an arg."""
     profiler = AdvancedProfiler()
     return profiler
 
@@ -51,13 +50,10 @@ def test_simple_profiler_describe(simple_profiler):
     simple_profiler.describe()
 
 
-def _get_total_cprofile_duration(profile):
-    return sum([x.totaltime for x in profile.getstats()])
-
-
 @pytest.mark.parametrize("action,expected", [("a", [3, 1]), ("b", [2]), ("c", [1])])
 def test_advanced_profiler_durations(advanced_profiler, action, expected):
-    """Ensure the reported durations are reasonably accurate."""
+    def _get_total_duration(profile):
+        return sum([x.totaltime for x in profile.getstats()])
 
     for duration in expected:
         with advanced_profiler.profile(action):
@@ -65,7 +61,7 @@ def test_advanced_profiler_durations(advanced_profiler, action, expected):
 
     # different environments have different precision when it comes to time.sleep()
     # see: https://github.com/PyTorchLightning/pytorch-lightning/issues/796
-    recored_total_duration = _get_total_cprofile_duration(
+    recored_total_duration = _get_total_duration(
         advanced_profiler.profiled_actions[action]
     )
     expected_total_duration = np.sum(expected)
@@ -75,17 +71,21 @@ def test_advanced_profiler_durations(advanced_profiler, action, expected):
 
 
 def test_advanced_profiler_overhead(advanced_profiler, n_iter=5):
-    """Ensure that the profiler doesn't introduce too much overhead during training."""
+    """
+    ensure that the profiler doesn't introduce too much overhead during training
+    """
     for _ in range(n_iter):
         with advanced_profiler.profile("no-op"):
             pass
 
     action_profile = advanced_profiler.profiled_actions["no-op"]
-    total_duration = _get_total_cprofile_duration(action_profile)
+    total_duration = sum([x.totaltime for x in action_profile.getstats()])
     average_duration = total_duration / n_iter
     assert average_duration < PROFILER_OVERHEAD_MAX_TOLERANCE
 
 
 def test_advanced_profiler_describe(advanced_profiler):
-    """Ensure the profiler won't fail when reporting the summary."""
+    """
+    ensure the profiler won't fail when reporting the summary
+    """
     advanced_profiler.describe()
diff --git a/tests/test_restore_models.py b/tests/test_restore_models.py
index 2bd033b..cf3a677 100644
--- a/tests/test_restore_models.py
+++ b/tests/test_restore_models.py
@@ -1,12 +1,19 @@
+import glob
 import logging as log
 import os
 
+import pytest
 import torch
 
 import tests.models.utils as tutils
 from pytorch_lightning import Trainer
 from pytorch_lightning.callbacks import ModelCheckpoint
-from tests.models import LightningTestModel
+from pytorch_lightning.utilities.debugging import MisconfigurationException
+from tests.models import (
+    LightningTestModel,
+    LightningTestModelWithoutHyperparametersArg,
+    LightningTestModelWithUnusedHyperparametersArg
+)
 
 
 def test_running_test_pretrained_model_ddp(tmpdir):
@@ -46,14 +53,18 @@ def test_running_test_pretrained_model_ddp(tmpdir):
     # correct result and ok accuracy
     assert result == 1, 'training failed to complete'
     pretrained_model = tutils.load_model(logger,
-                                         trainer.checkpoint_callback.filepath,
+                                         trainer.checkpoint_callback.dirpath,
                                          module_class=LightningTestModel)
 
     # run test set
     new_trainer = Trainer(**trainer_options)
     new_trainer.test(pretrained_model)
 
-    for dataloader in model.test_dataloader():
+    dataloaders = model.test_dataloader()
+    if not isinstance(dataloaders, list):
+        dataloaders = [dataloaders]
+
+    for dataloader in dataloaders:
         tutils.run_prediction(dataloader, pretrained_model)
 
 
@@ -86,7 +97,7 @@ def test_running_test_pretrained_model(tmpdir):
     # correct result and ok accuracy
     assert result == 1, 'training failed to complete'
     pretrained_model = tutils.load_model(
-        logger, trainer.checkpoint_callback.filepath, module_class=LightningTestModel
+        logger, trainer.checkpoint_callback.dirpath, module_class=LightningTestModel
     )
 
     new_trainer = Trainer(**trainer_options)
@@ -116,20 +127,23 @@ def test_load_model_from_checkpoint(tmpdir):
     # fit model
     trainer = Trainer(**trainer_options)
     result = trainer.fit(model)
+    trainer.test()
 
     # correct result and ok accuracy
     assert result == 1, 'training failed to complete'
 
     # load last checkpoint
-    last_checkpoint = os.path.join(trainer.checkpoint_callback.filepath, "_ckpt_epoch_1.ckpt")
-    if not os.path.isfile(last_checkpoint):
-        last_checkpoint = os.path.join(trainer.checkpoint_callback.filepath, "_ckpt_epoch_0.ckpt")
+    last_checkpoint = sorted(glob.glob(os.path.join(trainer.checkpoint_callback.dirpath, "*.ckpt")))[-1]
     pretrained_model = LightningTestModel.load_from_checkpoint(last_checkpoint)
 
     # test that hparams loaded correctly
     for k, v in vars(hparams).items():
         assert getattr(pretrained_model.hparams, k) == v
 
+    # assert weights are the same
+    for (old_name, old_p), (new_name, new_p) in zip(model.named_parameters(), pretrained_model.named_parameters()):
+        assert torch.all(torch.eq(old_p, new_p)), 'loaded weights are not the same as the saved weights'
+
     new_trainer = Trainer(**trainer_options)
     new_trainer.test(pretrained_model)
 
@@ -171,7 +185,7 @@ def test_running_test_pretrained_model_dp(tmpdir):
     # correct result and ok accuracy
     assert result == 1, 'training failed to complete'
     pretrained_model = tutils.load_model(logger,
-                                         trainer.checkpoint_callback.filepath,
+                                         trainer.checkpoint_callback.dirpath,
                                          module_class=LightningTestModel)
 
     new_trainer = Trainer(**trainer_options)
@@ -193,7 +207,7 @@ def test_dp_resume(tmpdir):
 
     trainer_options = dict(
         show_progress_bar=True,
-        max_epochs=2,
+        max_epochs=3,
         gpus=2,
         distributed_backend='dp',
     )
@@ -230,7 +244,7 @@ def test_dp_resume(tmpdir):
     new_logger = tutils.get_test_tube_logger(tmpdir, version=logger.version)
     trainer_options['logger'] = new_logger
     trainer_options['checkpoint_callback'] = ModelCheckpoint(tmpdir)
-    trainer_options['train_percent_check'] = 0.2
+    trainer_options['train_percent_check'] = 0.5
     trainer_options['val_percent_check'] = 0.2
     trainer_options['max_epochs'] = 1
     new_trainer = Trainer(**trainer_options)
@@ -244,7 +258,7 @@ def test_dp_resume(tmpdir):
         dp_model = new_trainer.model
         dp_model.eval()
 
-        dataloader = trainer.get_train_dataloader()
+        dataloader = trainer.train_dataloader
         tutils.run_prediction(dataloader, dp_model, dp=True)
 
     # new model
@@ -259,68 +273,6 @@ def test_dp_resume(tmpdir):
     model.unfreeze()
 
 
-def test_cpu_restore_training(tmpdir):
-    """Verify continue training session on CPU."""
-    tutils.reset_seed()
-
-    hparams = tutils.get_hparams()
-    model = LightningTestModel(hparams)
-
-    # logger file to get meta
-    test_logger_version = 10
-    logger = tutils.get_test_tube_logger(tmpdir, False, version=test_logger_version)
-
-    trainer_options = dict(
-        max_epochs=8,
-        val_check_interval=0.50,
-        val_percent_check=0.2,
-        train_percent_check=0.2,
-        logger=logger,
-        checkpoint_callback=ModelCheckpoint(tmpdir, save_top_k=-1)
-    )
-
-    # fit model
-    trainer = Trainer(**trainer_options)
-    result = trainer.fit(model)
-    # Increment since we've finished the current epoch, don't want to rerun
-    real_global_epoch = trainer.current_epoch + 1
-
-    # traning complete
-    assert result == 1, 'amp + ddp model failed to complete'
-
-    # wipe-out trainer and model
-    # retrain with not much data... this simulates picking training back up after slurm
-    # we want to see if the weights come back correctly
-    new_logger = tutils.get_test_tube_logger(tmpdir, False, version=test_logger_version)
-    trainer_options = dict(
-        max_epochs=2,
-        val_check_interval=0.50,
-        val_percent_check=0.2,
-        train_percent_check=0.2,
-        logger=new_logger,
-        checkpoint_callback=ModelCheckpoint(tmpdir),
-    )
-    trainer = Trainer(**trainer_options)
-    model = LightningTestModel(hparams)
-
-    # set the epoch start hook so we can predict before the model does the full training
-    def assert_good_acc():
-        assert trainer.current_epoch == real_global_epoch
-        assert trainer.current_epoch >= 0
-
-        # if model and state loaded correctly, predictions will be good even though we
-        # haven't trained with the new loaded model
-        trainer.model.eval()
-        for dataloader in trainer.get_val_dataloaders():
-            tutils.run_prediction(dataloader, trainer.model)
-
-    model.on_train_start = assert_good_acc
-
-    # by calling fit again, we trigger training, loading weights from the cluster
-    # and our hook to predict using current model before any more weight updates
-    trainer.fit(model)
-
-
 def test_model_saving_loading(tmpdir):
     """Tests use case where trainer saves the model, and user loads it from tags independently."""
     tutils.reset_seed()
@@ -345,7 +297,11 @@ def test_model_saving_loading(tmpdir):
     assert result == 1, 'amp + ddp model failed to complete'
 
     # make a prediction
-    for dataloader in model.test_dataloader():
+    dataloaders = model.test_dataloader()
+    if not isinstance(dataloaders, list):
+        dataloaders = [dataloaders]
+
+    for dataloader in dataloaders:
         for batch in dataloader:
             break
 
@@ -363,8 +319,10 @@ def test_model_saving_loading(tmpdir):
     # load new model
     tags_path = tutils.get_data_path(logger, path_dir=tmpdir)
     tags_path = os.path.join(tags_path, 'meta_tags.csv')
-    model_2 = LightningTestModel.load_from_metrics(weights_path=new_weights_path,
-                                                   tags_csv=tags_path)
+    model_2 = LightningTestModel.load_from_checkpoint(
+        checkpoint_path=new_weights_path,
+        tags_csv=tags_path
+    )
     model_2.eval()
 
     # make prediction
@@ -372,5 +330,39 @@ def test_model_saving_loading(tmpdir):
     new_pred = model_2(x)
     assert torch.all(torch.eq(pred_before_saving, new_pred)).item() == 1
 
+
+def test_load_model_with_missing_hparams(tmpdir):
+    trainer_options = dict(
+        show_progress_bar=False,
+        max_epochs=1,
+        checkpoint_callback=ModelCheckpoint(tmpdir, save_top_k=-1),
+        logger=False,
+        default_save_path=tmpdir,
+    )
+
+    # fit model
+    trainer = Trainer(**trainer_options)
+
+    model = LightningTestModelWithoutHyperparametersArg()
+    trainer.fit(model)
+    last_checkpoint = sorted(glob.glob(os.path.join(trainer.checkpoint_callback.dirpath, "*.ckpt")))[-1]
+
+    # try to load a checkpoint that has hparams but model is missing hparams arg
+    with pytest.raises(MisconfigurationException, match=r".*__init__ is missing the argument 'hparams'.*"):
+        LightningTestModelWithoutHyperparametersArg.load_from_checkpoint(last_checkpoint)
+
+    # create a checkpoint without hyperparameters
+    # if the model does not take a hparams argument, it should not throw an error
+    ckpt = torch.load(last_checkpoint)
+    del(ckpt['hparams'])
+    torch.save(ckpt, last_checkpoint)
+    LightningTestModelWithoutHyperparametersArg.load_from_checkpoint(last_checkpoint)
+
+    # load checkpoint without hparams again
+    # warn if user's model has hparams argument
+    with pytest.warns(UserWarning, match=r".*Will pass in an empty Namespace instead."):
+        LightningTestModelWithUnusedHyperparametersArg.load_from_checkpoint(last_checkpoint)
+
+
 # if __name__ == '__main__':
 #     pytest.main([__file__])
diff --git a/tests/test_trainer.py b/tests/test_trainer.py
deleted file mode 100644
index 231ef95..0000000
--- a/tests/test_trainer.py
+++ /dev/null
@@ -1,766 +0,0 @@
-import math
-import os
-
-import pytest
-import torch
-
-import tests.models.utils as tutils
-from pytorch_lightning import Trainer
-from pytorch_lightning.callbacks import (
-    EarlyStopping,
-    ModelCheckpoint,
-)
-from tests.models import (
-    LightningTestModel,
-    LightningTestModelBase,
-    LightningTestModelBaseWithoutDataloader,
-    LightningValidationStepMixin,
-    LightningValidationMultipleDataloadersMixin,
-    LightningTestMultipleDataloadersMixin,
-)
-from pytorch_lightning.core.lightning import load_hparams_from_tags_csv
-from pytorch_lightning.trainer.logging import TrainerLoggingMixin
-
-
-def test_no_val_module(tmpdir):
-    """Tests use case where trainer saves the model, and user loads it from tags independently."""
-    tutils.reset_seed()
-
-    hparams = tutils.get_hparams()
-
-    class CurrentTestModel(LightningTestModelBase):
-        pass
-
-    model = CurrentTestModel(hparams)
-
-    # logger file to get meta
-    logger = tutils.get_test_tube_logger(tmpdir, False)
-
-    trainer_options = dict(
-        max_epochs=1,
-        logger=logger,
-        checkpoint_callback=ModelCheckpoint(tmpdir)
-    )
-
-    # fit model
-    trainer = Trainer(**trainer_options)
-    result = trainer.fit(model)
-
-    # training complete
-    assert result == 1, 'amp + ddp model failed to complete'
-
-    # save model
-    new_weights_path = os.path.join(tmpdir, 'save_test.ckpt')
-    trainer.save_checkpoint(new_weights_path)
-
-    # load new model
-    tags_path = tutils.get_data_path(logger, path_dir=tmpdir)
-    tags_path = os.path.join(tags_path, 'meta_tags.csv')
-    model_2 = LightningTestModel.load_from_metrics(weights_path=new_weights_path,
-                                                   tags_csv=tags_path)
-    model_2.eval()
-
-
-def test_no_val_end_module(tmpdir):
-    """Tests use case where trainer saves the model, and user loads it from tags independently."""
-    tutils.reset_seed()
-
-    class CurrentTestModel(LightningValidationStepMixin, LightningTestModelBase):
-        pass
-
-    hparams = tutils.get_hparams()
-    model = CurrentTestModel(hparams)
-
-    # logger file to get meta
-    logger = tutils.get_test_tube_logger(tmpdir, False)
-
-    trainer_options = dict(
-        max_epochs=1,
-        logger=logger,
-        checkpoint_callback=ModelCheckpoint(tmpdir)
-    )
-
-    # fit model
-    trainer = Trainer(**trainer_options)
-    result = trainer.fit(model)
-
-    # traning complete
-    assert result == 1, 'amp + ddp model failed to complete'
-
-    # save model
-    new_weights_path = os.path.join(tmpdir, 'save_test.ckpt')
-    trainer.save_checkpoint(new_weights_path)
-
-    # load new model
-    tags_path = tutils.get_data_path(logger, path_dir=tmpdir)
-    tags_path = os.path.join(tags_path, 'meta_tags.csv')
-    model_2 = LightningTestModel.load_from_metrics(weights_path=new_weights_path,
-                                                   tags_csv=tags_path)
-    model_2.eval()
-
-
-def test_gradient_accumulation_scheduling(tmpdir):
-    """
-    Test grad accumulation by the freq of optimizer updates
-    """
-    tutils.reset_seed()
-
-    # test incorrect configs
-    with pytest.raises(IndexError):
-        assert Trainer(accumulate_grad_batches={0: 3, 1: 4, 4: 6})
-        assert Trainer(accumulate_grad_batches={-2: 3})
-
-    with pytest.raises(TypeError):
-        assert Trainer(accumulate_grad_batches={})
-        assert Trainer(accumulate_grad_batches=[[2, 3], [4, 6]])
-        assert Trainer(accumulate_grad_batches={1: 2, 3.: 4})
-        assert Trainer(accumulate_grad_batches={1: 2.5, 3: 5})
-
-    # test optimizer call freq matches scheduler
-    def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_idx, second_order_closure=None):
-        # only test the first 12 batches in epoch
-        if batch_idx < 12:
-            if epoch == 0:
-                # reset counter when starting epoch
-                if batch_idx == 0:
-                    self.prev_called_batch_idx = 0
-
-                    # use this opportunity to test once
-                    assert self.trainer.accumulate_grad_batches == 1
-
-                assert batch_idx == self.prev_called_batch_idx
-                self.prev_called_batch_idx += 1
-
-            elif 1 <= epoch <= 2:
-                # reset counter when starting epoch
-                if batch_idx == 1:
-                    self.prev_called_batch_idx = 1
-
-                    # use this opportunity to test once
-                    assert self.trainer.accumulate_grad_batches == 2
-
-                assert batch_idx == self.prev_called_batch_idx
-                self.prev_called_batch_idx += 2
-
-            else:
-                if batch_idx == 3:
-                    self.prev_called_batch_idx = 3
-
-                    # use this opportunity to test once
-                    assert self.trainer.accumulate_grad_batches == 4
-
-                assert batch_idx == self.prev_called_batch_idx
-                self.prev_called_batch_idx += 3
-
-        optimizer.step()
-
-        # clear gradients
-        optimizer.zero_grad()
-
-    hparams = tutils.get_hparams()
-    model = LightningTestModel(hparams)
-    schedule = {1: 2, 3: 4}
-
-    trainer = Trainer(accumulate_grad_batches=schedule,
-                      train_percent_check=0.1,
-                      val_percent_check=0.1,
-                      max_epochs=4,
-                      default_save_path=tmpdir)
-
-    # for the test
-    trainer.optimizer_step = optimizer_step
-    model.prev_called_batch_idx = 0
-
-    trainer.fit(model)
-
-
-def test_loading_meta_tags(tmpdir):
-    tutils.reset_seed()
-
-    from argparse import Namespace
-    hparams = tutils.get_hparams()
-
-    # save tags
-    logger = tutils.get_test_tube_logger(tmpdir, False)
-    logger.log_hyperparams(Namespace(some_str='a_str', an_int=1, a_float=2.0))
-    logger.log_hyperparams(hparams)
-    logger.save()
-
-    # load tags
-    path_expt_dir = tutils.get_data_path(logger, path_dir=tmpdir)
-    tags_path = os.path.join(path_expt_dir, 'meta_tags.csv')
-    tags = load_hparams_from_tags_csv(tags_path)
-
-    assert tags.batch_size == 32 and tags.hidden_dim == 1000
-
-
-def test_dp_output_reduce():
-    mixin = TrainerLoggingMixin()
-    tutils.reset_seed()
-
-    # test identity when we have a single gpu
-    out = torch.rand(3, 1)
-    assert mixin.reduce_distributed_output(out, num_gpus=1) is out
-
-    # average when we have multiples
-    assert mixin.reduce_distributed_output(out, num_gpus=2) == out.mean()
-
-    # when we have a dict of vals
-    out = {
-        'a': out,
-        'b': {
-            'c': out
-        }
-    }
-    reduced = mixin.reduce_distributed_output(out, num_gpus=3)
-    assert reduced['a'] == out['a']
-    assert reduced['b']['c'] == out['b']['c']
-
-
-def test_model_checkpoint_options(tmp_path):
-    """Test ModelCheckpoint options."""
-    def mock_save_function(filepath):
-        open(filepath, 'a').close()
-
-    hparams = tutils.get_hparams()
-    _ = LightningTestModel(hparams)
-
-    # simulated losses
-    save_dir = tmp_path / "1"
-    save_dir.mkdir()
-    losses = [10, 9, 2.8, 5, 2.5]
-
-    # -----------------
-    # CASE K=-1  (all)
-    checkpoint_callback = ModelCheckpoint(save_dir, save_top_k=-1, verbose=1)
-    checkpoint_callback.save_function = mock_save_function
-    trainer = Trainer()
-    checkpoint_callback.set_trainer(trainer)
-
-    # emulate callback's calls during the training
-    for i, loss in enumerate(losses):
-        checkpoint_callback._trainer.current_epoch = i
-        checkpoint_callback._trainer.callback_metrics = {'val_loss': loss}
-        checkpoint_callback.on_validation_end()
-
-    file_lists = set(os.listdir(save_dir))
-
-    assert len(file_lists) == len(losses), "Should save all models when save_top_k=-1"
-
-    # verify correct naming
-    for i in range(0, len(losses)):
-        assert f'_ckpt_epoch_{i}.ckpt' in file_lists
-
-    save_dir = tmp_path / "2"
-    save_dir.mkdir()
-
-    # -----------------
-    # CASE K=0 (none)
-    checkpoint_callback = ModelCheckpoint(save_dir, save_top_k=0, verbose=1)
-    checkpoint_callback.save_function = mock_save_function
-    trainer = Trainer()
-    checkpoint_callback.set_trainer(trainer)
-
-    # emulate callback's calls during the training
-    for i, loss in enumerate(losses):
-        checkpoint_callback._trainer.current_epoch = i
-        checkpoint_callback._trainer.callback_metrics = {'val_loss': loss}
-        checkpoint_callback.on_validation_end()
-
-    file_lists = os.listdir(save_dir)
-
-    assert len(file_lists) == 0, "Should save 0 models when save_top_k=0"
-
-    save_dir = tmp_path / "3"
-    save_dir.mkdir()
-
-    # -----------------
-    # CASE K=1 (2.5, epoch 4)
-    checkpoint_callback = ModelCheckpoint(save_dir, save_top_k=1, verbose=1, prefix='test_prefix')
-    checkpoint_callback.save_function = mock_save_function
-    trainer = Trainer()
-    checkpoint_callback.set_trainer(trainer)
-
-    # emulate callback's calls during the training
-    for i, loss in enumerate(losses):
-        checkpoint_callback._trainer.current_epoch = i
-        checkpoint_callback._trainer.callback_metrics = {'val_loss': loss}
-        checkpoint_callback.on_validation_end()
-
-    file_lists = set(os.listdir(save_dir))
-
-    assert len(file_lists) == 1, "Should save 1 model when save_top_k=1"
-    assert 'test_prefix_ckpt_epoch_4.ckpt' in file_lists
-
-    save_dir = tmp_path / "4"
-    save_dir.mkdir()
-
-    # -----------------
-    # CASE K=2 (2.5 epoch 4, 2.8 epoch 2)
-    # make sure other files don't get deleted
-
-    checkpoint_callback = ModelCheckpoint(save_dir, save_top_k=2, verbose=1)
-    open(f'{save_dir}/other_file.ckpt', 'a').close()
-    checkpoint_callback.save_function = mock_save_function
-    trainer = Trainer()
-    checkpoint_callback.set_trainer(trainer)
-
-    # emulate callback's calls during the training
-    for i, loss in enumerate(losses):
-        checkpoint_callback._trainer.current_epoch = i
-        checkpoint_callback._trainer.callback_metrics = {'val_loss': loss}
-        checkpoint_callback.on_validation_end()
-
-    file_lists = set(os.listdir(save_dir))
-
-    assert len(file_lists) == 3, 'Should save 2 model when save_top_k=2'
-    assert '_ckpt_epoch_4.ckpt' in file_lists
-    assert '_ckpt_epoch_2.ckpt' in file_lists
-    assert 'other_file.ckpt' in file_lists
-
-    save_dir = tmp_path / "5"
-    save_dir.mkdir()
-
-    # -----------------
-    # CASE K=4 (save all 4 models)
-    # multiple checkpoints within same epoch
-
-    checkpoint_callback = ModelCheckpoint(save_dir, save_top_k=4, verbose=1)
-    checkpoint_callback.save_function = mock_save_function
-    trainer = Trainer()
-    checkpoint_callback.set_trainer(trainer)
-
-    # emulate callback's calls during the training
-    for loss in losses:
-        checkpoint_callback._trainer.current_epoch = 0
-        checkpoint_callback._trainer.callback_metrics = {'val_loss': loss}
-        checkpoint_callback.on_validation_end()
-
-    file_lists = set(os.listdir(save_dir))
-
-    assert len(file_lists) == 4, 'Should save all 4 models when save_top_k=4 within same epoch'
-
-    save_dir = tmp_path / "6"
-    save_dir.mkdir()
-
-    # -----------------
-    # CASE K=3 (save the 2nd, 3rd, 4th model)
-    # multiple checkpoints within same epoch
-
-    checkpoint_callback = ModelCheckpoint(save_dir, save_top_k=3, verbose=1)
-    checkpoint_callback.save_function = mock_save_function
-    trainer = Trainer()
-    checkpoint_callback.set_trainer(trainer)
-
-    # emulate callback's calls during the training
-    for loss in losses:
-        checkpoint_callback._trainer.current_epoch = 0
-        checkpoint_callback._trainer.callback_metrics = {'val_loss': loss}
-        checkpoint_callback.on_validation_end()
-
-    file_lists = set(os.listdir(save_dir))
-
-    assert len(file_lists) == 3, 'Should save 3 models when save_top_k=3'
-    assert '_ckpt_epoch_0_v2.ckpt' in file_lists
-    assert '_ckpt_epoch_0_v1.ckpt' in file_lists
-    assert '_ckpt_epoch_0.ckpt' in file_lists
-
-
-def test_model_freeze_unfreeze():
-    tutils.reset_seed()
-
-    hparams = tutils.get_hparams()
-    model = LightningTestModel(hparams)
-
-    model.freeze()
-    model.unfreeze()
-
-
-def test_multiple_val_dataloader(tmpdir):
-    """Verify multiple val_dataloader."""
-    tutils.reset_seed()
-
-    class CurrentTestModel(
-        LightningValidationMultipleDataloadersMixin,
-        LightningTestModelBase
-    ):
-        pass
-
-    hparams = tutils.get_hparams()
-    model = CurrentTestModel(hparams)
-
-    # logger file to get meta
-    trainer_options = dict(
-        default_save_path=tmpdir,
-        max_epochs=1,
-        val_percent_check=0.1,
-        train_percent_check=1.0,
-    )
-
-    # fit model
-    trainer = Trainer(**trainer_options)
-    result = trainer.fit(model)
-
-    # verify training completed
-    assert result == 1
-
-    # verify there are 2 val loaders
-    assert len(trainer.get_val_dataloaders()) == 2, \
-        'Multiple val_dataloaders not initiated properly'
-
-    # make sure predictions are good for each val set
-    for dataloader in trainer.get_val_dataloaders():
-        tutils.run_prediction(dataloader, trainer.model)
-
-
-def test_resume_from_checkpoint_epoch_restored(tmpdir):
-    """Verify resuming from checkpoint runs the right number of epochs"""
-    import types
-
-    tutils.reset_seed()
-
-    hparams = tutils.get_hparams()
-
-    def new_model():
-        # Create a model that tracks epochs and batches seen
-        model = LightningTestModel(hparams)
-        model.num_epochs_seen = 0
-        model.num_batches_seen = 0
-
-        def increment_epoch(self):
-            self.num_epochs_seen += 1
-
-        def increment_batch(self, _):
-            self.num_batches_seen += 1
-
-        # Bind the increment_epoch function on_epoch_end so that the
-        # model keeps track of the number of epochs it has seen.
-        model.on_epoch_end = types.MethodType(increment_epoch, model)
-        model.on_batch_start = types.MethodType(increment_batch, model)
-        return model
-
-    model = new_model()
-
-    trainer_options = dict(
-        show_progress_bar=False,
-        max_epochs=2,
-        train_percent_check=0.65,
-        val_percent_check=1,
-        checkpoint_callback=ModelCheckpoint(tmpdir, save_top_k=-1),
-        logger=False,
-        default_save_path=tmpdir,
-        early_stop_callback=False,
-        val_check_interval=0.5,
-    )
-
-    # fit model
-    trainer = Trainer(**trainer_options)
-    trainer.fit(model)
-
-    training_batches = trainer.num_training_batches
-
-    assert model.num_epochs_seen == 2
-    assert model.num_batches_seen == training_batches * 2
-
-    # Other checkpoints can be uncommented if/when resuming mid-epoch is supported
-    checkpoints = [
-        # os.path.join(trainer.checkpoint_callback.filepath, "_ckpt_epoch_0.ckpt"),
-        os.path.join(trainer.checkpoint_callback.filepath, "_ckpt_epoch_0_v0.ckpt"),
-        # os.path.join(trainer.checkpoint_callback.filepath, "_ckpt_epoch_1.ckpt"),
-        os.path.join(trainer.checkpoint_callback.filepath, "_ckpt_epoch_1_v0.ckpt"),
-    ]
-
-    for check in checkpoints:
-        next_model = new_model()
-        state = torch.load(check)
-
-        # Resume training
-        trainer_options['max_epochs'] = 4
-        new_trainer = Trainer(**trainer_options, resume_from_checkpoint=check)
-        new_trainer.fit(next_model)
-        assert state['global_step'] + next_model.num_batches_seen == training_batches * 4
-
-
-def test_multiple_test_dataloader(tmpdir):
-    """Verify multiple test_dataloader."""
-    tutils.reset_seed()
-
-    class CurrentTestModel(
-        LightningTestMultipleDataloadersMixin,
-        LightningTestModelBase
-    ):
-        pass
-
-    hparams = tutils.get_hparams()
-    model = CurrentTestModel(hparams)
-
-    # logger file to get meta
-    trainer_options = dict(
-        default_save_path=tmpdir,
-        max_epochs=1,
-        val_percent_check=0.1,
-        train_percent_check=0.2
-    )
-
-    # fit model
-    trainer = Trainer(**trainer_options)
-    result = trainer.fit(model)
-
-    # verify there are 2 val loaders
-    assert len(trainer.get_test_dataloaders()) == 2, \
-        'Multiple test_dataloaders not initiated properly'
-
-    # make sure predictions are good for each test set
-    for dataloader in trainer.get_test_dataloaders():
-        tutils.run_prediction(dataloader, trainer.model)
-
-    # run the test method
-    trainer.test()
-
-
-def test_train_dataloaders_passed_to_fit(tmpdir):
-    """ Verify that train dataloader can be passed to fit """
-    tutils.reset_seed()
-
-    class CurrentTestModel(
-        LightningTestModelBaseWithoutDataloader
-    ):
-        pass
-
-    hparams = tutils.get_hparams()
-
-    # logger file to get meta
-    trainer_options = dict(
-        default_save_path=tmpdir,
-        max_epochs=1,
-        val_percent_check=0.1,
-        train_percent_check=0.2
-    )
-
-    # only train passed to fit
-    model = CurrentTestModel(hparams)
-    trainer = Trainer(**trainer_options)
-    fit_options = dict(train_dataloader=model._dataloader(train=True))
-    results = trainer.fit(model, **fit_options)
-
-
-def test_train_val_dataloaders_passed_to_fit(tmpdir):
-    """ Verify that train & val dataloader can be passed to fit """
-    tutils.reset_seed()
-
-    class CurrentTestModel(
-        LightningTestModelBaseWithoutDataloader
-    ):
-        pass
-
-    hparams = tutils.get_hparams()
-
-    # logger file to get meta
-    trainer_options = dict(
-        default_save_path=tmpdir,
-        max_epochs=1,
-        val_percent_check=0.1,
-        train_percent_check=0.2
-    )
-
-    # train, val passed to fit
-    model = CurrentTestModel(hparams)
-    trainer = Trainer(**trainer_options)
-    fit_options = dict(train_dataloader=model._dataloader(train=True),
-                       val_dataloader=model._dataloader(train=False))
-    results = trainer.fit(model, **fit_options)
-    assert len(trainer.get_val_dataloaders()) == 1, \
-        f'`val_dataloaders` not initiated properly, got {trainer.get_val_dataloaders()}'
-
-
-def test_all_dataloaders_passed_to_fit(tmpdir):
-    """ Verify train, val & test dataloader can be passed to fit """
-    tutils.reset_seed()
-
-    class CurrentTestModel(
-        LightningTestModelBaseWithoutDataloader
-    ):
-        pass
-
-    hparams = tutils.get_hparams()
-
-    # logger file to get meta
-    trainer_options = dict(
-        default_save_path=tmpdir,
-        max_epochs=1,
-        val_percent_check=0.1,
-        train_percent_check=0.2
-    )
-
-    # train, val and test passed to fit
-    model = CurrentTestModel(hparams)
-    trainer = Trainer(**trainer_options)
-    fit_options = dict(train_dataloader=model._dataloader(train=True),
-                       val_dataloader=model._dataloader(train=False),
-                       test_dataloader=model._dataloader(train=False))
-    results = trainer.fit(model, **fit_options)
-
-    assert len(trainer.get_val_dataloaders()) == 1, \
-        f'`val_dataloaders` not initiated properly, got {trainer.get_val_dataloaders()}'
-    assert len(trainer.get_test_dataloaders()) == 1, \
-        f'`test_dataloaders` not initiated properly, got {trainer.get_test_dataloaders()}'
-
-
-def test_multiple_dataloaders_passed_to_fit(tmpdir):
-    """ Verify that multiple val & test dataloaders can be passed to fit """
-    tutils.reset_seed()
-
-    class CurrentTestModel(
-        LightningTestModelBaseWithoutDataloader
-    ):
-        pass
-
-    hparams = tutils.get_hparams()
-
-    # logger file to get meta
-    trainer_options = dict(
-        default_save_path=tmpdir,
-        max_epochs=1,
-        val_percent_check=0.1,
-        train_percent_check=0.2
-    )
-
-    # train, multiple val and multiple test passed to fit
-    model = CurrentTestModel(hparams)
-    trainer = Trainer(**trainer_options)
-    fit_options = dict(train_dataloader=model._dataloader(train=True),
-                       val_dataloader=[model._dataloader(train=False),
-                                       model._dataloader(train=False)],
-                       test_dataloader=[model._dataloader(train=False),
-                                        model._dataloader(train=False)])
-    results = trainer.fit(model, **fit_options)
-
-    assert len(trainer.get_val_dataloaders()) == 2, \
-        f'Multiple `val_dataloaders` not initiated properly, got {trainer.get_val_dataloaders()}'
-    assert len(trainer.get_test_dataloaders()) == 2, \
-        f'Multiple `test_dataloaders` not initiated properly, got {trainer.get_test_dataloaders()}'
-
-
-def test_mixing_of_dataloader_options(tmpdir):
-    """Verify that dataloaders can be passed to fit"""
-    tutils.reset_seed()
-
-    class CurrentTestModel(
-        LightningTestModelBase
-    ):
-        pass
-
-    hparams = tutils.get_hparams()
-    model = CurrentTestModel(hparams)
-
-    # logger file to get meta
-    trainer_options = dict(
-        default_save_path=tmpdir,
-        max_epochs=1,
-        val_percent_check=0.1,
-        train_percent_check=0.2
-    )
-
-    # fit model
-    trainer = Trainer(**trainer_options)
-    fit_options = dict(val_dataloader=model._dataloader(train=False))
-    results = trainer.fit(model, **fit_options)
-
-    # fit model
-    trainer = Trainer(**trainer_options)
-    fit_options = dict(val_dataloader=model._dataloader(train=False),
-                       test_dataloader=model._dataloader(train=False))
-    results = trainer.fit(model, **fit_options)
-    assert len(trainer.get_val_dataloaders()) == 1, \
-        f'`val_dataloaders` not initiated properly, got {trainer.get_val_dataloaders()}'
-    assert len(trainer.get_test_dataloaders()) == 1, \
-        f'`test_dataloaders` not initiated properly, got {trainer.get_test_dataloaders()}'
-
-
-def _init_steps_model():
-    """private method for initializing a model with 5% train epochs"""
-    tutils.reset_seed()
-    model, _ = tutils.get_model()
-
-    # define train epoch to 5% of data
-    train_percent = 0.05
-    # get number of samples in 1 epoch
-    num_train_samples = math.floor(len(model.train_dataloader()) * train_percent)
-
-    trainer_options = dict(
-        train_percent_check=train_percent,
-    )
-    return model, trainer_options, num_train_samples
-
-
-def test_trainer_max_steps_and_epochs(tmpdir):
-    """Verify model trains according to specified max steps"""
-    model, trainer_options, num_train_samples = _init_steps_model()
-
-    # define less train steps than epochs
-    trainer_options.update(dict(
-        max_epochs=5,
-        max_steps=num_train_samples + 10
-    ))
-
-    # fit model
-    trainer = Trainer(**trainer_options)
-    result = trainer.fit(model)
-    assert result == 1, "Training did not complete"
-
-    # check training stopped at max_steps
-    assert trainer.global_step == trainer.max_steps, "Model did not stop at max_steps"
-
-    # define less train epochs than steps
-    trainer_options['max_epochs'] = 2
-    trainer_options['max_steps'] = trainer_options['max_epochs'] * 2 * num_train_samples
-
-    # fit model
-    trainer = Trainer(**trainer_options)
-    result = trainer.fit(model)
-    assert result == 1, "Training did not complete"
-
-    # check training stopped at max_epochs
-    assert trainer.global_step == num_train_samples * trainer.max_nb_epochs \
-        and trainer.current_epoch == trainer.max_nb_epochs - 1, "Model did not stop at max_epochs"
-
-
-def test_trainer_min_steps_and_epochs(tmpdir):
-    """Verify model trains according to specified min steps"""
-    model, trainer_options, num_train_samples = _init_steps_model()
-
-    # define callback for stopping the model and default epochs
-    trainer_options.update({
-        'early_stop_callback': EarlyStopping(monitor='val_loss', min_delta=1.0),
-        'val_check_interval': 20,
-        'min_epochs': 1,
-        'max_epochs': 10
-    })
-
-    # define less min steps than 1 epoch
-    trainer_options['min_steps'] = math.floor(num_train_samples / 2)
-
-    # fit model
-    trainer = Trainer(**trainer_options)
-    result = trainer.fit(model)
-    assert result == 1, "Training did not complete"
-
-    # check model ran for at least min_epochs
-    assert trainer.global_step >= num_train_samples and \
-        trainer.current_epoch > 0, "Model did not train for at least min_epochs"
-
-    # define less epochs than min_steps
-    trainer_options['min_steps'] = math.floor(num_train_samples * 1.5)
-
-    # fit model
-    trainer = Trainer(**trainer_options)
-    result = trainer.fit(model)
-    assert result == 1, "Training did not complete"
-
-    # check model ran for at least num_train_samples*1.5
-    assert trainer.global_step >= math.floor(num_train_samples * 1.5) and \
-        trainer.current_epoch > 0, "Model did not train for at least min_steps"
-
-
-# if __name__ == '__main__':
-#     pytest.main([__file__])
diff --git a/tests/trainer/__init__.py b/tests/trainer/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/tests/trainer/test_callbacks.py b/tests/trainer/test_callbacks.py
new file mode 100644
index 0000000..55a8463
--- /dev/null
+++ b/tests/trainer/test_callbacks.py
@@ -0,0 +1,155 @@
+import os
+
+import tests.models.utils as tutils
+from pytorch_lightning import Callback
+from pytorch_lightning import Trainer, LightningModule
+from pytorch_lightning.callbacks import ModelCheckpoint
+from tests.models import (
+    TestModelBase,
+    LightTrainDataloader,
+    LightValidationMixin,
+    LightTestMixin
+)
+
+
+def test_trainer_callback_system(tmpdir):
+    """Test the callback system."""
+
+    class CurrentTestModel(
+        LightTrainDataloader,
+        LightTestMixin,
+        LightValidationMixin,
+        TestModelBase,
+    ):
+        pass
+
+    hparams = tutils.get_hparams()
+    model = CurrentTestModel(hparams)
+
+    def _check_args(trainer, pl_module):
+        assert isinstance(trainer, Trainer)
+        assert isinstance(pl_module, LightningModule)
+
+    class TestCallback(Callback):
+        def __init__(self):
+            super().__init__()
+            self.on_init_start_called = False
+            self.on_init_end_called = False
+            self.on_epoch_start_called = False
+            self.on_epoch_end_called = False
+            self.on_batch_start_called = False
+            self.on_batch_end_called = False
+            self.on_train_start_called = False
+            self.on_train_end_called = False
+            self.on_validation_start_called = False
+            self.on_validation_end_called = False
+            self.on_test_start_called = False
+            self.on_test_end_called = False
+
+        def on_init_start(self, trainer):
+            assert isinstance(trainer, Trainer)
+            self.on_init_start_called = True
+
+        def on_init_end(self, trainer):
+            assert isinstance(trainer, Trainer)
+            self.on_init_end_called = True
+
+        def on_epoch_start(self, trainer, pl_module):
+            _check_args(trainer, pl_module)
+            self.on_epoch_start_called = True
+
+        def on_epoch_end(self, trainer, pl_module):
+            _check_args(trainer, pl_module)
+            self.on_epoch_end_called = True
+
+        def on_batch_start(self, trainer, pl_module):
+            _check_args(trainer, pl_module)
+            self.on_batch_start_called = True
+
+        def on_batch_end(self, trainer, pl_module):
+            _check_args(trainer, pl_module)
+            self.on_batch_end_called = True
+
+        def on_train_start(self, trainer, pl_module):
+            _check_args(trainer, pl_module)
+            self.on_train_start_called = True
+
+        def on_train_end(self, trainer, pl_module):
+            _check_args(trainer, pl_module)
+            self.on_train_end_called = True
+
+        def on_validation_start(self, trainer, pl_module):
+            _check_args(trainer, pl_module)
+            self.on_validation_start_called = True
+
+        def on_validation_end(self, trainer, pl_module):
+            _check_args(trainer, pl_module)
+            self.on_validation_end_called = True
+
+        def on_test_start(self, trainer, pl_module):
+            _check_args(trainer, pl_module)
+            self.on_test_start_called = True
+
+        def on_test_end(self, trainer, pl_module):
+            _check_args(trainer, pl_module)
+            self.on_test_end_called = True
+
+    test_callback = TestCallback()
+
+    trainer_options = {
+        'callbacks': [test_callback],
+        'max_epochs': 1,
+        'val_percent_check': 0.1,
+        'train_percent_check': 0.2,
+        'show_progress_bar': False
+    }
+
+    assert not test_callback.on_init_start_called
+    assert not test_callback.on_init_end_called
+    assert not test_callback.on_epoch_start_called
+    assert not test_callback.on_epoch_start_called
+    assert not test_callback.on_batch_start_called
+    assert not test_callback.on_batch_end_called
+    assert not test_callback.on_train_start_called
+    assert not test_callback.on_train_end_called
+    assert not test_callback.on_validation_start_called
+    assert not test_callback.on_validation_end_called
+    assert not test_callback.on_test_start_called
+    assert not test_callback.on_test_end_called
+
+    # fit model
+    trainer = Trainer(**trainer_options)
+
+    assert trainer.callbacks[0] == test_callback
+    assert test_callback.on_init_start_called
+    assert test_callback.on_init_end_called
+    assert not test_callback.on_epoch_start_called
+    assert not test_callback.on_epoch_start_called
+    assert not test_callback.on_batch_start_called
+    assert not test_callback.on_batch_end_called
+    assert not test_callback.on_train_start_called
+    assert not test_callback.on_train_end_called
+    assert not test_callback.on_validation_start_called
+    assert not test_callback.on_validation_end_called
+    assert not test_callback.on_test_start_called
+    assert not test_callback.on_test_end_called
+
+    trainer.fit(model)
+
+    assert test_callback.on_init_start_called
+    assert test_callback.on_init_end_called
+    assert test_callback.on_epoch_start_called
+    assert test_callback.on_epoch_start_called
+    assert test_callback.on_batch_start_called
+    assert test_callback.on_batch_end_called
+    assert test_callback.on_train_start_called
+    assert test_callback.on_train_end_called
+    assert test_callback.on_validation_start_called
+    assert test_callback.on_validation_end_called
+    assert not test_callback.on_test_start_called
+    assert not test_callback.on_test_end_called
+
+    trainer.test()
+
+    assert test_callback.on_test_start_called
+    assert test_callback.on_test_end_called
diff --git a/tests/trainer/test_dataloaders.py b/tests/trainer/test_dataloaders.py
new file mode 100644
index 0000000..40670da
--- /dev/null
+++ b/tests/trainer/test_dataloaders.py
@@ -0,0 +1,452 @@
+import pytest
+
+import tests.models.utils as tutils
+from pytorch_lightning import Trainer
+from pytorch_lightning.utilities.debugging import MisconfigurationException
+from tests.models import (
+    TestModelBase,
+    LightningTestModel,
+    LightEmptyTestStep,
+    LightValidationMultipleDataloadersMixin,
+    LightTestMultipleDataloadersMixin,
+    LightTestFitSingleTestDataloadersMixin,
+    LightTestFitMultipleTestDataloadersMixin,
+    LightValStepFitMultipleDataloadersMixin,
+    LightValStepFitSingleDataloaderMixin,
+    LightTrainDataloader,
+    LightInfTrainDataloader,
+    LightInfValDataloader,
+    LightInfTestDataloader
+)
+
+
+def test_dataloader_config_errors(tmpdir):
+    tutils.reset_seed()
+
+    class CurrentTestModel(
+        LightTrainDataloader,
+        TestModelBase,
+    ):
+        pass
+
+    hparams = tutils.get_hparams()
+    model = CurrentTestModel(hparams)
+
+    # percent check < 0
+
+    # logger file to get meta
+    trainer_options = dict(
+        default_save_path=tmpdir,
+        max_epochs=1,
+        train_percent_check=-0.1,
+    )
+
+    # fit model
+    trainer = Trainer(**trainer_options)
+
+    with pytest.raises(ValueError):
+        trainer.fit(model)
+
+    # percent check > 1
+
+    # logger file to get meta
+    trainer_options = dict(
+        default_save_path=tmpdir,
+        max_epochs=1,
+        train_percent_check=1.1,
+    )
+
+    # fit model
+    trainer = Trainer(**trainer_options)
+
+    with pytest.raises(ValueError):
+        trainer.fit(model)
+
+    # int val_check_interval > num batches
+
+    # logger file to get meta
+    trainer_options = dict(
+        default_save_path=tmpdir,
+        max_epochs=1,
+        val_check_interval=10000
+    )
+
+    # fit model
+    trainer = Trainer(**trainer_options)
+
+    with pytest.raises(ValueError):
+        trainer.fit(model)
+
+    # float val_check_interval > 1
+
+    # logger file to get meta
+    trainer_options = dict(
+        default_save_path=tmpdir,
+        max_epochs=1,
+        val_check_interval=1.1
+    )
+
+    # fit model
+    trainer = Trainer(**trainer_options)
+
+    with pytest.raises(ValueError):
+        trainer.fit(model)
+
+
+def test_multiple_val_dataloader(tmpdir):
+    """Verify multiple val_dataloader."""
+    tutils.reset_seed()
+
+    class CurrentTestModel(
+        LightTrainDataloader,
+        LightValidationMultipleDataloadersMixin,
+        TestModelBase,
+    ):
+        pass
+
+    hparams = tutils.get_hparams()
+    model = CurrentTestModel(hparams)
+
+    # logger file to get meta
+    trainer_options = dict(
+        default_save_path=tmpdir,
+        max_epochs=1,
+        val_percent_check=0.1,
+        train_percent_check=1.0,
+    )
+
+    # fit model
+    trainer = Trainer(**trainer_options)
+    result = trainer.fit(model)
+
+    # verify training completed
+    assert result == 1
+
+    # verify there are 2 val loaders
+    assert len(trainer.val_dataloaders) == 2, \
+        'Multiple val_dataloaders not initiated properly'
+
+    # make sure predictions are good for each val set
+    for dataloader in trainer.val_dataloaders:
+        tutils.run_prediction(dataloader, trainer.model)
+
+
+def test_multiple_test_dataloader(tmpdir):
+    """Verify multiple test_dataloader."""
+    tutils.reset_seed()
+
+    class CurrentTestModel(
+        LightTrainDataloader,
+        LightTestMultipleDataloadersMixin,
+        LightEmptyTestStep,
+        TestModelBase,
+    ):
+        pass
+
+    hparams = tutils.get_hparams()
+    model = CurrentTestModel(hparams)
+
+    # logger file to get meta
+    trainer_options = dict(
+        default_save_path=tmpdir,
+        max_epochs=1,
+        val_percent_check=0.1,
+        train_percent_check=0.2
+    )
+
+    # fit model
+    trainer = Trainer(**trainer_options)
+    trainer.fit(model)
+    trainer.test()
+
+    # verify there are 2 val loaders
+    assert len(trainer.test_dataloaders) == 2, \
+        'Multiple test_dataloaders not initiated properly'
+
+    # make sure predictions are good for each test set
+    for dataloader in trainer.test_dataloaders:
+        tutils.run_prediction(dataloader, trainer.model)
+
+    # run the test method
+    trainer.test()
+
+
+def test_train_dataloaders_passed_to_fit(tmpdir):
+    """Verify that train dataloader can be passed to fit """
+    tutils.reset_seed()
+
+    class CurrentTestModel(LightTrainDataloader, TestModelBase):
+        pass
+
+    hparams = tutils.get_hparams()
+
+    # logger file to get meta
+    trainer_options = dict(
+        default_save_path=tmpdir,
+        max_epochs=1,
+        val_percent_check=0.1,
+        train_percent_check=0.2
+    )
+
+    # only train passed to fit
+    model = CurrentTestModel(hparams)
+    trainer = Trainer(**trainer_options)
+    fit_options = dict(train_dataloader=model._dataloader(train=True))
+    result = trainer.fit(model, **fit_options)
+
+    assert result == 1
+
+
+def test_train_val_dataloaders_passed_to_fit(tmpdir):
+    """ Verify that train & val dataloader can be passed to fit """
+    tutils.reset_seed()
+
+    class CurrentTestModel(
+        LightTrainDataloader,
+        LightValStepFitSingleDataloaderMixin,
+        TestModelBase,
+    ):
+        pass
+
+    hparams = tutils.get_hparams()
+
+    # logger file to get meta
+    trainer_options = dict(
+        default_save_path=tmpdir,
+        max_epochs=1,
+        val_percent_check=0.1,
+        train_percent_check=0.2
+    )
+
+    # train, val passed to fit
+    model = CurrentTestModel(hparams)
+    trainer = Trainer(**trainer_options)
+    fit_options = dict(train_dataloader=model._dataloader(train=True),
+                       val_dataloaders=model._dataloader(train=False))
+
+    result = trainer.fit(model, **fit_options)
+    assert result == 1
+    assert len(trainer.val_dataloaders) == 1, \
+        f'`val_dataloaders` not initiated properly, got {trainer.val_dataloaders}'
+
+
+def test_all_dataloaders_passed_to_fit(tmpdir):
+    """Verify train, val & test dataloader can be passed to fit """
+    tutils.reset_seed()
+
+    class CurrentTestModel(
+        LightTrainDataloader,
+        LightValStepFitSingleDataloaderMixin,
+        LightTestFitSingleTestDataloadersMixin,
+        LightEmptyTestStep,
+        TestModelBase,
+    ):
+        pass
+
+    hparams = tutils.get_hparams()
+
+    # logger file to get meta
+    trainer_options = dict(
+        default_save_path=tmpdir,
+        max_epochs=1,
+        val_percent_check=0.1,
+        train_percent_check=0.2
+    )
+
+    # train, val and test passed to fit
+    model = CurrentTestModel(hparams)
+    trainer = Trainer(**trainer_options)
+    fit_options = dict(train_dataloader=model._dataloader(train=True),
+                       val_dataloaders=model._dataloader(train=False),
+                       test_dataloaders=model._dataloader(train=False))
+
+    result = trainer.fit(model, **fit_options)
+
+    trainer.test()
+
+    assert result == 1
+    assert len(trainer.val_dataloaders) == 1, \
+        f'val_dataloaders` not initiated properly, got {trainer.val_dataloaders}'
+    assert len(trainer.test_dataloaders) == 1, \
+        f'test_dataloaders` not initiated properly, got {trainer.test_dataloaders}'
+
+
+def test_multiple_dataloaders_passed_to_fit(tmpdir):
+    """Verify that multiple val & test dataloaders can be passed to fit."""
+    tutils.reset_seed()
+
+    class CurrentTestModel(
+        LightningTestModel,
+        LightValStepFitMultipleDataloadersMixin,
+        LightTestFitMultipleTestDataloadersMixin,
+    ):
+        pass
+
+    hparams = tutils.get_hparams()
+
+    # logger file to get meta
+    trainer_options = dict(
+        default_save_path=tmpdir,
+        max_epochs=1,
+        val_percent_check=0.1,
+        train_percent_check=0.2
+    )
+
+    # train, multiple val and multiple test passed to fit
+    model = CurrentTestModel(hparams)
+    trainer = Trainer(**trainer_options)
+    fit_options = dict(train_dataloader=model._dataloader(train=True),
+                       val_dataloaders=[model._dataloader(train=False),
+                                        model._dataloader(train=False)],
+                       test_dataloaders=[model._dataloader(train=False),
+                                         model._dataloader(train=False)])
+    results = trainer.fit(model, **fit_options)
+    trainer.test()
+
+    assert len(trainer.val_dataloaders) == 2, \
+        f'Multiple `val_dataloaders` not initiated properly, got {trainer.val_dataloaders}'
+    assert len(trainer.test_dataloaders) == 2, \
+        f'Multiple `test_dataloaders` not initiated properly, got {trainer.test_dataloaders}'
+
+
+def test_mixing_of_dataloader_options(tmpdir):
+    """Verify that dataloaders can be passed to fit"""
+    tutils.reset_seed()
+
+    class CurrentTestModel(
+        LightTrainDataloader,
+        LightValStepFitSingleDataloaderMixin,
+        LightTestFitSingleTestDataloadersMixin,
+        TestModelBase,
+    ):
+        pass
+
+    hparams = tutils.get_hparams()
+    model = CurrentTestModel(hparams)
+
+    # logger file to get meta
+    trainer_options = dict(
+        default_save_path=tmpdir,
+        max_epochs=1,
+        val_percent_check=0.1,
+        train_percent_check=0.2
+    )
+
+    # fit model
+    trainer = Trainer(**trainer_options)
+    fit_options = dict(val_dataloaders=model._dataloader(train=False))
+    results = trainer.fit(model, **fit_options)
+
+    # fit model
+    trainer = Trainer(**trainer_options)
+    fit_options = dict(val_dataloaders=model._dataloader(train=False),
+                       test_dataloaders=model._dataloader(train=False))
+    _ = trainer.fit(model, **fit_options)
+    trainer.test()
+
+    assert len(trainer.val_dataloaders) == 1, \
+        f'`val_dataloaders` not initiated properly, got {trainer.val_dataloaders}'
+    assert len(trainer.test_dataloaders) == 1, \
+        f'`test_dataloaders` not initiated properly, got {trainer.test_dataloaders}'
+
+
+def test_inf_train_dataloader(tmpdir):
+    """Test inf train data loader (e.g. IterableDataset)"""
+    tutils.reset_seed()
+
+    class CurrentTestModel(
+        LightInfTrainDataloader,
+        LightningTestModel
+    ):
+        pass
+
+    hparams = tutils.get_hparams()
+    model = CurrentTestModel(hparams)
+
+    # fit model
+    with pytest.raises(MisconfigurationException):
+        trainer = Trainer(
+            default_save_path=tmpdir,
+            max_epochs=1,
+            val_check_interval=0.5
+        )
+        trainer.fit(model)
+
+    # logger file to get meta
+    trainer = Trainer(
+        default_save_path=tmpdir,
+        max_epochs=1,
+        val_check_interval=50
+    )
+    result = trainer.fit(model)
+
+    # verify training completed
+    assert result == 1
+
+
+def test_inf_val_dataloader(tmpdir):
+    """Test inf val data loader (e.g. IterableDataset)"""
+    tutils.reset_seed()
+
+    class CurrentTestModel(
+        LightInfValDataloader,
+        LightningTestModel
+    ):
+        pass
+
+    hparams = tutils.get_hparams()
+    model = CurrentTestModel(hparams)
+
+    # fit model
+    with pytest.raises(MisconfigurationException):
+        trainer = Trainer(
+            default_save_path=tmpdir,
+            max_epochs=1,
+            val_percent_check=0.5
+        )
+        trainer.fit(model)
+
+    # logger file to get meta
+    trainer = Trainer(
+        default_save_path=tmpdir,
+        max_epochs=1
+    )
+    result = trainer.fit(model)
+
+    # verify training completed
+    assert result == 1
+
+
+def test_inf_test_dataloader(tmpdir):
+    """Test inf test data loader (e.g. IterableDataset)"""
+    tutils.reset_seed()
+
+    class CurrentTestModel(
+        LightInfTestDataloader,
+        LightningTestModel,
+        LightTestFitSingleTestDataloadersMixin
+    ):
+        pass
+
+    hparams = tutils.get_hparams()
+    model = CurrentTestModel(hparams)
+
+    # fit model
+    with pytest.raises(MisconfigurationException):
+        trainer = Trainer(
+            default_save_path=tmpdir,
+            max_epochs=1,
+            test_percent_check=0.5
+        )
+        trainer.test(model)
+
+    # logger file to get meta
+    trainer = Trainer(
+        default_save_path=tmpdir,
+        max_epochs=1
+    )
+    result = trainer.fit(model)
+    trainer.test(model)
+
+    # verify training completed
+    assert result == 1
diff --git a/tests/trainer/test_optimizers.py b/tests/trainer/test_optimizers.py
new file mode 100644
index 0000000..bc5dde5
--- /dev/null
+++ b/tests/trainer/test_optimizers.py
@@ -0,0 +1,146 @@
+import math
+import os
+
+import pytest
+import torch
+
+import tests.models.utils as tutils
+from pytorch_lightning import Trainer
+
+from tests.models import (
+    TestModelBase,
+    LightTrainDataloader,
+    LightTestOptimizerWithSchedulingMixin,
+    LightTestMultipleOptimizersWithSchedulingMixin,
+    LightTestOptimizersWithMixedSchedulingMixin
+)
+
+
+def test_optimizer_with_scheduling(tmpdir):
+    """ Verify that learning rate scheduling is working """
+    tutils.reset_seed()
+
+    class CurrentTestModel(
+            LightTestOptimizerWithSchedulingMixin,
+            LightTrainDataloader,
+            TestModelBase):
+        pass
+
+    hparams = tutils.get_hparams()
+    model = CurrentTestModel(hparams)
+
+    # logger file to get meta
+    trainer_options = dict(
+        default_save_path=tmpdir,
+        max_epochs=1,
+        val_percent_check=0.1,
+        train_percent_check=0.2
+    )
+
+    # fit model
+    trainer = Trainer(**trainer_options)
+    results = trainer.fit(model)
+
+    init_lr = hparams.learning_rate
+    adjusted_lr = [pg['lr'] for pg in trainer.optimizers[0].param_groups]
+
+    assert len(trainer.lr_schedulers) == 1, \
+        'lr scheduler not initialized properly, it has %i elements instread of 1' % len(trainer.lr_schedulers)
+
+    assert all(a == adjusted_lr[0] for a in adjusted_lr), \
+        'Lr not equally adjusted for all param groups'
+    adjusted_lr = adjusted_lr[0]
+
+    assert init_lr * 0.1 == adjusted_lr, \
+        'Lr not adjusted correctly, expected %f but got %f' % (init_lr * 0.1, adjusted_lr)
+
+
+def test_multi_optimizer_with_scheduling(tmpdir):
+    """ Verify that learning rate scheduling is working """
+    tutils.reset_seed()
+
+    class CurrentTestModel(
+            LightTestMultipleOptimizersWithSchedulingMixin,
+            LightTrainDataloader,
+            TestModelBase):
+        pass
+
+    hparams = tutils.get_hparams()
+    model = CurrentTestModel(hparams)
+
+    # logger file to get meta
+    trainer_options = dict(
+        default_save_path=tmpdir,
+        max_epochs=1,
+        val_percent_check=0.1,
+        train_percent_check=0.2
+    )
+
+    # fit model
+    trainer = Trainer(**trainer_options)
+    results = trainer.fit(model)
+
+    init_lr = hparams.learning_rate
+    adjusted_lr1 = [pg['lr'] for pg in trainer.optimizers[0].param_groups]
+    adjusted_lr2 = [pg['lr'] for pg in trainer.optimizers[1].param_groups]
+
+    assert len(trainer.lr_schedulers) == 2, \
+        'all lr scheduler not initialized properly, it has %i elements instread of 1' % len(trainer.lr_schedulers)
+
+    assert all(a == adjusted_lr1[0] for a in adjusted_lr1), \
+        'Lr not equally adjusted for all param groups for optimizer 1'
+    adjusted_lr1 = adjusted_lr1[0]
+
+    assert all(a == adjusted_lr2[0] for a in adjusted_lr2), \
+        'Lr not equally adjusted for all param groups for optimizer 2'
+    adjusted_lr2 = adjusted_lr2[0]
+
+    assert init_lr * 0.1 == adjusted_lr1 and init_lr * 0.1 == adjusted_lr2, \
+        'Lr not adjusted correctly, expected %f but got %f' % (init_lr * 0.1, adjusted_lr1)
+
+
+def test_multi_optimizer_with_scheduling_stepping(tmpdir):
+    tutils.reset_seed()
+
+    class CurrentTestModel(
+            LightTestOptimizersWithMixedSchedulingMixin,
+            LightTrainDataloader,
+            TestModelBase):
+        pass
+
+    hparams = tutils.get_hparams()
+    model = CurrentTestModel(hparams)
+
+    # logger file to get meta
+    trainer_options = dict(
+        default_save_path=tmpdir,
+        max_epochs=1,
+        val_percent_check=0.1,
+        train_percent_check=0.2
+    )
+
+    # fit model
+    trainer = Trainer(**trainer_options)
+    results = trainer.fit(model)
+
+    init_lr = hparams.learning_rate
+    adjusted_lr1 = [pg['lr'] for pg in trainer.optimizers[0].param_groups]
+    adjusted_lr2 = [pg['lr'] for pg in trainer.optimizers[1].param_groups]
+
+    assert len(trainer.lr_schedulers) == 2, \
+        'all lr scheduler not initialized properly'
+
+    assert all(a == adjusted_lr1[0] for a in adjusted_lr1), \
+        'lr not equally adjusted for all param groups for optimizer 1'
+    adjusted_lr1 = adjusted_lr1[0]
+
+    assert all(a == adjusted_lr2[0] for a in adjusted_lr2), \
+        'lr not equally adjusted for all param groups for optimizer 2'
+    adjusted_lr2 = adjusted_lr2[0]
+
+    # Called ones after end of epoch
+    assert init_lr * (0.1)**3 == adjusted_lr1, \
+        'lr for optimizer 1 not adjusted correctly'
+    # Called every 3 steps, meaning for 1 epoch of 11 batches, it is called 3 times
+    assert init_lr * 0.1 == adjusted_lr2, \
+        'lr for optimizer 2 not adjusted correctly'
diff --git a/tests/trainer/test_trainer.py b/tests/trainer/test_trainer.py
new file mode 100644
index 0000000..38112e1
--- /dev/null
+++ b/tests/trainer/test_trainer.py
@@ -0,0 +1,646 @@
+import glob
+import math
+import os
+from argparse import ArgumentParser, Namespace
+from unittest import mock
+
+import pytest
+import torch
+
+import tests.models.utils as tutils
+from pytorch_lightning import Trainer
+from pytorch_lightning.callbacks import (
+    EarlyStopping,
+    ModelCheckpoint,
+)
+from pytorch_lightning.core.lightning import load_hparams_from_tags_csv
+from pytorch_lightning.trainer.logging import TrainerLoggingMixin
+from pytorch_lightning.utilities.debugging import MisconfigurationException
+from tests.models import (
+    TestModelBase,
+    DictHparamsModel,
+    LightningTestModel,
+    LightEmptyTestStep,
+    LightValidationStepMixin,
+    LightValidationMultipleDataloadersMixin,
+    LightTrainDataloader,
+    LightTestDataloader,
+)
+
+
+def test_hparams_save_load(tmpdir):
+    model = DictHparamsModel({'in_features': 28 * 28, 'out_features': 10})
+
+    # logger file to get meta
+    trainer_options = dict(
+        default_save_path=tmpdir,
+        max_epochs=2,
+    )
+
+    # fit model
+    trainer = Trainer(**trainer_options)
+    result = trainer.fit(model)
+
+    assert result == 1
+
+    # try to load the model now
+    pretrained_model = tutils.load_model_from_checkpoint(
+        trainer.checkpoint_callback.dirpath,
+        module_class=DictHparamsModel
+    )
+
+
+def test_no_val_module(tmpdir):
+    """Tests use case where trainer saves the model, and user loads it from tags independently."""
+    tutils.reset_seed()
+
+    hparams = tutils.get_hparams()
+
+    class CurrentTestModel(LightTrainDataloader, TestModelBase):
+        pass
+
+    model = CurrentTestModel(hparams)
+
+    # logger file to get meta
+    logger = tutils.get_test_tube_logger(tmpdir, False)
+
+    trainer_options = dict(
+        max_epochs=1,
+        logger=logger,
+        checkpoint_callback=ModelCheckpoint(tmpdir)
+    )
+
+    # fit model
+    trainer = Trainer(**trainer_options)
+    result = trainer.fit(model)
+
+    # training complete
+    assert result == 1, 'amp + ddp model failed to complete'
+
+    # save model
+    new_weights_path = os.path.join(tmpdir, 'save_test.ckpt')
+    trainer.save_checkpoint(new_weights_path)
+
+    # load new model
+    tags_path = tutils.get_data_path(logger, path_dir=tmpdir)
+    tags_path = os.path.join(tags_path, 'meta_tags.csv')
+    model_2 = LightningTestModel.load_from_checkpoint(
+        checkpoint_path=new_weights_path,
+        tags_csv=tags_path
+    )
+    model_2.eval()
+
+
+def test_no_val_end_module(tmpdir):
+    """Tests use case where trainer saves the model, and user loads it from tags independently."""
+    tutils.reset_seed()
+
+    class CurrentTestModel(LightTrainDataloader, LightValidationStepMixin, TestModelBase):
+        pass
+
+    hparams = tutils.get_hparams()
+    model = CurrentTestModel(hparams)
+
+    # logger file to get meta
+    logger = tutils.get_test_tube_logger(tmpdir, False)
+
+    trainer_options = dict(
+        max_epochs=1,
+        logger=logger,
+        checkpoint_callback=ModelCheckpoint(tmpdir)
+    )
+
+    # fit model
+    trainer = Trainer(**trainer_options)
+    result = trainer.fit(model)
+
+    # traning complete
+    assert result == 1, 'amp + ddp model failed to complete'
+
+    # save model
+    new_weights_path = os.path.join(tmpdir, 'save_test.ckpt')
+    trainer.save_checkpoint(new_weights_path)
+
+    # load new model
+    tags_path = tutils.get_data_path(logger, path_dir=tmpdir)
+    tags_path = os.path.join(tags_path, 'meta_tags.csv')
+    model_2 = LightningTestModel.load_from_checkpoint(
+        checkpoint_path=new_weights_path,
+        tags_csv=tags_path
+    )
+    model_2.eval()
+
+
+def test_gradient_accumulation_scheduling(tmpdir):
+    """
+    Test grad accumulation by the freq of optimizer updates
+    """
+    tutils.reset_seed()
+
+    # test incorrect configs
+    with pytest.raises(IndexError):
+        assert Trainer(accumulate_grad_batches={0: 3, 1: 4, 4: 6})
+        assert Trainer(accumulate_grad_batches={-2: 3})
+
+    with pytest.raises(TypeError):
+        assert Trainer(accumulate_grad_batches={})
+        assert Trainer(accumulate_grad_batches=[[2, 3], [4, 6]])
+        assert Trainer(accumulate_grad_batches={1: 2, 3.: 4})
+        assert Trainer(accumulate_grad_batches={1: 2.5, 3: 5})
+
+    # test optimizer call freq matches scheduler
+    def _optimizer_step(self, epoch, batch_idx, optimizer,
+                        optimizer_idx, second_order_closure=None):
+        # only test the first 12 batches in epoch
+        if batch_idx < 12:
+            if epoch == 0:
+                # reset counter when starting epoch
+                if batch_idx == 0:
+                    self.prev_called_batch_idx = 0
+
+                    # use this opportunity to test once
+                    assert self.trainer.accumulate_grad_batches == 1
+
+                assert batch_idx == self.prev_called_batch_idx
+                self.prev_called_batch_idx += 1
+
+            elif 1 <= epoch <= 2:
+                # reset counter when starting epoch
+                if batch_idx == 1:
+                    self.prev_called_batch_idx = 1
+
+                    # use this opportunity to test once
+                    assert self.trainer.accumulate_grad_batches == 2
+
+                assert batch_idx == self.prev_called_batch_idx
+                self.prev_called_batch_idx += 2
+
+            else:
+                if batch_idx == 3:
+                    self.prev_called_batch_idx = 3
+
+                    # use this opportunity to test once
+                    assert self.trainer.accumulate_grad_batches == 4
+
+                assert batch_idx == self.prev_called_batch_idx
+                self.prev_called_batch_idx += 3
+
+        optimizer.step()
+
+        # clear gradients
+        optimizer.zero_grad()
+
+    hparams = tutils.get_hparams()
+    model = LightningTestModel(hparams)
+    schedule = {1: 2, 3: 4}
+
+    trainer = Trainer(accumulate_grad_batches=schedule,
+                      train_percent_check=0.1,
+                      val_percent_check=0.1,
+                      max_epochs=4,
+                      default_save_path=tmpdir)
+
+    # for the test
+    trainer.optimizer_step = _optimizer_step
+    model.prev_called_batch_idx = 0
+
+    trainer.fit(model)
+
+
+def test_loading_meta_tags(tmpdir):
+    tutils.reset_seed()
+
+    hparams = tutils.get_hparams()
+
+    # save tags
+    logger = tutils.get_test_tube_logger(tmpdir, False)
+    logger.log_hyperparams(Namespace(some_str='a_str', an_int=1, a_float=2.0))
+    logger.log_hyperparams(hparams)
+    logger.save()
+
+    # load tags
+    path_expt_dir = tutils.get_data_path(logger, path_dir=tmpdir)
+    tags_path = os.path.join(path_expt_dir, 'meta_tags.csv')
+    tags = load_hparams_from_tags_csv(tags_path)
+
+    assert tags.batch_size == 32 and tags.hidden_dim == 1000
+
+
+def test_dp_output_reduce():
+    mixin = TrainerLoggingMixin()
+    tutils.reset_seed()
+
+    # test identity when we have a single gpu
+    out = torch.rand(3, 1)
+    assert mixin.reduce_distributed_output(out, num_gpus=1) is out
+
+    # average when we have multiples
+    assert mixin.reduce_distributed_output(out, num_gpus=2) == out.mean()
+
+    # when we have a dict of vals
+    out = {
+        'a': out,
+        'b': {
+            'c': out
+        }
+    }
+    reduced = mixin.reduce_distributed_output(out, num_gpus=3)
+    assert reduced['a'] == out['a']
+    assert reduced['b']['c'] == out['b']['c']
+
+
+def test_model_checkpoint_options(tmpdir):
+    """Test ModelCheckpoint options."""
+    def mock_save_function(filepath):
+        open(filepath, 'a').close()
+
+    hparams = tutils.get_hparams()
+    _ = LightningTestModel(hparams)
+
+    # simulated losses
+    save_dir = os.path.join(tmpdir, '1')
+    os.mkdir(save_dir)
+    losses = [10, 9, 2.8, 5, 2.5]
+
+    # -----------------
+    # CASE K=-1  (all)
+    checkpoint_callback = ModelCheckpoint(save_dir, save_top_k=-1, verbose=1)
+    checkpoint_callback.save_function = mock_save_function
+    trainer = Trainer()
+
+    # emulate callback's calls during the training
+    for i, loss in enumerate(losses):
+        trainer.current_epoch = i
+        trainer.callback_metrics = {'val_loss': loss}
+        checkpoint_callback.on_validation_end(trainer, trainer.get_model())
+
+    file_lists = set(os.listdir(save_dir))
+
+    assert len(file_lists) == len(losses), "Should save all models when save_top_k=-1"
+
+    # verify correct naming
+    for fname in {'epoch=4.ckpt',
+                  'epoch=3.ckpt',
+                  'epoch=2.ckpt',
+                  'epoch=1.ckpt',
+                  'epoch=0.ckpt'}:
+        assert fname in file_lists
+
+    save_dir = os.path.join(tmpdir, '2')
+    os.mkdir(save_dir)
+
+    # -----------------
+    # CASE K=0 (none)
+    checkpoint_callback = ModelCheckpoint(save_dir, save_top_k=0, verbose=1)
+    checkpoint_callback.save_function = mock_save_function
+    trainer = Trainer()
+
+    # emulate callback's calls during the training
+    for i, loss in enumerate(losses):
+        trainer.current_epoch = i
+        trainer.callback_metrics = {'val_loss': loss}
+        checkpoint_callback.on_validation_end(trainer, trainer.get_model())
+
+    file_lists = os.listdir(save_dir)
+
+    assert len(file_lists) == 0, "Should save 0 models when save_top_k=0"
+
+    save_dir = os.path.join(tmpdir, '3')
+    os.mkdir(save_dir)
+
+    # -----------------
+    # CASE K=1 (2.5, epoch 4)
+    checkpoint_callback = ModelCheckpoint(save_dir, save_top_k=1, verbose=1, prefix='test_prefix_')
+    checkpoint_callback.save_function = mock_save_function
+    trainer = Trainer()
+
+    # emulate callback's calls during the training
+    for i, loss in enumerate(losses):
+        trainer.current_epoch = i
+        trainer.callback_metrics = {'val_loss': loss}
+        checkpoint_callback.on_validation_end(trainer, trainer.get_model())
+
+    file_lists = set(os.listdir(save_dir))
+
+    assert len(file_lists) == 1, "Should save 1 model when save_top_k=1"
+    assert 'test_prefix_epoch=4.ckpt' in file_lists
+
+    save_dir = os.path.join(tmpdir, '4')
+    os.mkdir(save_dir)
+
+    # -----------------
+    # CASE K=2 (2.5 epoch 4, 2.8 epoch 2)
+    # make sure other files don't get deleted
+
+    checkpoint_callback = ModelCheckpoint(save_dir, save_top_k=2, verbose=1)
+    open(f"{save_dir}/other_file.ckpt", 'a').close()
+    checkpoint_callback.save_function = mock_save_function
+    trainer = Trainer()
+
+    # emulate callback's calls during the training
+    for i, loss in enumerate(losses):
+        trainer.current_epoch = i
+        trainer.callback_metrics = {'val_loss': loss}
+        checkpoint_callback.on_validation_end(trainer, trainer.get_model())
+
+    file_lists = set(os.listdir(save_dir))
+
+    assert len(file_lists) == 3, 'Should save 2 model when save_top_k=2'
+    for fname in {'epoch=4.ckpt',
+                  'epoch=2.ckpt',
+                  'other_file.ckpt'}:
+        assert fname in file_lists
+
+    save_dir = os.path.join(tmpdir, '5')
+    os.mkdir(save_dir)
+
+    # -----------------
+    # CASE K=4 (save all 4 models)
+    # multiple checkpoints within same epoch
+
+    checkpoint_callback = ModelCheckpoint(save_dir, save_top_k=4, verbose=1)
+    checkpoint_callback.save_function = mock_save_function
+    trainer = Trainer()
+
+    # emulate callback's calls during the training
+    for loss in losses:
+        trainer.current_epoch = 0
+        trainer.callback_metrics = {'val_loss': loss}
+        checkpoint_callback.on_validation_end(trainer, trainer.get_model())
+
+    file_lists = set(os.listdir(save_dir))
+
+    assert len(file_lists) == 4, 'Should save all 4 models when save_top_k=4 within same epoch'
+
+    save_dir = os.path.join(tmpdir, '6')
+    os.mkdir(save_dir)
+
+    # -----------------
+    # CASE K=3 (save the 2nd, 3rd, 4th model)
+    # multiple checkpoints within same epoch
+
+    checkpoint_callback = ModelCheckpoint(save_dir, save_top_k=3, verbose=1)
+    checkpoint_callback.save_function = mock_save_function
+    trainer = Trainer()
+
+    # emulate callback's calls during the training
+    for loss in losses:
+        trainer.current_epoch = 0
+        trainer.callback_metrics = {'val_loss': loss}
+        checkpoint_callback.on_validation_end(trainer, trainer.get_model())
+
+    file_lists = set(os.listdir(save_dir))
+
+    assert len(file_lists) == 3, 'Should save 3 models when save_top_k=3'
+    for fname in {'epoch=0.ckpt',
+                  'epoch=0.ckpt',
+                  'epoch=0.ckpt'}:
+        assert fname in file_lists
+
+
+def test_model_freeze_unfreeze():
+    tutils.reset_seed()
+
+    hparams = tutils.get_hparams()
+    model = LightningTestModel(hparams)
+
+    model.freeze()
+    model.unfreeze()
+
+
+def test_resume_from_checkpoint_epoch_restored(tmpdir):
+    """Verify resuming from checkpoint runs the right number of epochs"""
+    import types
+
+    tutils.reset_seed()
+
+    hparams = tutils.get_hparams()
+
+    def _new_model():
+        # Create a model that tracks epochs and batches seen
+        model = LightningTestModel(hparams)
+        model.num_epochs_seen = 0
+        model.num_batches_seen = 0
+
+        def increment_epoch(self):
+            self.num_epochs_seen += 1
+
+        def increment_batch(self, _):
+            self.num_batches_seen += 1
+
+        # Bind the increment_epoch function on_epoch_end so that the
+        # model keeps track of the number of epochs it has seen.
+        model.on_epoch_end = types.MethodType(increment_epoch, model)
+        model.on_batch_start = types.MethodType(increment_batch, model)
+        return model
+
+    model = _new_model()
+
+    trainer_options = dict(
+        show_progress_bar=False,
+        max_epochs=2,
+        train_percent_check=0.65,
+        val_percent_check=1,
+        checkpoint_callback=ModelCheckpoint(tmpdir, save_top_k=-1),
+        logger=False,
+        default_save_path=tmpdir,
+        early_stop_callback=False,
+        val_check_interval=1.,
+    )
+
+    # fit model
+    trainer = Trainer(**trainer_options)
+    trainer.fit(model)
+
+    training_batches = trainer.num_training_batches
+
+    assert model.num_epochs_seen == 2
+    assert model.num_batches_seen == training_batches * 2
+
+    # Other checkpoints can be uncommented if/when resuming mid-epoch is supported
+    checkpoints = sorted(glob.glob(os.path.join(trainer.checkpoint_callback.dirpath, '*.ckpt')))
+
+    for check in checkpoints:
+        next_model = _new_model()
+        state = torch.load(check)
+
+        # Resume training
+        trainer_options['max_epochs'] = 4
+        new_trainer = Trainer(**trainer_options, resume_from_checkpoint=check)
+        new_trainer.fit(next_model)
+        assert state['global_step'] + next_model.num_batches_seen == training_batches * 4
+
+
+def _init_steps_model():
+    """private method for initializing a model with 5% train epochs"""
+    tutils.reset_seed()
+    model, _ = tutils.get_model()
+
+    # define train epoch to 5% of data
+    train_percent = 0.05
+    # get number of samples in 1 epoch
+    num_train_samples = math.floor(len(model.train_dataloader()) * train_percent)
+
+    trainer_options = dict(
+        train_percent_check=train_percent,
+    )
+    return model, trainer_options, num_train_samples
+
+
+def test_trainer_max_steps_and_epochs(tmpdir):
+    """Verify model trains according to specified max steps"""
+    model, trainer_options, num_train_samples = _init_steps_model()
+
+    # define less train steps than epochs
+    trainer_options.update(dict(
+        default_save_path=tmpdir,
+        max_epochs=5,
+        max_steps=num_train_samples + 10
+    ))
+
+    # fit model
+    trainer = Trainer(**trainer_options)
+    result = trainer.fit(model)
+    assert result == 1, "Training did not complete"
+
+    # check training stopped at max_steps
+    assert trainer.global_step == trainer.max_steps, "Model did not stop at max_steps"
+
+    # define less train epochs than steps
+    trainer_options.update(dict(
+        max_epochs=2,
+        max_steps=trainer_options['max_epochs'] * 2 * num_train_samples
+    ))
+
+    # fit model
+    trainer = Trainer(**trainer_options)
+    result = trainer.fit(model)
+    assert result == 1, "Training did not complete"
+
+    # check training stopped at max_epochs
+    assert trainer.global_step == num_train_samples * trainer.max_epochs \
+        and trainer.current_epoch == trainer.max_epochs - 1, "Model did not stop at max_epochs"
+
+
+def test_trainer_min_steps_and_epochs(tmpdir):
+    """Verify model trains according to specified min steps"""
+    model, trainer_options, num_train_samples = _init_steps_model()
+
+    # define callback for stopping the model and default epochs
+    trainer_options.update(dict(
+        default_save_path=tmpdir,
+        early_stop_callback=EarlyStopping(monitor='val_loss', min_delta=1.0),
+        val_check_interval=20,
+        min_epochs=1,
+        max_epochs=10
+    ))
+
+    # define less min steps than 1 epoch
+    trainer_options['min_steps'] = math.floor(num_train_samples / 2)
+
+    # fit model
+    trainer = Trainer(**trainer_options)
+    result = trainer.fit(model)
+    assert result == 1, "Training did not complete"
+
+    # check model ran for at least min_epochs
+    assert trainer.global_step >= num_train_samples and \
+        trainer.current_epoch > 0, "Model did not train for at least min_epochs"
+
+    # define less epochs than min_steps
+    trainer_options['min_steps'] = math.floor(num_train_samples * 1.5)
+
+    # fit model
+    trainer = Trainer(**trainer_options)
+    result = trainer.fit(model)
+    assert result == 1, "Training did not complete"
+
+    # check model ran for at least num_train_samples*1.5
+    assert trainer.global_step >= math.floor(num_train_samples * 1.5) and \
+        trainer.current_epoch > 0, "Model did not train for at least min_steps"
+
+
+def test_benchmark_option(tmpdir):
+    """Verify benchmark option."""
+    tutils.reset_seed()
+
+    class CurrentTestModel(
+        LightValidationMultipleDataloadersMixin,
+        LightTrainDataloader,
+        TestModelBase
+    ):
+        pass
+
+    hparams = tutils.get_hparams()
+    model = CurrentTestModel(hparams)
+
+    # verify torch.backends.cudnn.benchmark is not turned on
+    assert not torch.backends.cudnn.benchmark
+
+    # logger file to get meta
+    trainer_options = dict(
+        default_save_path=tmpdir,
+        max_epochs=1,
+        benchmark=True,
+    )
+
+    # fit model
+    trainer = Trainer(**trainer_options)
+    result = trainer.fit(model)
+
+    # verify training completed
+    assert result == 1
+
+    # verify torch.backends.cudnn.benchmark is not turned off
+    assert torch.backends.cudnn.benchmark
+
+
+def test_testpass_overrides(tmpdir):
+    hparams = tutils.get_hparams()
+
+    class LocalModel(LightTrainDataloader, TestModelBase):
+        pass
+
+    class LocalModelNoEnd(LightTrainDataloader, LightTestDataloader, LightEmptyTestStep, TestModelBase):
+        pass
+
+    class LocalModelNoStep(LightTrainDataloader, TestModelBase):
+        def test_epoch_end(self, outputs):
+            return {}
+
+    # Misconfig when neither test_step or test_end is implemented
+    with pytest.raises(MisconfigurationException):
+        model = LocalModel(hparams)
+        Trainer().test(model)
+
+    # Misconfig when neither test_step or test_end is implemented
+    with pytest.raises(MisconfigurationException):
+        model = LocalModelNoStep(hparams)
+        Trainer().test(model)
+
+    # No exceptions when one or both of test_step or test_end are implemented
+    model = LocalModelNoEnd(hparams)
+    Trainer().test(model)
+
+    model = LightningTestModel(hparams)
+    Trainer().test(model)
+
+
+@mock.patch('argparse.ArgumentParser.parse_args',
+            return_value=Namespace(**Trainer.default_attributes()))
+def test_default_args(tmpdir):
+    """Tests default argument parser for Trainer"""
+    tutils.reset_seed()
+
+    # logger file to get meta
+    logger = tutils.get_test_tube_logger(tmpdir, False)
+
+    parser = ArgumentParser(add_help=False)
+    args = parser.parse_args()
+    args.logger = logger
+
+    args.max_epochs = 5
+    trainer = Trainer.from_argparse_args(args)
+
+    assert isinstance(trainer, Trainer)
+    assert trainer.max_epochs == 5
