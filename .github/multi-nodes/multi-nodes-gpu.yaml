apiVersion: elastic.pytorch.org/v1alpha1
kind: ElasticJob
metadata:
  name: Pytorch Lightning Multi Nodes Testing
  namespace: elastic-job
spec:
  # Use "etcd-service:2379" if you already apply etcd.yaml
  rdzvEndpoint: "etcd-service:2379"
  minReplicas: 2
  maxReplicas: 2
  replicaSpecs:
    Worker:
      replicas: 2
      restartPolicy: ExitCode
      template:
        apiVersion: v1
        kind: Pod
        spec:
          initContainers:
            - name: Clone Repo
              image: pytorchlightning/pytorch_lightning:base-cuda-py{PYTHON_VERSION}-torch{PYTORCH_VERSION}
              command: ["git", "clone", "https://github.com/tchaton/pytorch-lightning.git"]
            
            - name: Cd Pytorch Lightning
              image: pytorchlightning/pytorch_lightning:base-cuda-py{PYTHON_VERSION}-torch{PYTORCH_VERSION}
              command: ["cd", "pytorch-lightning"]
            
            - name: Fetch all
              image: pytorchlightning/pytorch_lightning:base-cuda-py{PYTHON_VERSION}-torch{PYTORCH_VERSION}
              command: ["git", "fetch", "--all"]
            
            - name: Pip install
              image: pytorchlightning/pytorch_lightning:base-cuda-py{PYTHON_VERSION}-torch{PYTORCH_VERSION}
              command: ["pip", "install", "-e", "."]
          
          containers:
            - name: Pytorch Lightning Multi Nodes Testing
              image: pytorchlightning/pytorch_lightning:base-cuda-py{PYTHON_VERSION}-torch{PYTORCH_VERSION}
              imagePullPolicy: Always
              command: [python", "-m", "torchelastic.distributed.launch"]
              args:
                - "--nproc_per_node={NODES}"
                - "-m coverage run pytest tests/backends/multi-nodes.py"
              resources:
                limits:
                  nvidia.com/gpu: 4
