# Python CircleCI 2.0 configuration file
#
# Check https://circleci.com/docs/2.0/language-python/ for more details
#
version: 2.0

references:

  make_docs: &make_docs
    run:
      name: Make Documentation
      command: |
        # First run the same pipeline as Read-The-Docs
        # apt-get update && apt-get install -y cmake
        # using: https://hub.docker.com/r/readthedocs/build
        # we need to use py3.7 ot higher becase of an issue with metaclass inheritence
        pyenv global 3.7.3
        python --version
        pip install -r requirements/docs.txt
        cd docs; make clean; make html --debug --jobs 2 SPHINXOPTS="-W"

  install_go: &install_go
    run:
      name: Install Go
      command: |
        # todo

  checkout_ml_testing: &checkout_ml_testing
   run:
     name: Checkout ml-testing-accelerators
     command: |
       git clone https://github.com/GoogleCloudPlatform/ml-testing-accelerators.git
       git checkout 5e88ac24f631c27045e62f0e8d5dfcf34e425e25

  setup_gcloud: &setup_gcloud
   run:
     name: Setup gcloud CLI
     command: |
        # GoogleCloudPlatform/github-actions/setup-gcloud@master
        # version: '290.0.1'
        # service_account_key: ${{ secrets.GKE_SA_KEY_BASE64 }}
        # project_id: ${{ secrets.GKE_PROJECT }}
        # export_default_credentials: true

  config_docker: &config_docker
    run:
      name: Configure Docker
      command: |
        cd docker/tpu
        docker build --tag "$IMAGE:$GITHUB_RUN_ID" -f Dockerfile --build-arg "GITHUB_REF=$GITHUB_REF" --build-arg "TEST_IMAGE=1" .
        docker push "$IMAGE:$GITHUB_RUN_ID"

  install_jsonnet: &install_jsonnet
    run:
      name: Install jsonnet
      command: |
        go get github.com/google/go-jsonnet/cmd/jsonnet

  gke_credentials: &gke_credentials
   run:
     name: GKE credentials
     command: |
       gcloud container clusters get-credentials "$GKE_CLUSTER" --zone "$GKE_ZONE"

  deploy_cluster: &deploy_cluster
   run:
     name: Deploy the job on the kubernetes cluster
     command: |
       job_name=$(jsonnet -J ml-testing-accelerators/ dockers/tpu-tests/tpu_test_cases.jsonnet --ext-str image=$IMAGE --ext-str image-tag=$GITHUB_RUN_ID | kubectl create -f -) && \
       job_name=${job_name#job.batch/} && \
       job_name=${job_name% created} && \
       echo "Waiting on kubernetes job: $job_name in cluster: $GKE_CLUSTER" && \
       i=0 && \
       # 30 checks spaced 30s apart = 900s total.
       max_checks=30 && \
       status_code=2 && \
       # Check on the job periodically. Set the status code depending on what
       # happened to the job in Kubernetes. If we try max_checks times and
       # still the job hasn't finished, give up and return the starting
       # non-zero status code.
       while [ $i -lt $max_checks ]; do ((i++)); if kubectl get jobs $job_name -o jsonpath='Failed:{.status.failed}' | grep "Failed:1"; then status_code=1 && break; elif kubectl get jobs $job_name -o jsonpath='Succeeded:{.status.succeeded}' | grep "Succeeded:1" ; then status_code=0 && break; else echo "Job not finished yet"; fi; sleep 30; done && \
       echo "Done waiting. Job status code: $status_code" && \
       # Allow time for logs to flush.
       sleep 60 && \
       echo "JOB_NAME: $job_name" && \
       echo "GKE_CLUSTER: $GKE_CLUSTER" && \
       echo "GKE_ZONE: $GKE_ZONE" && \
       gcloud logging read "resource.type=k8s_container resource.labels.project_id=$PROJECT_ID resource.labels.location=$GKE_ZONE resource.labels.cluster_name=$GKE_CLUSTER resource.labels.namespace_name=default resource.labels.pod_name:$job_name" --limit 10000000 --order asc --format 'value(textPayload)' --project=$PROJECT_ID > /tmp/full_output.txt && \
       if grep -q '<?xml version="1.0" ?>' /tmp/full_output.txt ; then csplit /tmp/full_output.txt '/<?xml version="1.0" ?>/'; else mv /tmp/full_output.txt xx00; fi && \
       # First portion is the test logs. Print these to Github Action stdout.
       cat xx00 && \
       echo "Done with log retrieval attempt." && \
       gcloud container images delete "$IMAGE:$GITHUB_RUN_ID" --force-delete-tags && \
       exit $status_code

  stats: &stats
   run:
     name: Statistics
     command: |
       mv ./xx01 coverage.xml
       # TODO: add human readable report
       cat coverage
       sudo pip install pycobertura
       pycobertura show coverage.xml

  codecov: &codecov
   run:
     name: Upload coverage to Codecov
     command: |
       codecov --token $CODECOV_TOKEN --flags=tpu,pytest --name="GPU-coverage" --env=linux  # --build $DRONE_BUILD_NUMBER --commit $DRONE_COMMIT

jobs:

  TPU-tests:
    docker:
      - image: circleci/python:3.7
    steps:
      - checkout
      - *install_go
      - *checkout_ml_testing
      - *setup_gcloud
      - *config_docker
      - *install_jsonnet
      - *gke_credentials
      - *deploy_cluster
      - *stats
      - *codecov
      - store_artifacts:
          path: coverage.xml

  Build-Docs:
    docker:
      - image: readthedocs/build:latest
    steps:
      - checkout
      - *make_docs
      - store_artifacts:
          # allows us to preview the generated html pages
          path: docs/build/html/
          destination: html

workflows:
  version: 2
  build:
    jobs:
      - Build-Docs
      - TPU-tests
